[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fortgeschrittene Datenanalyse mit R",
    "section": "",
    "text": "Willkommen\nDies ist die Website des Seminars Fortgeschrittene Datenanalyse am Institut für Publizistik der Johannes-Gutenberg Universität Mainz.\nGrundlagen von R und Datenanalyse finden sich im Kursmaterial zur BA Datenanalyse.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.html#kursmaterialien",
    "href": "index.html#kursmaterialien",
    "title": "Fortgeschrittene Datenanalyse mit R",
    "section": "Kursmaterialien",
    "text": "Kursmaterialien\nAlle Materialien in Form von R-Code und Datensätzen sind hier als ZIP-Datei verfügbar. Wenn Sie den Ordner entpackt und die Projekt-Datei MA-Datenanalyse.Rproj geöffnet haben, können Sie alle Analysen auf den nachfolgenden Seiten sowie eigene Hausaufgaben und Übungen darin durchführen.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "index.html#kleingedrucktes",
    "href": "index.html#kleingedrucktes",
    "title": "Fortgeschrittene Datenanalyse mit R",
    "section": "Kleingedrucktes",
    "text": "Kleingedrucktes\nInhalte: Michael Scharkow, Nora Denner\nLizenz: CC-BY-SA\nErstellt mit Quarto, R und dem tidyverse.",
    "crumbs": [
      "Willkommen"
    ]
  },
  {
    "objectID": "regression-anova.html",
    "href": "regression-anova.html",
    "title": "1  ANOVA und Regression",
    "section": "",
    "text": "1.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für die ANOVA und Regression brauchen wir das marginaleffects- , sowie das tidyverse- und das report-Paket. Für eine schönere Darstellung der Plots setzen wir außerdem das Theme auf theme_minimal.\nlibrary(marginaleffects)\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nFür die ANOVA und die Regression nutzen wir den SPSS-Datensatz productplacement_anova.sav und wir wandeln die Spalte Placementhäufigkeit in einen Faktor um, sodass es als kategoriale Variable behandelt wird. Der Datensatz enthält zwei Spalten: die Placementhäufigkeit und das Persuasionswissen.\nd_pp &lt;- haven::read_sav(\"data/productplacement_anova.sav\") |&gt;\n  mutate(Placementhäufigkeit = as_factor(Placementhäufigkeit))\nd_pp\n\n# A tibble: 15 × 2\n  Placementhäufigkeit Persuasionswissen\n  &lt;fct&gt;                           &lt;dbl&gt;\n1 0 Placements                        5\n2 0 Placements                        7\n3 0 Placements                        3\n4 0 Placements                        4\n5 0 Placements                        6\n# ℹ 10 more rows\nZudem laden wir dem SPSS-Datensatz wahlabsicht_regression.sav. Auch hier wird eine Spalte, in diesem Fall Sex, in einen Faktor umgewandelt, sodass es als kategoriale Variable behandelt wird. Der Datensatz enthält 8 Spalten: Bildung, Sex, Einkommen, Politische Wertorientierung, Wirksamkeitserwartung, Qualitätsmedien, Wahlabsicht und Boulevardmedien.\nd_wahl &lt;- haven::read_sav(\"data/wahlabsicht_regression.sav\") |&gt;\n  mutate(Sex = as_factor(Sex)) |&gt;\n  haven::zap_labels()\nd_wahl\n\n# A tibble: 156 × 8\n  Bildung Sex      Einkommen PolitischeWertorientierung Wirksamkeitserwartung\n    &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;                      &lt;dbl&gt;                 &lt;dbl&gt;\n1       2 männlich         2                          5                     1\n2       5 männlich         5                          5                     4\n3       4 männlich         3                          3                     3\n4       3 männlich         2                          4                     2\n5       3 männlich         2                          1                     1\n# ℹ 151 more rows\n# ℹ 3 more variables: Qualitätsmedien &lt;dbl&gt;, Wahlabsicht &lt;dbl&gt;,\n#   Boulevardmedien &lt;dbl&gt;",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "regression-anova.html#pakete-und-daten",
    "href": "regression-anova.html#pakete-und-daten",
    "title": "1  ANOVA und Regression",
    "section": "",
    "text": "Variablenübersicht für Datensätze\n\n\n\nAus einigen Datenformaten, vor allem SPSS-Dateien, lassen sich automatisch Variablenübersichten mit Variablen- und Wertelabels generieren. Die einfachste Funktion ist dafür view_df() aus dem sjPlot-Paket:\n\nsjPlot::view_df(d_wahl)",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "regression-anova.html#anova",
    "href": "regression-anova.html#anova",
    "title": "1  ANOVA und Regression",
    "section": "1.2 ANOVA",
    "text": "1.2 ANOVA\n\n1.2.1 Mittelwertvergleiche\nMit der ANOVA überprüfen wir den Einfluss einer Gruppen- bzw. Faktor-Variable (kategorial, also nominal oder ordinal mit wenigen Ausprägungen) auf eine metrische Variable, wobei im Gegensatz zum t-Test mehr als zwei Gruppen verglichen werden können. (Für eine ausführlichere Erklärung siehe die Webseite für die BA-Datenanalyse: https://stats.ifp.uni-mainz.de/ba-datenanalyse/t-test.html).\nIn unserem Experiment ist eine der zentralen Annahmen, dass sich die Placementhäufigkeit auf das Persuasionswissen auswirkt.\nZunächst nutzen wir die Funktionen group_by() und summarise(), um Mittelwert, Standardabweichung und Fallzahl für die Variable Persuasionswissen basierend auf den Gruppen der Variable Placementhäufigkeit auszugeben.\n\nd_pp |&gt;\n  group_by(Placementhäufigkeit) |&gt;\n  summarise(\n    M = mean(Persuasionswissen, na.rm = TRUE),\n    SD = sd(Persuasionswissen, na.rm = TRUE),\n    n = n()\n  )\n\n# A tibble: 3 × 4\n  Placementhäufigkeit     M    SD     n\n  &lt;fct&gt;               &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 0 Placements            5 1.58      5\n2 7 Placements           10 2.55      5\n3 15 Placements          12 0.707     5\n\n\nDas Ergebnis zeigen, dass mit zunehmender Placementhäufigkeit der Mittelwert der Zielvariable steigt: Bei 0 Placements liegt er bei M=5, bei 7 Placements bei M=10 und bei 15 Placements bei M=12. Die Standardabweichungen variieren dabei, wobei die Gruppe mit 15 Placements die geringste Streuung aufweist.\n\n\n1.2.2 Einfaktorielle Varianzanalyse\nDie einfaktorielle Varianzanalyse dient dazu, Unterschiede in den Gruppenmittelwerten der abhängigen Variable Persuasionswissen basierend auf den Kategorien der faktoriellen Variable Placementhäufigkeit zu untersuchen.\nNullhypothese H0: Der Mittelwert des Persuasionswissen ist in allen Experimentalbedingungen gleich.\nWir verwenden die Funktion aov(), um die einfaktorielle Varianzanalyse durchzuführen. Die grundlegende Syntax lautet: aov(metrische_variable ~ gruppen_variable, data = Datenframe). Außerdem benutzen wir die report_table()-Funktion, um die Ergebnisse der Varianzanalyse in einer übersichtlichen Tabelle darzustellen. Diese enthält neben F-Wert, Freiheitsgraden und p-Wert auch das Effektstärkemaß Eta².\n\nresults_aov_pp &lt;- aov(Persuasionswissen ~ Placementhäufigkeit, data = d_pp)\n\nresults_aov_pp |&gt;\n  report::report_table()\n\nParameter           | Sum_Squares | df | Mean_Square |     F |      p | Eta2 |  Eta2 95% CI\n-------------------------------------------------------------------------------------------\nPlacementhäufigkeit |      130.00 |  2 |       65.00 | 20.53 | &lt; .001 | 0.77 | [0.51, 1.00]\nResiduals           |       38.00 | 12 |        3.17 |       |        |      |             \n\n\nIn unserem Fall zeigt sich, dass sich die Experimentalgruppen statistisch signifikant hinsichtlich ihres Persuasionswissens (F(2, 12) = 20.53, p &lt; .001) unterscheiden, wobei das Modell mit 77% Varianzaufklärung (Eta² = 0.77) eine große Vorhersagekraft des Antwortverhaltens hat. Wir wissen aber noch nicht, welche Gruppen sich unterschieden. Die Varianzanalyse gibt nur Aufschluss darüber, ob sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Vergleichen wir nur zwei Gruppen, reicht uns dieses Ergebnis schon. Vergleichen wir aber mehr als zwei Gruppen, wollen wir auch wissen, welche Gruppen sich signifikant voneinander unterscheiden. Hierfür benötigen wir Post-Hoc-Tests.\n\n\n1.2.3 Post-Hoc-Tests\nUm zu ermitteln, welche Gruppen sich signifikant voneinander unterscheiden, wird mithilfe von paarweisen Vergleichen und einer Alphafehler-Korrektur vorgegangen. In diesem Fall wird der Bonferroni-Korrekturansatz verwendet, der das Risiko von falsch positiven Ergebnissen verringert.\nMit der Funktion marginaleffects::avg_comparisons() werden paarweise Vergleiche zwischen den Gruppen der Variable Placementhäufigkeit durchgeführt. Die Funktion nimmt das zuvor erstellte ANOVA-Modell als Grundlage, und durch die Option p_adjust = \"bonferroni\" wird sichergestellt, dass die p-Werte entsprechend angepasst werden, um den kumulierten Fehler durch mehrere Tests zu kontrollieren. Die Ergebnisse der paarweisen Vergleiche werden in einem übersichtlichen Format mithilfe von as_tibble() dargestellt.\n\nresults_aov_pp |&gt;\n  marginaleffects::avg_comparisons(\n    variables = list(Placementhäufigkeit = \"pairwise\"),\n    p_adjust = \"bonferroni\"\n  ) |&gt;\n  as_tibble()\n\n# A tibble: 3 × 10\n  term        contrast estimate std.error statistic p.value s.value predicted_lo\n  &lt;chr&gt;       &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n1 Placementh… mean(15…     7         1.13      6.22 1.49e-9   29.3             5\n2 Placementh… mean(15…     2.00      1.13      1.78 2.27e-1    2.14           10\n3 Placementh… mean(7 …     5         1.13      4.44 2.67e-5   15.2             5\n# ℹ 2 more variables: predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nDer Post-hoc-Test zeigt, dass zwischen den Gruppen 0 Placements und 7 Placements sowie zwischen 7 Placements und 15 Placements signifikante Unterschiede im Persuasionswissen bestehen.\n\n\n1.2.4 Modellvorhersagen und -visualisierung\nÄhnlich wie bein dem eben verwendeten Post-Hoc-Test nutzen wir die Funktion marginaleffects::avg_predictions(). Der Unterschied liegt darin, dass hier Modellvorhersagen (predictions) anstelle von Vergleichen (comparisons) berechnet werden.\n\nresults_aov_pp |&gt;\n  marginaleffects::avg_predictions(variables = \"Placementhäufigkeit\") |&gt;\n  as_tibble()\n\n# A tibble: 3 × 8\n  Placementhäufigkeit estimate std.error statistic  p.value s.value conf.low\n  &lt;fct&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 0 Placements               5     0.796      6.28 3.33e-10    31.5     3.44\n2 7 Placements              10     0.796     12.6  3.26e-36   118.      8.44\n3 15 Placements             12     0.796     15.1  2.23e-51   168.     10.4 \n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nWir sehen, dass das Persuasionswissen signifikant ansteigt, wenn die Anzahl der Placements erhöht wird. Dies deutet darauf hin, dass eine größere Anzahl an Placements mit einer höheren Wahrscheinlichkeit verbunden ist, dass die Rezipienten das Persuasionswissen aufnehmen. Die p-Werte sind alle signifikant (p &lt; 0.001).\nFür die Visualisierung erstellen wir nun mit ggplot() und geom_pointrange() eine Visualisierung der Mittelwerte und dazugehörigen Konfidenzintervalle von den Modellvorhersage pro Gruppe. Die x-Achse zeigt die Placementhäufigkeit, während die y-Achse die geschätzten Vorhersagen für das Persuasionswissen darstellt. Mit geom_pointrange() werden Punkte für die geschätzten Mittelwerte und vertikale Linien für die Konfidenzintervalle gezeichnet. So können wir erkennen, wie das Persuasionswissen je nach Placementhäufigkeit variiert und wie präzise diese Schätzungen sind.\n\nresults_aov_pp |&gt;\n  marginaleffects::avg_predictions(variables = \"Placementhäufigkeit\") |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = Placementhäufigkeit, y = estimate,\n    ymin = conf.low, ymax = conf.high\n  )) +\n  geom_pointrange() +\n  labs(x = \"Placementhäufigkeit\", y = \"Vorhergesagtes Persuasionswissen\")",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "regression-anova.html#regression",
    "href": "regression-anova.html#regression",
    "title": "1  ANOVA und Regression",
    "section": "1.3 Regression",
    "text": "1.3 Regression\n\n1.3.1 ANOVA = Regression\nWenn wir den Zusammenhang zwischen zwei metrischen Variablen, wie Placementhäufigkeit und Persuasionswissen, untersuchen wollen, können wir eine lineare Regression durchführen.\nNullhypothese H0: Die Placementhäufigkeit hat keinen Einfluss auf das Persuasionswissen.\nLineare Regression werden mit der Funktion lm() durchgeführt, wobei die Syntax lm(abhängige_variable ~ unabhängige_variable, data = Datenframe) der von aov() für Mittelwertvergleiche entspricht. Wir führen die Regression durch und speichern das Ergebnis im Objekt results_lm_pp.\nMit summary() erhalten wir eine Zusammenfassung des Regressionsmodells, die wichtige Informationen wie die Koeffizienten der unabhängigen Variablen, die Signifikanzniveaus (p-Werte), das Bestimmtheitsmaß (R-Quadrat) und weitere statistische Kennzahlen enthält.\n\nresults_lm_pp &lt;- lm(Persuasionswissen ~ Placementhäufigkeit, data = d_pp)\n\nresults_lm_pp |&gt;\n  summary()\n\n\nCall:\nlm(formula = Persuasionswissen ~ Placementhäufigkeit, data = d_pp)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n    -3     -1      0      1      3 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                        5.0000     0.7958   6.283 4.05e-05 ***\nPlacementhäufigkeit7 Placements    5.0000     1.1255   4.443 0.000803 ***\nPlacementhäufigkeit15 Placements   7.0000     1.1255   6.220 4.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.78 on 12 degrees of freedom\nMultiple R-squared:  0.7738,    Adjusted R-squared:  0.7361 \nF-statistic: 20.53 on 2 and 12 DF,  p-value: 0.0001339\n\n\nFür einen Output in einer übersichtlichen Tabelle nutzen wir wieder report_table().\n\nresults_lm_pp |&gt;\n  report::report_table()\n\nParameter                           | Coefficient |       95% CI | t(12) |      p | Std. Coef. | Std. Coef. 95% CI |   Fit\n--------------------------------------------------------------------------------------------------------------------------\n(Intercept)                         |        5.00 | [3.27, 6.73] |  6.28 | &lt; .001 |      -1.15 |    [-1.66, -0.65] |      \nPlacementhäufigkeit [7 Placements]  |        5.00 | [2.55, 7.45] |  4.44 | &lt; .001 |       1.44 |    [ 0.74,  2.15] |      \nPlacementhäufigkeit [15 Placements] |        7.00 | [4.55, 9.45] |  6.22 | &lt; .001 |       2.02 |    [ 1.31,  2.73] |      \n                                    |             |              |       |        |            |                   |      \nAIC                                 |             |              |       |        |            |                   | 64.51\nAICc                                |             |              |       |        |            |                   | 68.51\nBIC                                 |             |              |       |        |            |                   | 67.34\nR2                                  |             |              |       |        |            |                   |  0.77\nR2 (adj.)                           |             |              |       |        |            |                   |  0.74\nSigma                               |             |              |       |        |            |                   |  1.78\n\n\nWir erkennen am 95%-CI, das nicht die Null enthält, oder am p-Wert (p &lt; .001), dass die Placementhäufigkeit das Persuasionswissen statistisch signifikant vorhersagt. Der standardisierte Regressionskoeffizient entspricht für 7 Placements r = 1.44 und für 15 Placements r = 2.02. Basierend auf Cohen (1988) kann man also bei beiden von einem starken Effekt sprechen. Das R-Quadrat beträgt einen Wert von R²=.77, d.h. unser Regressionsmodell kann 77% der Varianz in der Variable Persuasionswissen vorhersagen.\nWir verwenden wieder die Funktion marginaleffects::avg_predictions() zur Berechnung der durchschnittlichen Vorhersagen für das Persuasionswissen in Bezug auf die Placementhäufigkeit. Diese mal aber basierend auf dem Regressionsmodell results_lm_pp. Diese Vorhersagen geben Aufschluss darüber, wie sich das Persuasionswissen im Durchschnitt verändert, wenn sich die Placementhäufigkeit ändert, und helfen dabei, die Auswirkungen davon anschaulich zu verstehen.\n\nresults_lm_pp |&gt;\n  marginaleffects::avg_predictions(variables = \"Placementhäufigkeit\") |&gt;\n  as_tibble()\n\n# A tibble: 3 × 8\n  Placementhäufigkeit estimate std.error statistic  p.value s.value conf.low\n  &lt;fct&gt;                  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1 0 Placements               5     0.796      6.28 3.33e-10    31.5     3.44\n2 7 Placements              10     0.796     12.6  3.26e-36   118.      8.44\n3 15 Placements             12     0.796     15.1  2.23e-51   168.     10.4 \n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nAuch hier zeigt der Output, dass das Persuasionswissen im Durchschnitt signifikant ansteigt, wenn die Anzahl der Placements erhöht wird.\n\n\n1.3.2 Multiple Regression\nMit der lm()-Funktion können wir auch multiple Regressionen berechnen, bei denen es mehr als eine unabhängige Variable gibt. Die Syntax ist identisch, es werden einfach die Variablen mit + verbunden.\nHier benutzen wir den Datensatz der Wahlabsicht und schauen, ob die Wahlabsicht vom Sex, Bildung, Einkommen, Politische Wertorientierung, Wirksamkeitserwartung beeinflusst wird. Wir führen die Multiple Regression durch und speichern das Ergebnis im Objekt results_wahl_1 um anschließend wieder report_table()zu verwenden.\n\nresults_wahl_1 &lt;- lm(\n  Wahlabsicht ~ Sex + Bildung + Einkommen +\n    PolitischeWertorientierung + Wirksamkeitserwartung,\n  data = d_wahl\n)\nresults_wahl_1 |&gt;\n  report::report_table()\n\nParameter                  | Coefficient |        95% CI | t(150) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n--------------------------------------------------------------------------------------------------------------------\n(Intercept)                |        0.99 | [ 0.40, 1.58] |   3.32 | 0.001  |   6.91e-03 |     [-0.13, 0.14] |       \nSex [weiblich]             |       -0.04 | [-0.35, 0.26] |  -0.27 | 0.789  |      -0.05 |     [-0.43, 0.33] |       \nBildung                    |        0.19 | [ 0.09, 0.28] |   3.76 | &lt; .001 |       0.26 |     [ 0.12, 0.40] |       \nEinkommen                  |        0.09 | [-0.01, 0.18] |   1.80 | 0.074  |       0.12 |     [-0.01, 0.26] |       \nPolitischeWertorientierung |        0.03 | [-0.07, 0.13] |   0.55 | 0.581  |       0.04 |     [-0.10, 0.17] |       \nWirksamkeitserwartung      |        0.40 | [ 0.27, 0.53] |   6.29 | &lt; .001 |       0.44 |     [ 0.30, 0.57] |       \n                           |             |               |        |        |            |                   |       \nAIC                        |             |               |        |        |            |                   | 316.56\nAICc                       |             |               |        |        |            |                   | 317.32\nBIC                        |             |               |        |        |            |                   | 337.91\nR2                         |             |               |        |        |            |                   |   0.36\nR2 (adj.)                  |             |               |        |        |            |                   |   0.34\nSigma                      |             |               |        |        |            |                   |   0.65\n\n\nWir erkennen, dass nur die Bildung und die Wirksamkeitserwartung die Wahlabsicht beeinflussen. Bei der Bildung zeigt sich ein positiver Einfluss mit einem Koeffizienten von 0.19, was bedeutet, dass jeder zusätzliche Punkt in der Bildung zu einem Anstieg der Wahlabsicht um 0.19 Skalenpunkte führt. Dieser Effekt ist signifikant (p &lt; 0.001). Die Wirksamkeitserwartung hat einen noch stärkeren Einfluss auf die Wahlabsicht, mit einem Koeffizienten von 0.40. Das bedeutet, dass ein höheres Maß an Wirksamkeitserwartung mit einem Anstieg der Wahlabsicht um 0.40 Skalenpunkte verbunden ist. Auch dieser Effekt ist signifikant (p &lt; 0.001). Im Gegensatz dazu zeigen die Variablen Sex, Einkommen und politische Wertorientierung keinen signifikanten Einfluss auf die Wahlabsicht, da ihre p-Werte über 0.05 liegen. Die Vorhersagequalität unseres Modells liegt bei einem R-Quadrat von R²=.34, was darauf hinweist, dass die Prädiktoren zusammen etwa 34% der Varianz der Wahlabsicht erklären.\nNun führen wir wieder eine multiple Regressionen durch, aber ergänzen noch Qualitätsmedien und Boulevardmedien als Variablen.\n\nresults_wahl_2 &lt;- lm(\n  Wahlabsicht ~ Sex + Bildung + Einkommen +\n    PolitischeWertorientierung + Wirksamkeitserwartung +\n    Qualitätsmedien + Boulevardmedien,\n  data = d_wahl\n)\nresults_wahl_2 |&gt;\n  report::report_table()\n\nParameter                  | Coefficient |         95% CI | t(148) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n---------------------------------------------------------------------------------------------------------------------\n(Intercept)                |        1.94 | [ 1.26,  2.62] |   5.62 | &lt; .001 |      -0.02 |    [-0.13,  0.10] |       \nSex [weiblich]             |        0.09 | [-0.16,  0.35] |   0.73 | 0.466  |       0.12 |    [-0.20,  0.44] |       \nBildung                    |        0.15 | [ 0.06,  0.23] |   3.45 | &lt; .001 |       0.20 |    [ 0.09,  0.32] |       \nEinkommen                  |        0.02 | [-0.07,  0.10] |   0.42 | 0.674  |       0.03 |    [-0.09,  0.14] |       \nPolitischeWertorientierung |    3.12e-03 | [-0.08,  0.09] |   0.07 | 0.943  |   4.17e-03 |    [-0.11,  0.12] |       \nWirksamkeitserwartung      |        0.21 | [ 0.10,  0.33] |   3.60 | &lt; .001 |       0.23 |    [ 0.10,  0.36] |       \nQualitätsmedien            |        0.19 | [ 0.11,  0.28] |   4.36 | &lt; .001 |       0.26 |    [ 0.14,  0.38] |       \nBoulevardmedien            |       -0.22 | [-0.29, -0.15] |  -6.01 | &lt; .001 |      -0.39 |    [-0.52, -0.26] |       \n                           |             |                |        |        |            |                   |       \nAIC                        |             |                |        |        |            |                   | 262.68\nAICc                       |             |                |        |        |            |                   | 263.92\nBIC                        |             |                |        |        |            |                   | 290.13\nR2                         |             |                |        |        |            |                   |   0.56\nR2 (adj.)                  |             |                |        |        |            |                   |   0.54\nSigma                      |             |                |        |        |            |                   |   0.54\n\n\nHier sehen wir, dass die Bildung, die Wirksamkeitserwartung, wie auch Qualitätsmedien und Boulevardmedien statistisch signifikant die Wahlabsicht beeinflussen (p &lt; 0.001).\n\n\n1.3.3 Modellvergleich\nOb Modell 2 signifikant mehr Varianz im politischen Wissen erklären kann als Modell 1, zeigt der partielle F-Test, der mit der anova()-Funktion durchgeführt wird. Funktionsargumente sind die beiden Modelle, die verglichen werden sollen.\n\nanova(results_wahl_1, results_wahl_2)\n\nAnalysis of Variance Table\n\nModel 1: Wahlabsicht ~ Sex + Bildung + Einkommen + PolitischeWertorientierung + \n    Wirksamkeitserwartung\nModel 2: Wahlabsicht ~ Sex + Bildung + Einkommen + PolitischeWertorientierung + \n    Wirksamkeitserwartung + Qualitätsmedien + Boulevardmedien\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1    150 63.528                                  \n2    148 43.836  2    19.692 33.242 1.192e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDie Residualvarianz von Modell 2 ist signifikant kleiner, bzw. die erklärte Varianz signifikant größer als bei Modell 1. Durch das Hinzufügen der Variablen Qualitätsmedien und Boulevardmedien hat sich die Modellgüte deutlich verbessert.\n\n\n1.3.4 Modellannahmen\nFür die Prüfung der klassischen OLS-Annahmen wie Linearität, Normalverteilung der Residuen, Homoskedastizität und Multikollinearität gibt es im performance-Paket eine Sammelfunktion, die schlicht check_model() heißt.\n\nchecks &lt;- performance::check_model(results_wahl_2, panel = F)\nplot(checks)\n\n$PP_CHECK\n\n\n\n\n\n\n\n\n\n\n$NCV\n\n\n\n\n\n\n\n\n\n\n$HOMOGENEITY\n\n\n\n\n\n\n\n\n\n\n$OUTLIERS\n\n\n\n\n\n\n\n\n\n\n$VIF\n\n\n\n\n\n\n\n\n\n\n$QQ\n\n\n\n\n\n\n\n\n\n\n\n1.3.5 Modellvorhersagen\nUm aus Regressionsmodellen in R Vorhersagen zu generieren, benutzen wir die Funktion avg_predictions() aus dem marginaleffects-Paket. Dabei erhalten wir für eine oder mehrere Prädiktorvariablen vorhergesagte Werte des Outcomes. Dabei werden für kategorielle Variablen die Vorhersagen für jede Ausprägung aggregiert, für metrische über (typische) Einzelwerte.\n\nresults_wahl_2 |&gt;\n  marginaleffects::avg_predictions(variables = \"Boulevardmedien\") |&gt;\n  as_tibble()\n\n# A tibble: 5 × 8\n  Boulevardmedien estimate std.error statistic   p.value s.value conf.low\n            &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1               5     2.64    0.104       25.3 1.42e-141    468.     2.43\n2               1     3.52    0.0685      51.4 0            Inf      3.39\n3               4     2.86    0.0723      39.5 0            Inf      2.72\n4               3     3.08    0.0483      63.8 0            Inf      2.98\n5               2     3.30    0.0464      71.1 0            Inf      3.21\n# ℹ 1 more variable: conf.high &lt;dbl&gt;\n\n\nDie Tabelle zeigt die Vorhersagen für die Wahlabsicht in Abhängigkeit von der Nutzung von Boulevardmedien. Für jede Ausprägung der Boulevardmediennutzung wird ein geschätzter Wert der Wahlabsicht (estimate) angegeben. Diese Schätzungen werden mit dem jeweiligen Standardfehler (std.error), der Teststatistik (statistic) und dem p-Wert (p.value) präsentiert. Die Konfidenzintervalle (conf.low, conf.high) geben an, in welchem Bereich der wahre Wert der Wahlabsicht mit hoher Wahrscheinlichkeit liegt. Höhere Boulevardmediennutzung ist mit einer niedrigeren Wahlabsicht verbunden.\n\n\n1.3.6 Modellvisualisierung\nDie Vorhersagen für metrische Prädiktoren lassen sich am besten als Regressionsgerade samt Konfidenzband visualisieren, d.h. geom_line() und geom_ribbon(). Das Konfidenzband wird fast transparent dargestellt (alpha = .1). Auf der X-Achse ist die Prädiktorvariable, auf der Y-Achse die vorhergesagten Werte.\n\nresults_wahl_2 |&gt;\n  marginaleffects::avg_predictions(variables = \"Boulevardmedien\") |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = Boulevardmedien, y = estimate,\n    ymin = conf.low, ymax = conf.high\n  )) +\n  geom_line() +\n  geom_ribbon(alpha = .1) +\n  labs(x = \"Nutzungshäufigkeit Boulevardmedien\", y = \"Vorhergesagte Wahlabsicht\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeiterführende Materialien\n\n\n\nWeitere detaillierte Beispiele mit R-Code und Daten finden sich in den Materialien zur Vorlesung Anwendungsorientierte Analyseverfahren, u.a. zu\n\nkategoriellen und metrischen Prädiktorvariablen\nmultipler Regression und Regressionsannahmen\nModellvorhersagen und -visualisierungen",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "regression-anova.html#glossar",
    "href": "regression-anova.html#glossar",
    "title": "1  ANOVA und Regression",
    "section": "1.4 Glossar",
    "text": "1.4 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nanova\nModellvergleich und partieller F-Test\n\n\nlm\nLineares Regressionsmodell schätzen\n\n\nmarginaleffects::avg_comparisons\nModellkontraste und Posthoc-Tests berechnen\n\n\nmarginaleffects::avg_predictions\nModellvorhersagen berechnen\n\n\nperformance::check_performance\nModellannahmen prüfen",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "regression-anova.html#hausaufgabe",
    "href": "regression-anova.html#hausaufgabe",
    "title": "1  ANOVA und Regression",
    "section": "1.5 Hausaufgabe",
    "text": "1.5 Hausaufgabe\nIn einer Studie wurde untersucht, welche Merkmale Vorurteile gegenüber Asylsuchenden bei Befragten beeinflussen (Datensatz asyl.sav).\n\nUntersuchen sie den Zusammenhang von Demographie (Geschlecht, Alter, Bildung), politischen Überzeugungen (allg. politisches Interesse, Ideologie (links-rechts-Selbsteinschätzung, Autoritarismus, Wahrnehmung negativer Mediendarstellungen) und Vorurteilen gegenüber Asylsuchenden.\nIdentifizieren, interpretieren und visualisieren sie den stärksten Effekt aus dem Regressionsmodell.",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ANOVA und Regression</span>"
    ]
  },
  {
    "objectID": "moderation-interaktionen.html",
    "href": "moderation-interaktionen.html",
    "title": "2  Moderationsanalyse",
    "section": "",
    "text": "2.1 Pakete und Daten\nZunächst laden wir das marginaleffects- sowie das tidyverse- und das report-Paket.\nlibrary(marginaleffects)\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nFür die Moderationsanalyse benötigen wir den SPSS-Datensatz productplacement_moderation.sav. Mit der mutate-Funktion passen wir zwei Variablen an: Die Variable Placementhäufigkeit wird in einen Faktor umgewandelt und ungenutzte Kategorien werden mit fct_drop() entfernt. Ebenso wird die Variable Involvement in einen Faktor umgewandelt. Schließlich entfernt die Funktion zap_labels() die SPSS-Labels, um die Daten ohne zusätzliche Kennzeichnungen zu verwenden. Der Datensatz enthält 6 Spalten. eine laufende Nummer (lfdn), Placementhäufigkeit, Involvement, Bekanntheit und Störempfinden.\nd_pp2 &lt;- haven::read_sav(\"data/productplacement_moderation.sav\") |&gt;\n  mutate(\n    Placementhäufigkeit = as_factor(Placementhäufigkeit) |&gt; fct_drop(),\n    Involvement = as_factor(Involvement)\n  ) |&gt;\n  haven::zap_labels() |&gt;\n  select(-onefaktor)\nd_pp2\n\n# A tibble: 82 × 5\n   lfdn Placementhäufigkeit Involvement Bekanntheit Störempfinden\n  &lt;dbl&gt; &lt;fct&gt;               &lt;fct&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1    72 7 Placements        niedrig               1       -0.0529\n2    64 7 Placements        niedrig               1       -1.29  \n3    65 7 Placements        niedrig               4       -0.362 \n4    66 7 Placements        niedrig               1       -0.982 \n5    63 7 Placements        niedrig               1       -0.672 \n# ℹ 77 more rows",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Moderationsanalyse</span>"
    ]
  },
  {
    "objectID": "moderation-interaktionen.html#kategorieller-moderator",
    "href": "moderation-interaktionen.html#kategorieller-moderator",
    "title": "2  Moderationsanalyse",
    "section": "2.2 Kategorieller Moderator",
    "text": "2.2 Kategorieller Moderator\nWir untersuchen, wie sich das Störempfinden je nach den Kategorien von Placementhäufigkeit (7 oder 15) und Involvement (hoch/niedrig) verändert. Die Variable Involvement ist hier der kategorialer Moderator.\nAls Erstes gruppieren wir mit group_by den Datensatz basierend auf den Kategorien von Placementhäufigkeit und Involvement und berechnen den Mittelwert, die Standardabweichung und die Anzahl der Beobachtungen für das Störempfinden in jeder Gruppe.\n\nd_pp2 |&gt;\n  group_by(Placementhäufigkeit, Involvement) |&gt;\n  summarise(\n    M = mean(Störempfinden, na.rm = TRUE),\n    SD = sd(Störempfinden, na.rm = TRUE),\n    n = n()\n  )\n\n# A tibble: 4 × 5\n# Groups:   Placementhäufigkeit [2]\n  Placementhäufigkeit Involvement       M    SD     n\n  &lt;fct&gt;               &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 7 Placements        niedrig     -0.348  0.638    21\n2 7 Placements        hoch         0.0864 0.955    20\n3 15 Placements       niedrig      0.675  1.28     20\n4 15 Placements       hoch         0.0355 1.22     21\n\n\nDer Output zeigt, dass bei 7 Placements die Gruppe mit niedrigem Involvement ein geringeres Störempfinden hat als die mit hohem Involvement. Bei 15 Placements ist das Störempfinden in der Gruppe mit niedrigem Involvement höher, während es bei hohem Involvement deutlich niedriger bleibt.\n\n2.2.1 Zweifaktorielle ANOVA und moderierte Regression\nFür die zweifaktorielle ANOVA verwenden wir die Funktion aov(). Um eine Interaktion herzustellen benutzen wir das Sternchen (*), was bedeutet, dass neben den Haupteffekten der einzelnen Variablen auch deren gemeinsamer Einfluss auf die abhängige Variable, in diesem Fall das Störempfinden, untersucht wird. Wie immer kommt zum Schluss die report_table()-Funktion. Wir führen die zweifaktorielle ANOVA durch und speichern das Ergebnis im Objekt results_aov_involve.\n\nresults_aov_involve &lt;- aov(Störempfinden ~ Placementhäufigkeit * Involvement, data = d_pp2)\nreport::report_table(results_aov_involve)\n\nParameter                       | Sum_Squares | df | Mean_Square |    F |     p | Eta2 (partial) | Eta2_partial 95% CI\n----------------------------------------------------------------------------------------------------------------------\nPlacementhäufigkeit             |        4.79 |  1 |        4.79 | 4.32 | 0.041 |           0.05 |        [0.00, 1.00]\nInvolvement                     |        0.22 |  1 |        0.22 | 0.19 | 0.661 |       2.48e-03 |        [0.00, 1.00]\nPlacementhäufigkeit:Involvement |        5.90 |  1 |        5.90 | 5.32 | 0.024 |           0.06 |        [0.00, 1.00]\nResiduals                       |       86.50 | 78 |        1.11 |      |       |                |                    \n\n\nIn unserem Fall zeigt sich, dass sich die Gruppen hinsichtlich ihres Störempfindens aufgrund der Placementhäufigkeit statistisch signifikant unterscheiden (F(1, 78) = 4.32, p = .041), nicht jedoch nach Involvement. Relevant ist nun die Interaktion zwischen Placementhäufigkeit und Involvement (F(1, 78) = 5.32, p = .024), was darauf hinweist, dass der Effekt der Placementhäufigkeit auf das Störempfinden je nach Involvement-Level unterschiedlich ausfällt.\nUm eine moderierte Regression zu berechnen verwenden wir die lm()-Funktion und wie auch bei der zweifaktoriellen ANOVA wird hier die Interaktion durch das Sternchen (*) angezeigt. Wie gewohnt kommt die report_table()-Funktion und das Ergbenis wird in dem Objekt results_involvegespeichert. Wie wir bereits gesehen haben, sind ANOVA und Regression statistisch identisch, wir bekommen lediglich einige andere Koeffizienten angezeigt.\n\nresults_involve &lt;- lm(Störempfinden ~ Placementhäufigkeit * Involvement, data = d_pp2)\nreport::report_table(results_involve)\n\nParameter                                                | Coefficient |         95% CI | t(78) |     p | Std. Coef. | Std. Coef. 95% CI |    Fit\n-------------------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                                              |       -0.35 | [-0.81,  0.11] | -1.51 | 0.134 |      -0.41 |    [-0.83,  0.00] |       \nPlacementhäufigkeit [15 Placements]                      |        1.02 | [ 0.37,  1.68] |  3.11 | 0.003 |       0.93 |    [ 0.33,  1.53] |       \nInvolvement [hoch]                                       |        0.43 | [-0.22,  1.09] |  1.32 | 0.191 |       0.40 |    [-0.20,  0.99] |       \nPlacementhäufigkeit [15 Placements] × Involvement [hoch] |       -1.07 | [-2.00, -0.15] | -2.31 | 0.024 |      -0.98 |    [-1.82, -0.13] |       \n                                                         |             |                |       |       |            |                   |       \nAIC                                                      |             |                |       |       |            |                   | 247.09\nAICc                                                     |             |                |       |       |            |                   | 247.88\nBIC                                                      |             |                |       |       |            |                   | 259.12\nR2                                                       |             |                |       |       |            |                   |   0.11\nR2 (adj.)                                                |             |                |       |       |            |                   |   0.08\nSigma                                                    |             |                |       |       |            |                   |   1.05\n\n\nBei der moderierten Regression werden grundsätzlich konditionale Effekte ausgegeben, d.h. für jede Variable, die im Interaktionsterm enthalten ist, gilt: Die ist der Effekt, wenn die jeweils andere Variable Null ist bzw. bei kategoriellen Variablen die Referenzgruppe. Betrachten wir zunächst die Placementhäufigkeit: Wir sehen am 95%-Konfidenzintervall, dass der Wert Null nicht enthalten ist, sowie am p-Wert (p = .003), dass die Placementhäufigkeit das Störempfinden signifikant vorhersagt, wenn das Involvement niedrig ist (Referenzgruppe, konditionaler Effekt). Der konditionale Effekt von Involvement bei wenig Placements (konditionaler Effekt) ist nicht signifikant. Zusätzlich zeigt die signifikante Interaktion zwischen Placementhäufigkeit und Involvement (p = .024), dass der Effekt der Placementhäufigkeit auf das Störempfinden durch das Niveau des Involvements moderiert wird (und umgekehrt). Das bedeutet, dass der Einfluss von Placementhäufigkeit auf das Störempfinden je nach Involvement unterschiedlich stark ausgeprägt ist. Das R-Quadrat beträgt R²=.11, was bedeutet, dass unser Modell etwa 11% der Varianz im Störempfinden erklärt.\n\n\n2.2.2 Durchschnittliche Effekte: AME\nZur Interpretation der (unkonditionalen bzw. marginalen) Haupteffekte nutzen wir die Funktion avg_slopes(). Diese Funktion berechnet den Average Marginal Effect (AME). Das bedeutet, dass die Funktion für jeden Fall (= Person) in der Stichprobe den Effekt der Prädiktoren auf die abhängige Variable berechnet. Anschließend wird der Durchschnitt gebildet. Auf diese Weise erhalten wir den durchschnittlichen Effekt eines Prädiktors über alle Werte der Moderationsvariable in der Stichprobe.\n\nmarginaleffects::avg_slopes(results_involve) |&gt;\n  as_tibble()\n\n# A tibble: 2 × 12\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Invo… mean(ho…   -0.102     0.233    -0.440  0.660    0.600  -0.558      0.354\n2 Plac… mean(15…    0.486     0.233     2.09   0.0368   4.76    0.0297     0.942\n# ℹ 3 more variables: predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nDiese AME entsprechen denen des unkonditionalen Modells, also ohne Interaktionsterm, welches nun berechnet wird. Es betrachtet die Haupteffekte von Placementhäufigkeit und Involvement separat und unabhängig voneinander auf Störempfinden, ohne eine Interaktion zwischen den Variablen zu berücksichtigen. Wir benutzen wie bei einer ganz normalen multiple Regression die lm()-, und report_table()-Funktionen.\n\nlm(Störempfinden ~ Placementhäufigkeit + Involvement, data = d_pp2) |&gt;\n  report::report_table()\n\nParameter                           | Coefficient |        95% CI | t(79) |     p | Std. Coef. | Std. Coef. 95% CI |    Fit\n---------------------------------------------------------------------------------------------------------------------------\n(Intercept)                         |       -0.09 | [-0.49, 0.32] | -0.42 | 0.676 |      -0.17 |     [-0.55, 0.20] |       \nPlacementhäufigkeit [15 Placements] |        0.49 | [ 0.01, 0.96] |  2.03 | 0.045 |       0.44 |     [ 0.01, 0.88] |       \nInvolvement [hoch]                  |       -0.10 | [-0.58, 0.37] | -0.43 | 0.669 |      -0.09 |     [-0.53, 0.34] |       \n                                    |             |               |       |       |            |                   |       \nAIC                                 |             |               |       |       |            |                   | 250.50\nAICc                                |             |               |       |       |            |                   | 251.02\nBIC                                 |             |               |       |       |            |                   | 260.12\nR2                                  |             |               |       |       |            |                   |   0.05\nR2 (adj.)                           |             |               |       |       |            |                   |   0.03\nSigma                               |             |               |       |       |            |                   |   1.08\n\n\nAn dem Output sehen wir, dass der Effekt der Placementhäufigkeit auf das Störempfinden statistisch signifikant ist, da der p-Wert (p = .045) unter 0.05 liegt und das 95%-Konfidenzintervall (CI) den Nullpunkt nicht enthält.Involvement hingegen zeigt keinen signifikanten Einfluss auf das Störempfinden (p = .669). Die Punktschätzer entsprechen den AME aus dem moderierten Regressionsmodell.\n\n\n2.2.3 Konditionale Effekte nach Gruppen\nMit dem Funktionsargument by können wir die konditionalen Effekte für Placementhäufigkeit in Abhängigkeit von Involvement berechnen, zudem verwenden wir das gespeicherte Ergebnis results_involve aus der moderierten Regression.\n\nmarginaleffects::avg_slopes(results_involve,\n  variables = \"Placementhäufigkeit\", by = \"Involvement\"\n) |&gt;\n  as_tibble()\n\n# A tibble: 2 × 13\n  term         contrast Involvement estimate std.error statistic p.value s.value\n  &lt;chr&gt;        &lt;chr&gt;    &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Placementhä… mean(15… niedrig       1.02       0.329     3.11  0.00189   9.05 \n2 Placementhä… mean(15… hoch         -0.0509     0.329    -0.155 0.877     0.189\n# ℹ 5 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;,\n#   predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nDas Ergebnis zeigt uns, dass bei niedrigem Involvement ein starker positiver Effekt der Placementhäufigkeit zu erkennen ist (B = 1.02), während sich bei hohem Involvement praktisch kein Effekt zeigt (B = -0.0509).\n\n\n2.2.4 Modellvorhersagen und -visualisierung\nFür die Modellvorhersagen verwenden wir wieder die Funktion avg_predictions() und nehmen Placementhäufigkeit und Involvement als unsere Variablen.\n\nmarginaleffects::avg_predictions(results_involve,\n  variables = c(\"Placementhäufigkeit\", \"Involvement\")\n) |&gt;\n  as_tibble()\n\n# A tibble: 4 × 9\n  Placementhäufigkeit Involvement estimate std.error statistic p.value s.value\n  &lt;fct&gt;               &lt;fct&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 7 Placements        niedrig      -0.348      0.230    -1.51  0.130     2.94 \n2 15 Placements       niedrig       0.675      0.235     2.86  0.00418   7.90 \n3 7 Placements        hoch          0.0864     0.235     0.367 0.714     0.487\n4 15 Placements       hoch          0.0355     0.230     0.155 0.877     0.189\n# ℹ 2 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;\n\n\nAnschaulicher wird es, wenn wir diese Vorhersagen auch grafisch darstellen.\n\nmarginaleffects::avg_predictions(results_involve,\n  variables = c(\"Placementhäufigkeit\", \"Involvement\")\n) |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = Placementhäufigkeit, y = estimate,\n    ymin = conf.low, ymax = conf.high,\n    group = Involvement, color = Involvement\n  )) +\n  geom_pointrange(position = position_dodge(.5)) +\n  geom_line(position = position_dodge(.5)) +\n  labs(y = \"Vorhergesagtes Störempfinden\")",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Moderationsanalyse</span>"
    ]
  },
  {
    "objectID": "moderation-interaktionen.html#metrischer-moderator",
    "href": "moderation-interaktionen.html#metrischer-moderator",
    "title": "2  Moderationsanalyse",
    "section": "2.3 Metrischer Moderator",
    "text": "2.3 Metrischer Moderator\nWie bei der Moderationsanalyse mit dem kategoriellen Moderator verwenden wir die lm()-Funktion und benutzen das Sternchen (*) für die Interaktion. Dieses mal wird jedoch die metrische Variable Bekanntheit als Moderator genommen.\n\nresults_bekannt &lt;- lm(Störempfinden ~ Placementhäufigkeit * Bekanntheit, data = d_pp2)\nreport::report_table(results_bekannt)\n\nParameter                                         | Coefficient |        95% CI | t(78) |     p | Std. Coef. | Std. Coef. 95% CI |    Fit\n-----------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                                       |       -0.33 | [-0.99, 0.33] | -1.00 | 0.322 |      -0.22 |     [-0.52, 0.09] |       \nPlacementhäufigkeit [15 Placements]               |        1.24 | [ 0.29, 2.19] |  2.59 | 0.011 |       0.45 |     [ 0.02, 0.88] |       \nBekanntheit                                       |        0.11 | [-0.22, 0.45] |  0.68 | 0.501 |       0.10 |     [-0.20, 0.41] |       \nPlacementhäufigkeit [15 Placements] × Bekanntheit |       -0.42 | [-0.89, 0.05] | -1.79 | 0.077 |      -0.39 |     [-0.82, 0.04] |       \n                                                  |             |               |       |       |            |                   |       \nAIC                                               |             |               |       |       |            |                   | 248.67\nAICc                                              |             |               |       |       |            |                   | 249.45\nBIC                                               |             |               |       |       |            |                   | 260.70\nR2                                                |             |               |       |       |            |                   |   0.09\nR2 (adj.)                                         |             |               |       |       |            |                   |   0.06\nSigma                                             |             |               |       |       |            |                   |   1.06\n\n\nEs zeigt sich, dass eine höhere Placementhäufigkeit (15 Placements) einen signifikant positiven Einfluss auf das Störempfinden hat (B = 1.24, p = .011). Die Bekanntheit alleine hat keinen signifikanten Einfluss (p = .501), und der Interaktionseffekt von Placementhäufigkeit und Bekanntheit ist auch nicht signifikant (B = -0.42, p = .077). Wir stellen fest, dass eine höhere Anzahl an Placements das Störempfinden steigert, jedoch nicht durch die Bekanntheit moderiert wird.\n\n2.3.1 Durchschnittliche Effekte: AME\nWir wiederholen an dieser Stelle das Vorgehen aus dem vorherigen Kapitel und berechnen die Haupteffekte mittels avg_slopes().\n\nmarginaleffects::avg_slopes(results_bekannt) |&gt;\n  as_tibble()\n\n# A tibble: 2 × 12\n  term  contrast estimate std.error statistic p.value s.value conf.low conf.high\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Beka… mean(dY…  -0.0991     0.118    -0.839  0.402     1.32  -0.331      0.133\n2 Plac… mean(15…   0.493      0.235     2.10   0.0361    4.79   0.0320     0.954\n# ℹ 3 more variables: predicted_lo &lt;dbl&gt;, predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nDie Berechnungen zeigen einen negativen Effekt der Bekanntheit (B = -0.0991), der jedoch statistisch nicht signifikant ist (p = .402). Im Gegensatz dazu weist die höhere Placementhäufigkeit (15 Placements) einen positiven und statistisch signifikanten Effekt auf das Störempfinden auf (B = 0.493, p = .0361).\n\n\n2.3.2 Konditionale Effekte: Zentrierung\nAls erstes wird die Variable mit der scale()-Funktion zentriert, das heißt, der Mittelwert wird abgezogen, um die zentrierte Variable Bekanntheit_c zu erhalten. Dann wiederholen wir den Schritt der Moderationsanalyse mit dem metrischen Moderator, nur dass wir jetzt die zentrierte Bekanntheit als Moderator verwenden.\n\nd_pp2 &lt;- d_pp2 |&gt;\n  mutate(Bekanntheit_c = scale(Bekanntheit, scale = F))\n\nlm(Störempfinden ~ Placementhäufigkeit * Bekanntheit_c, data = d_pp2) |&gt;\n  report::report_table()\n\nParameter                                           | Coefficient |        95% CI | t(78) |     p | Std. Coef. | Std. Coef. 95% CI |    Fit\n-------------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                                         |       -0.13 | [-0.46, 0.20] | -0.78 | 0.435 |      -0.22 |     [-0.52, 0.09] |       \nPlacementhäufigkeit [15 Placements]                 |        0.49 | [ 0.02, 0.96] |  2.10 | 0.039 |       0.45 |     [ 0.02, 0.88] |       \nBekanntheit c                                       |        0.11 | [-0.22, 0.45] |  0.68 | 0.501 |       0.10 |     [-0.20, 0.41] |       \nPlacementhäufigkeit [15 Placements] × Bekanntheit c |       -0.42 | [-0.89, 0.05] | -1.79 | 0.077 |      -0.39 |     [-0.82, 0.04] |       \n                                                    |             |               |       |       |            |                   |       \nAIC                                                 |             |               |       |       |            |                   | 248.67\nAICc                                                |             |               |       |       |            |                   | 249.45\nBIC                                                 |             |               |       |       |            |                   | 260.70\nR2                                                  |             |               |       |       |            |                   |   0.09\nR2 (adj.)                                           |             |               |       |       |            |                   |   0.06\nSigma                                               |             |               |       |       |            |                   |   1.06\n\n\nDie Zentrierung hat in diesem Fall keine signifikante Änderung der Ergebnisse gebracht. Der Effekt von Bekanntheit bleibt statistisch nicht signifikant, und auch der Interaktionseffekt von Placementhäufigkeit und Bekanntheit_c ist weiterhin nicht signifikant (p = .077).\n\n\n2.3.3 Konditionale Effekte: Pick-a-point\nDie Methode Pick-a-point wird in der Analyse von konditionalen Effekten verwendet, um zu untersuchen, wie sich eine unabhängige Variable (in diesem Fall Placementhäufigkeit) auf eine abhängige Variable (hier Störempfinden) auswirkt, während die Werte einer moderierenden Variablen (hier Bekanntheit) fixiert werden.\nDafür verwenden wir wieder die avg_slopes()-Funktion und das Funktionsargument by, wie bei dem Kategorieller Moderator und die Konditionale Effekte nach Gruppen.\n\nmarginaleffects::avg_slopes(results_bekannt,\n  variables = \"Placementhäufigkeit\", by = \"Bekanntheit\"\n) |&gt;\n  as_tibble()\n\n# A tibble: 4 × 13\n  term         contrast Bekanntheit estimate std.error statistic p.value s.value\n  &lt;chr&gt;        &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1 Placementhä… mean(15…           1   0.814      0.295    2.75   0.00587   7.41 \n2 Placementhä… mean(15…           2   0.389      0.242    1.61   0.108     3.21 \n3 Placementhä… mean(15…           3  -0.0348     0.376   -0.0925 0.926     0.110\n4 Placementhä… mean(15…           4  -0.459      0.580   -0.791  0.429     1.22 \n# ℹ 5 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;,\n#   predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nWir erkennen, dass nur der Effekt für die Bekanntheit mit dem Wert 1 signifikant ist (p &lt; .05), was darauf hindeutet, dass bei einer Bekanntheit von 1 der Einfluss der Placementhäufigkeit auf das Störempfinden positiv und signifikant ist. Die anderen Werte der Bekanntheit sind nicht signifikant, was darauf hindeutet, dass die Beziehung zwischen Placementhäufigkeit und Störempfinden in diesen Fällen weniger ausgeprägt oder möglicherweise nicht vorhanden ist.\n\n\n2.3.4 Modellvorhersagen und -visualisierung\nMit avg_predictions()erstellen wir eine Modellvorhersage und hängen sie mithilfe der Pipe an die Visualisierung.\n\nmarginaleffects::avg_predictions(results_bekannt,\n  variables = c(\"Placementhäufigkeit\", \"Bekanntheit\")\n) |&gt;\n  as_tibble() |&gt;\n  filter(Bekanntheit %in% c(1, 4)) |&gt;\n  mutate(Bekanntheit = if_else(Bekanntheit == 1, \"unbekannt\", \"sehr bekannt\")) |&gt;\n  ggplot(aes(\n    x = Placementhäufigkeit, y = estimate,\n    ymin = conf.low, ymax = conf.high,\n    group = Bekanntheit, color = Bekanntheit\n  )) +\n  geom_pointrange(position = position_dodge(.5)) +\n  geom_line(position = position_dodge(.5)) +\n  labs(y = \"Vorhergesagtes Störempfinden\", color = \"Bekanntheit des Produkts\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeiterführende Materialien\n\n\n\nWeitere detaillierte Beispiele mit R-Code und Daten finden sich in den Materialien zur Vorlesung Anwendungsorientierte Analyseverfahren, u.a. zu\n\nModerationsanalyse mit kategoriellen und metrischen Moderatoren\nModellvorhersagen und -visualisierungen",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Moderationsanalyse</span>"
    ]
  },
  {
    "objectID": "moderation-interaktionen.html#glossar",
    "href": "moderation-interaktionen.html#glossar",
    "title": "2  Moderationsanalyse",
    "section": "2.4 Glossar",
    "text": "2.4 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nmarginaleffects::avg_predictions\nModellvorhersagen berechnen",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Moderationsanalyse</span>"
    ]
  },
  {
    "objectID": "moderation-interaktionen.html#hausaufgabe",
    "href": "moderation-interaktionen.html#hausaufgabe",
    "title": "2  Moderationsanalyse",
    "section": "2.5 Hausaufgabe",
    "text": "2.5 Hausaufgabe\nMcNulty et al. (2008) fanden in einer Studie mit frisch verheirateten Paaren einen Zusammenhang zwischen der Attraktivität einer Person und wie sehr sie ihren Partner unterstützt. Ist dieser Zusammenhang abhängig vom Geschlecht der Person? Schätzen, interpretieren und visualisieren sie den Zusammenhang. (Datensatz mcnulty.sav)",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Moderationsanalyse</span>"
    ]
  },
  {
    "objectID": "mediation-pfadmodelle.html",
    "href": "mediation-pfadmodelle.html",
    "title": "3  Mediationsanalyse und Pfadmodelle",
    "section": "",
    "text": "3.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für Mediationsanalysen benötigen wir entweder das mediation- oder das lavaan-Paket, hier laden wir beide. Wie immer laden wir tidyverse und report.\nlibrary(mediation)\nlibrary(lavaan)\n\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nFür die einfache Mediationsanalyse nutzen wir den SPSS_Datensatz zeitungsnutzung_mediation.sav, der nur 4 Spalten enhält: die laufende Probandennummer, politisches Wissen, politisches Interesse und Zeitungsnutzungsdauer.\nd_zeitung &lt;- haven::read_sav(\"data/zeitungsnutzung_mediation.sav\") |&gt;\n  haven::zap_labels()\nd_zeitung\n\n# A tibble: 100 × 4\n  Subject PolWiss PolInt Zeitungsnutzungsdauer\n    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;                 &lt;dbl&gt;\n1       3    4      2.67                   3.8\n2       7    4      4.33                   2.8\n3      12    3.33   3.33                   2.2\n4      13    3.33   3                      4.2\n5      15    2.33   3.33                   2.8\n# ℹ 95 more rows\nFür die multiple Mediationsanalyse verwenden wir den Experiment-Datensatz influencer_mediation.sav, der ebenfalls 4 Variablen enthält: die Versuchsbedingung Werbekennzeichnung (dichotom), sowie die beiden Variablen zum Persuasionswissen (Täuschungsabsicht und Überzeugungsabsicht) sowie die Reaktanz.\nd_influencer &lt;- haven::read_sav(\"data/influencer_mediation.sav\") |&gt;\n  haven::zap_labels()\nd_influencer\n\n# A tibble: 40 × 4\n  Werbekennzeichnung PW_TAEUSCHEN PW_UEBERZEUGEN Reaktanz\n               &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n1                  0            5              3        5\n2                  0            4              3        4\n3                  0            4              3        3\n4                  0            4              3        3\n5                  0            4              2        3\n# ℹ 35 more rows",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mediationsanalyse und Pfadmodelle</span>"
    ]
  },
  {
    "objectID": "mediation-pfadmodelle.html#regressionsbasierte-analyse",
    "href": "mediation-pfadmodelle.html#regressionsbasierte-analyse",
    "title": "3  Mediationsanalyse und Pfadmodelle",
    "section": "3.2 Regressionsbasierte Analyse",
    "text": "3.2 Regressionsbasierte Analyse\n\n3.2.1 Bivariater Zusammenhang\nZunächst machen wir uns mit den relevanten Variablen vertraut und nutzen dafür die report_table()-Funktion.\n\nd_zeitung |&gt;\n  select(Zeitungsnutzungsdauer, PolWiss, PolInt) |&gt;\n  report::report_table()\n\nVariable              | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | percentage_Missing\n--------------------------------------------------------------------------------------------------------------------\nZeitungsnutzungsdauer |   100 | 3.09 | 0.67 |   3.00 | 0.89 | 1.80 | 4.60 |     0.02 |    -0.78 |               0.00\nPolWiss               |   100 | 3.47 | 0.69 |   3.67 | 0.49 | 1.00 | 5.00 |    -0.67 |     0.76 |               0.00\nPolInt                |   100 | 3.20 | 0.72 |   3.33 | 0.99 | 1.67 | 5.00 |    -0.07 |    -0.90 |               0.00\n\n\nAls nächstes schätzen wir ein einfaches bivariates Regressionmodell, um den (totalen) Effekt von Zeitungsnutzungsdauer auf pol. Wissen zu testen.\n\nmodel_total &lt;- lm(PolWiss ~ Zeitungsnutzungsdauer, data = d_zeitung)\nreport::report_table(model_total)\n\nParameter             | Coefficient |       95% CI | t(98) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n-------------------------------------------------------------------------------------------------------------\n(Intercept)           |        2.60 | [1.98, 3.23] |  8.25 | &lt; .001 |  -4.18e-16 |     [-0.19, 0.19] |       \nZeitungsnutzungsdauer |        0.28 | [0.08, 0.48] |  2.81 | 0.006  |       0.27 |     [ 0.08, 0.47] |       \n                      |             |              |       |        |            |                   |       \nAIC                   |             |              |       |        |            |                   | 207.30\nAICc                  |             |              |       |        |            |                   | 207.55\nBIC                   |             |              |       |        |            |                   | 215.12\nR2                    |             |              |       |        |            |                   |   0.07\nR2 (adj.)             |             |              |       |        |            |                   |   0.06\nSigma                 |             |              |       |        |            |                   |   0.67\n\n\nDer Zusammenhang ist positiv und statistisch signifikant, d.h. eine stärkere Zeitungsnutzung hängt mit mehr politischem Wissen zusammen.\n\n\n3.2.2 Mediationanalyse mit Regressionen\nWir gehen im Folgenden davon aus, dass der (positive) Effekt des Zeitungslesens auf pol. Wissen zumindest teilweise vom pol. Interesse mediiert wird. Anders formuliert: Zeitunglesen sollte politisches Interesse steigern, das wiederum zum mehr politischem Wissen führt (z.B. weil relevante Informationen besser erinnert werden).\n\n\n\nEinfaches Mediationsmodell\n\n\nUm die in der Abbildung dargestellte Mediationshypothese mit politischem Interesse als Mediatorvariable zu prüfen, gibt es verschiedene Möglichkeiten:\n\nWir schätzen die beiden Regressionsmodelle einzeln mit der bekannten lm-Funktion und berechnen dann den indirekten Effekt samt Konfidenzintervall mit dem mediation-Paket.\nWir schätzen ein lineares Pfad- oder Strukturgleichungsmodell, in dem alle dargestellten Zusammenhänge simultan geschätzt werden. Hierfür benötigen wir das lavaan-Paket.\n\nBeide Varianten kommen zu (fast) identischen Ergebnissen, haben aber spezifische Vor- und Nachteile. Zunächst schätzen wir die beiden Teilmodelle, die per Konvention als a bzw. bc-Regressionen bezeichnet werden.\n\nmodel_a &lt;- lm(PolInt ~ Zeitungsnutzungsdauer, data = d_zeitung)\nreport::report_table(model_a)\n\nParameter             | Coefficient |       95% CI | t(98) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n-------------------------------------------------------------------------------------------------------------\n(Intercept)           |        1.94 | [1.31, 2.57] |  6.09 | &lt; .001 |  -4.54e-16 |     [-0.18, 0.18] |       \nZeitungsnutzungsdauer |        0.41 | [0.21, 0.61] |  4.05 | &lt; .001 |       0.38 |     [ 0.19, 0.56] |       \n                      |             |              |       |        |            |                   |       \nAIC                   |             |              |       |        |            |                   | 208.89\nAICc                  |             |              |       |        |            |                   | 209.14\nBIC                   |             |              |       |        |            |                   | 216.71\nR2                    |             |              |       |        |            |                   |   0.14\nR2 (adj.)             |             |              |       |        |            |                   |   0.13\nSigma                 |             |              |       |        |            |                   |   0.67\n\n\nEs gibt einen positiven, stat. signifikanten Zusammenhang zwischen Zeitungsnutzung und pol. Interesse, d.h. der \\(a\\)-Pfad ist signifikant.\n\nmodel_bc &lt;- lm(PolWiss ~ Zeitungsnutzungsdauer + PolInt, data = d_zeitung)\nreport::report_table(model_bc)\n\nParameter             | Coefficient |        95% CI | t(97) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n--------------------------------------------------------------------------------------------------------------\n(Intercept)           |        1.85 | [ 1.17, 2.53] |  5.39 | &lt; .001 |  -2.32e-16 |     [-0.18, 0.18] |       \nZeitungsnutzungsdauer |        0.12 | [-0.08, 0.32] |  1.22 | 0.227  |       0.12 |     [-0.07, 0.31] |       \nPolInt                |        0.39 | [ 0.21, 0.57] |  4.21 | &lt; .001 |       0.41 |     [ 0.22, 0.60] |       \n                      |             |               |       |        |            |                   |       \nAIC                   |             |               |       |        |            |                   | 192.53\nAICc                  |             |               |       |        |            |                   | 192.96\nBIC                   |             |               |       |        |            |                   | 202.95\nR2                    |             |               |       |        |            |                   |   0.22\nR2 (adj.)             |             |               |       |        |            |                   |   0.20\nSigma                 |             |               |       |        |            |                   |   0.62\n\n\nEs gibt außerdem einen positiven, statistisch signifikanten Zusammenhang zwischen politischem Interesse und politischem Wissen, der \\(b\\)-Pfad, während der verbleibende direkte Effekt \\(c'\\) nicht statistisch signifikant ist.\nDa \\(a\\) und \\(b\\)-Pfade signifikant sind (joint significance), können wir die Mediationshyptothese annehmen. In der Praxis wird darüber hinaus jedoch häufig der indirekte Effekt \\(ab\\) selbst noch quantifiziert, d.h das Produkt aus \\(a\\) und \\(b\\)-Koeffizienten.\n\n\n3.2.3 Indirekter Effekt\nWährend man die Punktschätzer für \\(ab\\) einfach ausmultiplizieren kann, ist die inferenzstatisches Prüfung bzw. Berechnung des Konfidenzintervalls nicht ganz so leicht. Hayes und Scharkow (2013) listen eine Reihe von Verfahren auf, von denen Bootstrapping mit Perzentil-Intervall empfohlen wird. Dies könnte man manuell in R schätzen, es gibt aber mit der mediate-Funktion eine komfortablere Lösung. Als Funktionsargumente werden, das \\(a\\)-Regressionsmodell, das \\(bc\\)-Regressionsmodell, der Name der \\(X\\)-Variable und der Name der Mediatorvariable \\(M\\) übergeben. Über boot = TRUE fordern wir ein Bootstrap-basiertes Konfidenzintervall an. Das Ergebnis des Aufrufs wird dann über summary() zusammengefasst.\n\nmediation::mediate(model_a, model_bc,\n  treat = \"Zeitungsnutzungsdauer\",\n  mediator = \"PolInt\",\n  boot = TRUE\n) |&gt;\n  summary()\n\n\nCausal Mediation Analysis \n\nNonparametric Bootstrap Confidence Intervals with the Percentile Method\n\n               Estimate 95% CI Lower 95% CI Upper p-value    \nACME             0.1593       0.0561         0.29  &lt;2e-16 ***\nADE              0.1214      -0.1093         0.31   0.282    \nTotal Effect     0.2807       0.0712         0.47   0.016 *  \nProp. Mediated   0.5674       0.1896         1.94   0.016 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSample Size Used: 100 \n\n\nSimulations: 1000 \n\n\nDer indirekte Effekt (ACME) ist positiv, das 95%-Konfidenzintervall enthält nicht die Null, d.h. der Effekt ist statistisch signfikant. Zusätzlich werden der direkte Effekt \\(c'\\) (ADE), der totale Effekt (siehe unser bivariate Regression oben) sowie das Verhältnis von indirektem zu totalem Effekt (Prop. Mediated) ausgegeben. Insgesamt zeigt sich auch hier, dass wir die Mediationshypothese annehmen können.",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mediationsanalyse und Pfadmodelle</span>"
    ]
  },
  {
    "objectID": "mediation-pfadmodelle.html#pfadanalyse",
    "href": "mediation-pfadmodelle.html#pfadanalyse",
    "title": "3  Mediationsanalyse und Pfadmodelle",
    "section": "3.3 Pfadanalyse",
    "text": "3.3 Pfadanalyse\nAlternativ zu Einzelregressionen kann man über Strukturgleichungsmodelle (fast) beliebig komplexe Zusammenhänge simultan schätzen. Hierfür verwenden wir das lavaan-Paket, das eine recht einfache Spezifikationssyntax hat.\n\n3.3.1 Pfadmodelle\nDie Schätzung von Pfadmodellen mit lavaan besteht immer aus zwei Teilschritten: Modellspezifikation und Modellschätzung. Die Spezifikation besteht darin, dass wir in einem character-Objekt einen oder mehrere Pfade im Modell beschreiben. In unserem Fall sind es Regressionsmodelle, die exakt die gleiche Form haben, wie die Formel im lm-Aufruf. Wir schreiben beide Regressionsformeln nacheinander in das Modell.\n\nsimple_model &lt;- \"\n  PolInt ~ Zeitungsnutzungsdauer\n  PolWiss ~ PolInt + Zeitungsnutzungsdauer\n\"\n\nNach der Spezifikation geschieht erst einmal nichts, da wir nur ein Objekt mit etwas Text angelegt haben. Geschätzt wird das Modell erst mit dem Aufruf der sem()-Funktion. Diese bekommt als erstes Argument unser spezifiziertes Modell, als zweites die Daten, mit denen das Modell geschätz werden sollen. Über die summary()-Funktion bekommen wir eine sehr ausführliche Zusammenfassung der Schätzung. Entscheidend ist zunächst, dass das Modell erfolgreich geschätzt wurde (Zeile 1) sowie die Schätzer für die Regressionskoeffizienten. Diese entsprechen exakt den mit lm() geschätzten Koeffizienten von oben.\n\nresults_simple &lt;- lavaan::sem(model = simple_model, data = d_zeitung)\nsummary(results_simple, standardized = TRUE, rsquare = TRUE)\n\nlavaan 0.6-18 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  PolInt ~                                                              \n    Zetngsntzngsdr    0.409    0.100    4.095    0.000    0.409    0.379\n  PolWiss ~                                                             \n    PolInt            0.390    0.091    4.273    0.000    0.390    0.408\n    Zetngsntzngsdr    0.121    0.098    1.235    0.217    0.121    0.118\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PolInt            0.445    0.063    7.071    0.000    0.445    0.856\n   .PolWiss           0.371    0.052    7.071    0.000    0.371    0.783\n\nR-Square:\n                   Estimate\n    PolInt            0.144\n    PolWiss           0.217\n\n\n\n\n3.3.2 Einfache Mediation\nFür die Mediationsanalyse machen wir uns die Möglichkeit zunutze, in der Modellspezifikation bestimmte Parameter (oder Pfade) benennen zu können, etwa den \\(a\\), \\(b\\) und \\(c'\\) Parameter aus dem Mediationsmodell.\nIm unteren Teil der Spezifikation definieren wir dann den indirekten (\\(a * b\\)) und totalen Effekt (\\(ab + c\\)) aus den benannten Modellparametern. Diese werden bei der Schätzung ebenfalls berücksichtigt, inklusive Standardfehler bzw. Konfidenzintervallen. Wir bekommen also alle relevanten Modellergebnisse auf einmal geliefert.\n\nmed_model &lt;- \"\n  # Regressionen\n  PolInt ~ a * Zeitungsnutzungsdauer\n  PolWiss ~ b * PolInt + c * Zeitungsnutzungsdauer\n\n  # abgeleitete Parameter\n  indirect := a * b\n  total := indirect + c\n  prop_mediated := indirect / total\n\"\n\nDer Modellaufruf ist wie im obigen Beispiel, jedoch wollen wir anstelle (falscher) asymptotischer Standardfehler und Konfidenzintervalle wiederum Bootstrap-basierte erhalten.\n\nresults_med &lt;- lavaan::sem(\n  model = med_model, data = d_zeitung,\n  se = \"bootstrap\", bootstrap = 1000\n)\nsummary(results_med, standardized = TRUE, rsquare = TRUE)\n\nlavaan 0.6-18 ended normally after 1 iteration\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         5\n\n  Number of observations                           100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws            1000\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  PolInt ~                                                              \n    Ztngsntzng (a)    0.409    0.099    4.142    0.000    0.409    0.379\n  PolWiss ~                                                             \n    PolInt     (b)    0.390    0.112    3.495    0.000    0.390    0.408\n    Ztngsntzng (c)    0.121    0.118    1.033    0.302    0.121    0.118\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PolInt            0.445    0.051    8.657    0.000    0.445    0.856\n   .PolWiss           0.371    0.059    6.250    0.000    0.371    0.783\n\nR-Square:\n                   Estimate\n    PolInt            0.144\n    PolWiss           0.217\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    indirect          0.159    0.058    2.743    0.006    0.159    0.155\n    total             0.281    0.113    2.486    0.013    0.281    0.273\n    prop_mediated     0.567    3.485    0.163    0.871    0.567    0.567\n\n\nDa uns nur die Regressions- und definierten Koeffizienten interessieren, nutzen wir die report_table()-Funktion und filtern alle anderen Modellparameter heraus.\n\nreport::report_table(results_med) |&gt;\n  filter(Coefficient != \"\")\n\nParameter                       | Coefficient |        95% CI |    z |      p |         Label |  Component | Fit\n----------------------------------------------------------------------------------------------------------------\nPolInt ~ Zeitungsnutzungsdauer  |        0.41 | [ 0.20, 0.59] | 4.14 | &lt; .001 |             a | Regression |    \nPolWiss ~ PolInt                |        0.39 | [ 0.18, 0.61] | 3.49 | &lt; .001 |             b | Regression |    \nPolWiss ~ Zeitungsnutzungsdauer |        0.12 | [-0.12, 0.33] | 1.03 | 0.302  |             c | Regression |    \nindirect := a*b                 |        0.16 | [ 0.05, 0.29] | 2.74 | 0.006  |      indirect |    Defined |    \ntotal := indirect+c             |        0.28 | [ 0.03, 0.48] | 2.49 | 0.013  |         total |    Defined |    \nprop_mediated := indirect/total |        0.57 | [ 0.17, 2.35] | 0.16 | 0.871  | prop_mediated |    Defined |    \n\n\nJetzt erhalten wir alle relevanten Modellergebnisse in einem Schritt, mit fast identischen Ergebnissen im Vergleich zu den einzelnen Regressionen oben.\n\n\n3.3.3 Multiple Mediation\nAls zweites Beispiel schätzen wir ein Mediationsmodell zum Einfluss von Werbekennzeichnungen bei Influencern. Zunächst machen wir uns mit den relevanten Variablen vertraut, bevor wir das Pfadmodell schätzen.\n\nd_influencer |&gt;\n  report::report_table()\n\nVariable           | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | n_Missing\n--------------------------------------------------------------------------------------------------------\nWerbekennzeichnung |    40 | 0.50 | 0.51 |   0.50 | 0.74 | 0.00 | 1.00 |     0.00 |    -2.11 |         0\nPW_TAEUSCHEN       |    40 | 3.10 | 1.32 |   3.00 | 1.48 | 1.00 | 5.00 |    -0.19 |    -1.11 |         0\nPW_UEBERZEUGEN     |    40 | 3.12 | 1.07 |   3.00 | 1.48 | 1.00 | 5.00 |     0.14 |    -0.43 |         0\nReaktanz           |    40 | 3.30 | 0.88 |   3.00 | 1.48 | 2.00 | 5.00 |     0.30 |    -0.48 |         0\n\n\nPfadmodelle haben den Vorteil, dass sie (fast) beliebig erweiterbar sind, d.h. wir können auch komplexere Modelle schätzen, etwa eine parallele multiple Mediation, wie in der Abbildung dargestellt.\n\n\n\nParalleles Mediationsmodell\n\n\nDas multiple Mediationsmodell hat jeweils zwei \\(a\\) und \\(b\\)-Pfade (d.h. drei Regressionsgleichungen). Üblicherweise wird auch der Zusammenhang zwischen den beiden Mediatorvariablen geschätzt (mit ~~ spezifiziert), weil es plausibel ist, dass diese auch zusammenhängen. Anschließend werden zwei indirekte und ein totaler Effekt definiert und das Modell dann geschätzt.\n\nmultmed_model &lt;- \"\n  # Regressionen\n  PW_UEBERZEUGEN ~ a1 * Werbekennzeichnung\n  PW_TAEUSCHEN ~ a2 * Werbekennzeichnung\n  Reaktanz ~ b1 * PW_UEBERZEUGEN + b2 * PW_TAEUSCHEN + c * Werbekennzeichnung\n\n  # Korrelation der Mediatoren\n  PW_UEBERZEUGEN ~~ PW_TAEUSCHEN\n\n  # abgeleitete Parameter\n  indirect1 := a1 * b1\n  indirect2 := a2 * b2\n  total := indirect1 + indirect2  + c\n\"\n\nresults_multmed &lt;- lavaan::sem(\n  model = multmed_model, data = d_influencer,\n  se = \"bootstrap\", bootstrap = 1000\n)\nsummary(results_multmed, standardized = TRUE, rsquare = TRUE)\n\nlavaan 0.6-18 ended normally after 9 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         9\n\n  Number of observations                            40\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                            Bootstrap\n  Number of requested bootstrap draws             1000\n  Number of successful bootstrap draws             998\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  PW_UEBERZEUGEN ~                                                      \n    Wrbknnzch (a1)    1.050    0.297    3.531    0.000    1.050    0.498\n  PW_TAEUSCHEN ~                                                        \n    Wrbknnzch (a2)   -1.300    0.365   -3.558    0.000   -1.300   -0.500\n  Reaktanz ~                                                            \n    PW_UEBERZ (b1)    0.422    0.158    2.665    0.008    0.422    0.509\n    PW_TAEUSC (b2)    0.250    0.120    2.086    0.037    0.250    0.373\n    Wrbknnzch  (c)   -0.318    0.282   -1.129    0.259   -0.318   -0.182\n\nCovariances:\n                    Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .PW_UEBERZEUGEN ~~                                                      \n   .PW_TAEUSCHEN      -0.146    0.153   -0.954    0.340   -0.146   -0.142\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .PW_UEBERZEUGEN    0.834    0.183    4.558    0.000    0.834    0.752\n   .PW_TAEUSCHEN      1.268    0.260    4.878    0.000    1.268    0.750\n   .Reaktanz          0.553    0.117    4.740    0.000    0.553    0.728\n\nR-Square:\n                   Estimate\n    PW_UEBERZEUGEN    0.248\n    PW_TAEUSCHEN      0.250\n    Reaktanz          0.272\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    indirect1         0.443    0.189    2.346    0.019    0.443    0.254\n    indirect2        -0.325    0.177   -1.837    0.066   -0.325   -0.186\n    total            -0.200    0.280   -0.713    0.476   -0.200   -0.115\n\n\nDer Output ist lediglich etwas länger als zuvor, aber die relevanten Koeffizienten finden sich an denselben Stellen. Auch hier können wir den Output auf die notwendigen Angaben filtern.\n\nreport_table(results_multmed) |&gt;\n  filter(Coefficient != \"\")\n\nParameter                           | Coefficient |         95% CI |     z |      p |     Label |   Component | Fit\n-------------------------------------------------------------------------------------------------------------------\nPW_UEBERZEUGEN ~ Werbekennzeichnung |        1.05 | [ 0.45,  1.66] |  3.53 | &lt; .001 |        a1 |  Regression |    \nPW_TAEUSCHEN ~ Werbekennzeichnung   |       -1.30 | [-2.00, -0.60] | -3.56 | &lt; .001 |        a2 |  Regression |    \nReaktanz ~ PW_UEBERZEUGEN           |        0.42 | [ 0.12,  0.73] |  2.67 | 0.008  |        b1 |  Regression |    \nReaktanz ~ PW_TAEUSCHEN             |        0.25 | [ 0.00,  0.47] |  2.09 | 0.037  |        b2 |  Regression |    \nReaktanz ~ Werbekennzeichnung       |       -0.32 | [-0.88,  0.24] | -1.13 | 0.259  |         c |  Regression |    \nPW_UEBERZEUGEN ~~ PW_TAEUSCHEN      |       -0.15 | [-0.44,  0.16] | -0.95 | 0.340  |           | Correlation |    \nindirect1 := a1*b1                  |        0.44 | [ 0.12,  0.85] |  2.35 | 0.019  | indirect1 |     Defined |    \nindirect2 := a2*b2                  |       -0.32 | [-0.67,  0.01] | -1.84 | 0.066  | indirect2 |     Defined |    \ntotal := indirect1+indirect2+c      |       -0.20 | [-0.78,  0.31] | -0.71 | 0.476  |     total |     Defined |    \n\n\nBeide indirekten Effekte sind statistisch signifikant, aber gegenläufig, was häufig als sog. Suppressionseffekt interpretiert wird.\n\n\n\n\n\n\nGibt es überhaupt einen Effekt?\n\n\n\nAchtung, bei genauerer Betrachtung des totalen Effekts stellen wir fest, dass dieser gar nicht statistisch signifikant ist, d.h. wir haben keinen Beleg dafür, dass die Werbekennzeichnung überhaupt die Reaktanz der Proband:innen beeinflusst hat. Dies sollte auch und erst recht bei der kausalen (Über-) Interpretation komplexer Mediationsmodelle berücksichtigt werden, vor allem, wenn die Mediatoren nicht experimentell manipuliert wurden.",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mediationsanalyse und Pfadmodelle</span>"
    ]
  },
  {
    "objectID": "mediation-pfadmodelle.html#glossar",
    "href": "mediation-pfadmodelle.html#glossar",
    "title": "3  Mediationsanalyse und Pfadmodelle",
    "section": "3.4 Glossar",
    "text": "3.4 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nlavaan::sem\nPfadmodelle schätzen\n\n\nmediation::mediate\nMediationseffekte analysieren",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mediationsanalyse und Pfadmodelle</span>"
    ]
  },
  {
    "objectID": "mediation-pfadmodelle.html#hausaufgabe",
    "href": "mediation-pfadmodelle.html#hausaufgabe",
    "title": "3  Mediationsanalyse und Pfadmodelle",
    "section": "3.5 Hausaufgabe",
    "text": "3.5 Hausaufgabe\nGegeben sei folgenden Hypothese:\n\n„Je mehr Pornografie eine Person konsumiert, desto eher ist sie untreu. Dieser Zusammenhang wird vom Commitment für die Beziehung mediiert: Je höher der Pornografiekonsum ausfällt, desto geringer ist das Committment, und je geringer das Committment ist, desto häufiger ist einer Person untreu.»\n\nTesten Sie diese Mediationshypothese mit dem Datensatz lambert.sav.",
    "crumbs": [
      "Regressionsmodelle",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Mediationsanalyse und Pfadmodelle</span>"
    ]
  },
  {
    "objectID": "lagged-crosslagged.html",
    "href": "lagged-crosslagged.html",
    "title": "4  Lagged und Cross-Lagged Modelle",
    "section": "",
    "text": "4.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für Pfadanalysen benötigen wir wieder das lavaan-Paket. Wie immer laden wir tidyverse und report.\nlibrary(lavaan)\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nAls Datensatz verwenden wir eine Zwei-Wellen-Panel-Befragung von Stevic et al. Hier wurden Kinder und Eltern zur (abendlichen) Mediennutzung, Aufmerksamkeitsdefiziten und der Leistung in der Schule befragt.\nd_stevic &lt;- haven::read_sav(\"data/stevic_etal.sav\") |&gt;\n  mutate(female_child = if_else(gender_child_w1 == 1, 1, 0)) |&gt;\n  haven::zap_labels()\nd_stevic\n\n# A tibble: 822 × 79\n  consent_w1 gender_parent_w1 age_parent_w1 education_parent_w1\n       &lt;dbl&gt;            &lt;dbl&gt;         &lt;dbl&gt;               &lt;dbl&gt;\n1          1                2            44                   7\n2          1                1            44                   7\n3          1                2            42                   3\n4          1                1            38                   7\n5          1                1            40                   4\n# ℹ 817 more rows\n# ℹ 75 more variables: kids_home_parent_w1 &lt;dbl&gt;, nr_children__parent_w1 &lt;dbl&gt;,\n#   age_participating_child_w1 &lt;dbl&gt;, smartphone_parents_w1 &lt;dbl&gt;,\n#   smartphone_child_w1 &lt;dbl&gt;, attention1_parent_w1 &lt;dbl&gt;,\n#   attention2_parent_w1 &lt;dbl&gt;, attention3_parent_w1 &lt;dbl&gt;,\n#   income_parent_w1 &lt;dbl&gt;, gender_child_w1 &lt;dbl&gt;, age_child_w1 &lt;dbl&gt;,\n#   education_child_w1 &lt;dbl&gt;, performance1_child_w1 &lt;dbl&gt;, …\nd_stevic |&gt;\n  select(female_child, w1_nightuse_child_w1, w2_nightuse_child_w2, attention_parent_w1, attention_parent_w2) |&gt;\n  report::report_table()\n\nVariable             | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | percentage_Missing\n-------------------------------------------------------------------------------------------------------------------\nfemale_child         |   822 | 0.51 | 0.50 |   1.00 | 0.00 | 0.00 | 1.00 |    -0.04 |    -2.00 |               0.00\nw1_nightuse_child_w1 |   822 | 1.87 | 1.27 |   1.25 | 0.37 | 1.00 | 7.00 |     1.85 |     2.77 |               0.00\nw2_nightuse_child_w2 |   822 | 1.77 | 1.19 |        | 0.37 | 1.00 | 7.00 |     2.15 |     4.64 |              53.28\nattention_parent_w1  |   822 | 2.73 | 1.12 |   2.67 | 0.99 | 1.00 | 5.00 |     0.21 |    -0.83 |               0.00\nattention_parent_w2  |   822 | 2.67 | 1.11 |        | 0.99 | 1.00 | 5.00 |     0.17 |    -0.82 |              53.28\nEin Blick auf die Deskriptivstatistiken verrät, dass weniger als die Hälfte der Befragten zum 2. Messzeitpunkt noch geantwortet haben, wir also eine recht starke Panelmortalität haben.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagged und Cross-Lagged Modelle</span>"
    ]
  },
  {
    "objectID": "lagged-crosslagged.html#autokorrelation--regression-und-lagged-dependent-variable-ldv",
    "href": "lagged-crosslagged.html#autokorrelation--regression-und-lagged-dependent-variable-ldv",
    "title": "4  Lagged und Cross-Lagged Modelle",
    "section": "4.2 Autokorrelation, -regression und Lagged Dependent Variable (LDV)",
    "text": "4.2 Autokorrelation, -regression und Lagged Dependent Variable (LDV)\n\n4.2.1 Autokorrelationen\nZunächst betrachten wir die Stabilität der beiden zentralen Variablen: nächtliche Social-Media-Nutzung (Selbstbericht der Kinder) und Aufmerksamkeitsschwierigkeiten (beurteilt durch die Eltern).\n\ncor.test(~ w1_nightuse_child_w1 + w2_nightuse_child_w2, d_stevic) |&gt;\n  report_table()\n\nPearson's product-moment correlation\n\nParameter1           |           Parameter2 |    r |       95% CI | t(382) |      p\n-----------------------------------------------------------------------------------\nw1_nightuse_child_w1 | w2_nightuse_child_w2 | 0.51 | [0.43, 0.58] |  11.67 | &lt; .001\n\nAlternative hypothesis: two.sided\n\n\nEs besteht eine mittlere Korrelation zwischen den Messungen der nächtlichen Mediennutzung, d.h. die Test-Retest-Reliabilität und/oder Stabilität des Mediennutzungsverhaltens ist moderat.\n\ncor.test(~ attention_parent_w1 + attention_parent_w2, d_stevic) |&gt;\n  report::report_table()\n\nPearson's product-moment correlation\n\nParameter1          |          Parameter2 |    r |       95% CI | t(382) |      p\n---------------------------------------------------------------------------------\nattention_parent_w1 | attention_parent_w2 | 0.72 | [0.67, 0.76] |  20.21 | &lt; .001\n\nAlternative hypothesis: two.sided\n\n\nDie Autokorrelation bei den (von den Eltern angegebenen) Aufmerksamkeitsdefiziten ist etwas stärker ausgeprägt, d.h. die Einschätzung ist reliabler und/oder stabiler über die Zeit. Einfach formuliert: Kinder, die schon zum ersten Messzeitpunkt relativ starke/geringe Aufmerksamkeitsdefizite aufwiesen (laut Eltern), taten dies auch zum zweiten Messzeitpunkt. Die Rangreihe der Kinder ist also relativ stabil über die Zeit.\n\n\n4.2.2 Regression ohne und mit LDV\nDas naive Regressionsmodell versucht, die Aufmerksamkeitsdefizite zu \\(t_2\\) durch die nächtliche Social-Media-Nutzung zu \\(t_1\\) vorherzusagen.\n\nresults_naiv &lt;- lm(attention_parent_w2 ~ w1_nightuse_child_w1, d_stevic)\nreport::report_table(results_naiv)\n\nParameter            | Coefficient |       95% CI | t(382) |      p | Std. Coef. | Std. Coef. 95% CI |     Fit\n--------------------------------------------------------------------------------------------------------------\n(Intercept)          |        2.44 | [2.24, 2.64] |  24.28 | &lt; .001 |  -2.77e-16 |     [-0.10, 0.10] |        \nw1 nightuse child w1 |        0.13 | [0.03, 0.22] |   2.71 | 0.007  |       0.14 |     [ 0.04, 0.24] |        \n                     |             |              |        |        |            |                   |        \nAIC                  |             |              |        |        |            |                   | 1167.42\nAICc                 |             |              |        |        |            |                   | 1167.48\nBIC                  |             |              |        |        |            |                   | 1179.27\nR2                   |             |              |        |        |            |                   |    0.02\nR2 (adj.)            |             |              |        |        |            |                   |    0.02\nSigma                |             |              |        |        |            |                   |    1.10\n\n\nEs scheint einen positiven, statistisch signifikanten Einfluss der nächtlichen Mediennutzung auf spätere Aufmerksamkeitsdefizite zu geben. Was passiert, wenn wir die zuvor erhobenen Aufmerksamkeitsprobleme zu \\(t_1\\) im Modell berücksichtigen? Dies entspricht dem klassischen LDV-Modell.\n\nresults_ldv &lt;- lm(attention_parent_w2 ~ w1_nightuse_child_w1 + attention_parent_w1, d_stevic)\nreport::report_table(results_ldv)\n\nParameter            | Coefficient |        95% CI | t(381) |      p | Std. Coef. | Std. Coef. 95% CI |    Fit\n--------------------------------------------------------------------------------------------------------------\n(Intercept)          |        0.58 | [ 0.35, 0.81] |   5.00 | &lt; .001 |  -3.56e-16 |     [-0.07, 0.07] |       \nw1 nightuse child w1 |        0.05 | [-0.01, 0.12] |   1.62 | 0.106  |       0.06 |     [-0.01, 0.13] |       \nattention parent w1  |        0.72 | [ 0.65, 0.79] |  19.95 | &lt; .001 |       0.71 |     [ 0.64, 0.78] |       \n                     |             |               |        |        |            |                   |       \nAIC                  |             |               |        |        |            |                   | 894.84\nAICc                 |             |               |        |        |            |                   | 894.95\nBIC                  |             |               |        |        |            |                   | 910.64\nR2                   |             |               |        |        |            |                   |   0.52\nR2 (adj.)            |             |               |        |        |            |                   |   0.52\nSigma                |             |               |        |        |            |                   |   0.77\n\n\nBerücksichtigen wir die bereits zum ersten Messzeitpunkt gemessenen Aufmerksamkeitsproblem, wird der geschätzte Effekt der nächtlichen Mediennutzung deutlich kleiner und statistisch nicht-signifikant (auch wenn wir bei einer gerichteten Hypothese wie oben einseitig testen würden). Anders formuliert: Wenn wir in Rechnung stellen, dass manche Kinder bereits bei der ersten Messung viele/wenige Aufmerksamkeitsdefizite hatten, finden wir nur einen kleinen, nicht signfikanten Medieneffekt. Dies ist sehr häufig der Fall.\n\n\n\n\n\n\nInterpretation des LDV-Koeffizienten\n\n\n\nDer Koeffizient der Lagged Dependent Variable sollte nicht als Verstärkungs/Abschwächungseffekt interpretiert werden, d.h. ein positiver Koeffizient bedeutet nicht unbedingt, dass Kinder mit Aufmerksamkeitsproblemen zu \\(t_1\\) noch mehr Aufmerksamkeitsprobleme zu \\(t_2\\) hatten, sondern wie oben beschrieben, die Rangfolge der Kinder nach Aufmerksamkeitsproblem bleibt relativ stabil. Folgende 3 Muster haben alle einen standardisierten Autoregressionseffekt von 1:\n\n\n\n\n\n\n\n\n\n\n\nUmgekehrt können wir auch untersuchen, ob Kinder mit Aufmerksamkeitsdefiziten eher zu nächtlicher Social-Media-Nutzung neigen. Diesmal schätzen wir gleich das LDV-Modell, d.h. wir berücksichtigen die zu \\(t_1\\) berichtete Mediennutzung.\n\nresults_ldv2 &lt;- lm(w2_nightuse_child_w2 ~ w1_nightuse_child_w1 + attention_parent_w1, d_stevic)\nreport::report_table(results_ldv2)\n\nParameter            | Coefficient |        95% CI | t(381) |      p | Std. Coef. | Std. Coef. 95% CI |     Fit\n---------------------------------------------------------------------------------------------------------------\n(Intercept)          |        0.64 | [ 0.34, 0.94] |   4.15 | &lt; .001 |  -1.08e-15 |     [-0.09, 0.09] |        \nw1 nightuse child w1 |        0.50 | [ 0.41, 0.59] |  11.43 | &lt; .001 |       0.50 |     [ 0.42, 0.59] |        \nattention parent w1  |        0.09 | [-0.01, 0.18] |   1.83 | 0.068  |       0.08 |     [-0.01, 0.17] |        \n                     |             |               |        |        |            |                   |        \nAIC                  |             |               |        |        |            |                   | 1108.52\nAICc                 |             |               |        |        |            |                   | 1108.62\nBIC                  |             |               |        |        |            |                   | 1124.32\nR2                   |             |               |        |        |            |                   |    0.27\nR2 (adj.)            |             |               |        |        |            |                   |    0.27\nSigma                |             |               |        |        |            |                   |    1.02\n\n\nDer Zusammenhang ist nicht-signifikant bei einem zweiseitigen Test, allerdings dürften wir bei einer gerichteten Hypothese wie oben den p-Wert halbieren.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagged und Cross-Lagged Modelle</span>"
    ]
  },
  {
    "objectID": "lagged-crosslagged.html#cross-lagged-panel-model-clpm",
    "href": "lagged-crosslagged.html#cross-lagged-panel-model-clpm",
    "title": "4  Lagged und Cross-Lagged Modelle",
    "section": "4.3 Cross-lagged Panel Model (CLPM)",
    "text": "4.3 Cross-lagged Panel Model (CLPM)\n\n4.3.1 Bivariates CLPM\nWie bei den Mediationsanalysen können wir statt zwei separater Regressionen auch ein einzelnes Pfadmodell rechnen, um beide reziproken Pfade gleichzeitig zu schätzen. Hierfür verwenden wir wieder das lavaan-Paket und den dort üblichen Ablauf aus Modellspezifikation und anschließender Schätzung. Das Cross-Lagged-Panel-Modell wird mit derselben Modellformel wie die Einzelregressionen spezifiziert:\n\nclp_model &lt;- \"\n  attention_parent_w2 ~ w1_nightuse_child_w1 + attention_parent_w1\n  w2_nightuse_child_w2 ~ w1_nightuse_child_w1 + attention_parent_w1\n\n  w1_nightuse_child_w1 ~~ attention_parent_w1\n\"\nresults_clpm &lt;- lavaan::sem(clp_model, data = d_stevic)\nsummary(results_clpm, standardized = TRUE, rsquare = TRUE)\n\nlavaan 0.6-18 ended normally after 15 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        10\n\n                                                  Used       Total\n  Number of observations                           384         822\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                         Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  attention_parent_w2 ~                                                       \n    w1_nghts_chl_1          0.054    0.033    1.625    0.104    0.054    0.058\n    attntn_prnt_w1          0.723    0.036   20.025    0.000    0.723    0.712\n  w2_nightuse_child_w2 ~                                                      \n    w1_nghts_chl_1          0.500    0.044   11.470    0.000    0.500    0.504\n    attntn_prnt_w1          0.087    0.048    1.836    0.066    0.087    0.081\n\nCovariances:\n                          Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  w1_nightuse_child_w1 ~~                                                      \n    attntn_prnt_w1           0.145    0.067    2.167    0.030    0.145    0.111\n .attention_parent_w2 ~~                                                       \n   .w2_nghts_chl_2           0.075    0.040    1.891    0.059    0.075    0.097\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .attntn_prnt_w2    0.590    0.043   13.856    0.000    0.590    0.480\n   .w2_nghts_chl_2    1.028    0.074   13.856    0.000    1.028    0.731\n    w1_nghts_chl_1    1.425    0.103   13.856    0.000    1.425    1.000\n    attntn_prnt_w1    1.194    0.086   13.856    0.000    1.194    1.000\n\nR-Square:\n                   Estimate\n    attntn_prnt_w2    0.520\n    w2_nghts_chl_2    0.269\n\n\nIm Output-Block Regressions erhalten wir dieselben Koeffizienten wie zuvor. Zusätzlich können wir im Block Covariances noch die Korrelation zwischen den beiden Variablen zu \\(t_1\\) sehen (r = .111) sowie die Korrelation der Residuen der beiden Variablen zu \\(t_2\\). Letzteres ist der Zusammenhang nach Kontrolle der autoregressiven und der cross-lagged Effekte. Ist dieser signifikant, deutet dies zumeist auf eine nicht-berücksichtigte Drittvariable hin.\n\n\n4.3.2 CLPM mit Kovariaten\nDas CLPM kann mit beliebigen zeitlich variierenden oder nicht variierenden Variablen erweitert werden. Als Beispiel kontrollieren wir statistisch für das Ge der Kinder. Hierfür erweitern wir die Spefizikation, so dass für beide Variablen der Prädiktor female_child hinzukommt.\n\nclp_model_age &lt;- \"\n  attention_parent_w2 ~ w1_nightuse_child_w1 + attention_parent_w1 + female_child\n  w2_nightuse_child_w2 ~ w1_nightuse_child_w1 + attention_parent_w1 + female_child\n\n  w1_nightuse_child_w1 ~ female_child\n   attention_parent_w1 ~ female_child\n  w1_nightuse_child_w1 ~~ attention_parent_w1\n\"\nresults_clpm_age &lt;- lavaan::sem(clp_model_age, data = d_stevic)\nsummary(results_clpm_age, standardized = TRUE, rsquare = TRUE)\n\nlavaan 0.6-18 ended normally after 11 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        14\n\n                                                  Used       Total\n  Number of observations                           384         822\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nRegressions:\n                         Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  attention_parent_w2 ~                                                       \n    w1_nghts_chl_1          0.053    0.033    1.582    0.114    0.053    0.057\n    attntn_prnt_w1          0.723    0.036   19.990    0.000    0.723    0.713\n    female_child            0.020    0.079    0.247    0.805    0.020    0.009\n  w2_nightuse_child_w2 ~                                                      \n    w1_nghts_chl_1          0.488    0.044   11.177    0.000    0.488    0.491\n    attntn_prnt_w1          0.096    0.047    2.014    0.044    0.096    0.088\n    female_child            0.240    0.104    2.305    0.021    0.240    0.101\n  w1_nightuse_child_w1 ~                                                      \n    female_child            0.276    0.121    2.279    0.023    0.276    0.116\n  attention_parent_w1 ~                                                       \n    female_child           -0.131    0.112   -1.178    0.239   -0.131   -0.060\n\nCovariances:\n                          Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n .w1_nightuse_child_w1 ~~                                                      \n   .attntn_prnt_w1           0.154    0.066    2.320    0.020    0.154    0.119\n .attention_parent_w2 ~~                                                       \n   .w2_nghts_chl_2           0.074    0.040    1.875    0.061    0.074    0.096\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .attntn_prnt_w2    0.589    0.043   13.856    0.000    0.589    0.480\n   .w2_nghts_chl_2    1.014    0.073   13.856    0.000    1.014    0.721\n   .w1_nghts_chl_1    1.406    0.101   13.856    0.000    1.406    0.987\n   .attntn_prnt_w1    1.190    0.086   13.856    0.000    1.190    0.996\n\nR-Square:\n                   Estimate\n    attntn_prnt_w2    0.520\n    w2_nghts_chl_2    0.279\n    w1_nghts_chl_1    0.013\n    attntn_prnt_w1    0.004\n\n\nWir erkennen, dass Mädchen signifikant häufiger nachts Social Media genutzt haben, während es bei den Aufmerksamkeitsproblemen keine signifikanten Unterschiede zwischen Jungen und Mädchen gab.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagged und Cross-Lagged Modelle</span>"
    ]
  },
  {
    "objectID": "lagged-crosslagged.html#glossar",
    "href": "lagged-crosslagged.html#glossar",
    "title": "4  Lagged und Cross-Lagged Modelle",
    "section": "4.4 Glossar",
    "text": "4.4 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\ncor.test\nKorrelation und Signifikanz schätzen",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagged und Cross-Lagged Modelle</span>"
    ]
  },
  {
    "objectID": "lagged-crosslagged.html#hausaufgabe",
    "href": "lagged-crosslagged.html#hausaufgabe",
    "title": "4  Lagged und Cross-Lagged Modelle",
    "section": "4.5 Hausaufgabe",
    "text": "4.5 Hausaufgabe\nUntersuchen Sie den längsschnittlichen Zusammenhang zwischen nächtlicher Social-Media-Nutzung und schulischen Leistungen (obj_performance_child_wX).",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Lagged und Cross-Lagged Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel-panel.html",
    "href": "multilevel-panel.html",
    "title": "5  Multilevel-Längsschnittanalyse",
    "section": "",
    "text": "5.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für die Fixed-Effect-Modelle verwenden wir plm, für die Multilevel-Analysen das lme4-Paket, für die Modellvorhersagen marginaleffects. Wie immer laden wir tidyverse und report und setzen ein schöneres Theme.\nlibrary(plm)\nlibrary(lme4)\nlibrary(marginaleffects)\n\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nAls Datensatz verwenden wir eine Studie von Johannes et al., bei der dieselben Befragten 6 Wochen lang unterschiedliche Mediennutzung und Lebenszufriedenheit berichtet haben. Der Datensatz ist im sog. Langformat, d.h. die Daten aller Wellen werden aufeinander gestapelt, dementsprechend gibt es n = Personen x Wellen Datenzeilen. Die Personen sind mit der Variable id gekennzeichnet, die Erhebungswoche mit wave. Die weiteren Variablen geben dann jeweils die Messung einer Person in einer Woche wieder, stabile Personenmerkmale wie Alter wiederholen sich entsprechend pro Person.\nd_johannes &lt;- read_rds(\"data/johannes_etal.rds\") |&gt;\n  filter(wave &gt;= 2) |&gt;\n  filter(!is.na(tv_time))\nd_johannes\n\n# A tibble: 8,882 × 122\n  id    gender  wave   age filter_music filter_films filter_tv\n  &lt;fct&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;\n1 pp_2  Female     2    22            1            0         0\n2 pp_2  Female     3    22            1            0         0\n3 pp_2  Female     5    22            1            0         0\n4 pp_3  Male       2    43            1            1         0\n5 pp_3  Male       3    43            1            1         0\n# ℹ 8,877 more rows\n# ℹ 115 more variables: filter_video_games &lt;dbl&gt;, filter_ebooks &lt;dbl&gt;,\n#   filter_magazines &lt;dbl&gt;, filter_audiobooks &lt;dbl&gt;, music_estimate &lt;dbl&gt;,\n#   music_identity_1 &lt;dbl&gt;, music_identity_2 &lt;dbl&gt;, music_identity_3 &lt;dbl&gt;,\n#   music_identity_4 &lt;dbl&gt;, music_identity_5 &lt;dbl&gt;, music_identity_6 &lt;dbl&gt;,\n#   music_identity_7 &lt;dbl&gt;, music_time &lt;dbl&gt;, music_identity &lt;dbl&gt;,\n#   films_estimate &lt;dbl&gt;, films_identity_1 &lt;dbl&gt;, films_identity_2 &lt;dbl&gt;, …\nDa der Datensatz im sog. Langformat ist, gibt es mehrere Zeilen pro Person (eine pro Welle). Wir zählen mit n_distinct() die tatsächliche Personenstichprobe:\nn_distinct(d_johannes$id)\n\n[1] 2159\nZudem schauen wir uns die Deskriptivstatistiken der relevanten Variablen an.\nd_johannes |&gt;\n  select(wave, life_satisfaction, tv_time, gender) |&gt;\n  report::report_table()\n\nVariable          |  Level | n_Obs | percentage_Obs | Mean |   SD | Median |  MAD |  Min |   Max | Skewness | Kurtosis | percentage_Missing\n-------------------------------------------------------------------------------------------------------------------------------------------\nwave              |        |  8882 |                | 3.71 | 1.32 |   4.00 | 1.48 | 2.00 |  6.00 |     0.21 |    -1.12 |               0.00\nlife_satisfaction |        |  8882 |                | 6.40 | 2.09 |   7.00 | 1.48 | 0.00 | 10.00 |    -0.85 |     0.48 |               0.00\ntv_time           |        |  8882 |                | 3.37 | 3.30 |   3.00 | 2.97 | 0.00 | 22.00 |     1.90 |     5.30 |               0.00\ngender            |  Other |     5 |           0.06 |      |      |        |      |      |       |          |          |                   \ngender            |   Male |  4283 |          48.22 |      |      |        |      |      |       |          |          |                   \ngender            | Female |  4594 |          51.72 |      |      |        |      |      |       |          |          |\nWir können an der Deskriptivstatistik erkennen, dass Daten über 5 Wochen (Wave 2-6, Woche 1 ist laut Autoren problematisch und wird daher ausgeschlossen) vorliegen und die Befragten im Mittel etwas über 3,5h TV am Tag sehen (SD 3,3h).",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multilevel-Längsschnittanalyse</span>"
    ]
  },
  {
    "objectID": "multilevel-panel.html#ols-modelle",
    "href": "multilevel-panel.html#ols-modelle",
    "title": "5  Multilevel-Längsschnittanalyse",
    "section": "5.2 OLS Modelle",
    "text": "5.2 OLS Modelle\n\n5.2.1 Naives Model (pooling)\nIm folgenden Beispiel wollen wir den Zusammenhang zwischen der TV-Nutzung und allgemeiner Lebenszufriedenheit untersuchen. Das naive Regressionsmodell ignoriert die Schachtelung bzw. Nicht-Unabhängigkeit der Daten und tut so, als hätten wir n = 8882 unabhängige Fälle.\n\nresults_ols &lt;- lm(life_satisfaction ~ tv_time, data = d_johannes)\nreport::report_table(results_ols)\n\nParameter   | Coefficient |         95% CI | t(8880) |      p | Std. Coef. | Std. Coef. 95% CI |      Fit\n---------------------------------------------------------------------------------------------------------\n(Intercept) |        6.47 | [ 6.41,  6.53] |  204.44 | &lt; .001 |  -1.66e-15 |    [-0.02,  0.02] |         \ntv time     |       -0.02 | [-0.03, -0.01] |   -3.00 | 0.003  |      -0.03 |    [-0.05, -0.01] |         \n            |             |                |         |        |            |                   |         \nAIC         |             |                |         |        |            |                   | 38281.92\nAICc        |             |                |         |        |            |                   | 38281.92\nBIC         |             |                |         |        |            |                   | 38303.19\nR2          |             |                |         |        |            |                   | 1.02e-03\nR2 (adj.)   |             |                |         |        |            |                   | 9.03e-04\nSigma       |             |                |         |        |            |                   |     2.09\n\n\nDer Effekt der TV-Nutzung ist negativ und statistisch signifikant, aber wir wissen das dieser Schätzer und der Standardfehler verzerrt sind.\n\n\n5.2.2 Fixed Effects Modell\nEin (vor allem in Politik- und Wirtschaftswissenschaften) weit verbreiteter Ansatz für die Analyse von Paneldaten ist das Fixed Effects (FE) Modell, durch das alle (beobachteten wie unbeobachteten) Unterschiede in der Lebenszufriedenheit zwischen den Befragten im Modell herausgerechnet werden. Technisch geht dies über zwei Wege:\n\nDe-meaning, d.h. von allen individuellen Werten der Prädiktoren wird der Personenmittelwert abgezogen, d.h. der neue Prädiktor ist als Abweichung vom Mittelwert zu verstehen. Der Regressionskoeffizient dieser Variable ist der Within-Effekt.\nDie Befragten-ID als nominale (Dummy-)Koviate in das Modell integriert wird (Least Squares Dummy Variable, LSDV-Modell), der dann übrig bleibende Effekt der TV-Nutzung auf die Lebenszufriedenheit ist der Within-Effekt.\n\nBeide Ansätze werden als FE-Modell bezeichnet, die Koeffizienten als Within-Person-Effects.\nFür das De-Meaning verwenden wir einfach die Kombination aus group_by() und mutate(). Anschließend schätzen wir das Modell mit dem neuen Prädiktor, aber ohne Konstante (-1 + ...) im Modell. Die Within-Variable ist die Abweichung der (wöchentlichen) TV-Nutzung vom Personenmittelwert. Wenn eine Befragte im Mittel über alle Wochen 4h TV pro Tag nutzt, aber in Woche 3 nur 2h, dann bekäme sie in diesem Fall den Wert -2. Dies führt dazu, dass wir den Koeffizienten dieser Within-Variable dahingehend interpretieren können, dass die Lebenszufriedenheit derselben Person um B Einheiten sinkt/steigt, wenn sie in einer Woche eine Stunde mehr TV gesehen hat als sonst.\n\nd_johannes &lt;- d_johannes |&gt;\n  group_by(id) |&gt;\n  mutate(tv_time_within = tv_time - mean(tv_time, na.rm = TRUE))\n\nresults_fe_demean &lt;- lm(life_satisfaction ~ -1 + tv_time_within, d_johannes)\nreport::report_table(results_fe_demean)\n\nParameter      | Coefficient |        95% CI | t(8881) |     p | Std. Coef. | Std. Coef. 95% CI |       Fit\n-----------------------------------------------------------------------------------------------------------\ntv time within |   -2.56e-03 | [-0.09, 0.09] |   -0.06 | 0.956 |  -1.89e-03 |     [-0.02, 0.02] |          \n               |             |               |         |       |            |                   |          \nAIC            |             |               |         |       |            |                   |  59093.01\nAICc           |             |               |         |       |            |                   |  59093.01\nBIC            |             |               |         |       |            |                   |  59107.19\nR2             |             |               |         |       |            |                   |  3.43e-07\nR2 (adj.)      |             |               |         |       |            |                   | -1.12e-04\nSigma          |             |               |         |       |            |                   |      6.74\n\n\nDer Koeffizient gibt den Within-Person-Effekt wieder, er ist nicht signifikant. Allerdings stimmen beim manuellen De-Meaning und anschließenden Schätzen ohne Intercept die Freiheitsgrade nicht, und damit auch die p-Werte und CI. Daher empfiehlt es sich, für FE-Modell spezielle R-Pakete zu verwenden, z.B. plm.\n\nresults_fe &lt;- plm::plm(life_satisfaction ~ tv_time, index = \"id\", data = d_johannes, model = \"within\")\nsummary(results_fe)\n\nOneway (individual) effect Within Model\n\nCall:\nplm::plm(formula = life_satisfaction ~ tv_time, data = d_johannes, \n    model = \"within\", index = \"id\")\n\nUnbalanced Panel: n = 2159, T = 2-5, N = 8882\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-5.5005 -0.2997  0.0000  0.3000  4.5020 \n\nCoefficients:\n          Estimate Std. Error t-value Pr(&gt;|t|)\ntv_time -0.0025554  0.0051773 -0.4936   0.6216\n\nTotal Sum of Squares:    3816.2\nResidual Sum of Squares: 3816.1\nR-Squared:      3.6242e-05\nAdj. R-Squared: -0.32114\nF-statistic: 0.243626 on 1 and 6722 DF, p-value: 0.62162\n\n\n\n\n\n\n\n\nLSDV- vs. FE-Modell\n\n\n\nDa das LSDV-Modell mit lm() und vielen Befragten sehr lange zu schätzen braucht, illustrieren wir diesen Ansatz hier mit einem kleinen Datensatz von 10 Befragten:\n\nd_johannes10 &lt;- d_johannes |&gt;\n  filter(id %in% sample(d_johannes$id, size = 10))\n\nlm(life_satisfaction ~ -1 + tv_time + id, data = d_johannes10) |&gt;\n  report::report_table() |&gt;\n  head(3)\n\nParameter    | Coefficient |        95% CI | t(36) |      p | Std. Coef. | Std. Coef. 95% CI | Fit\n--------------------------------------------------------------------------------------------------\ntv time      |       -0.01 | [-0.24, 0.22] | -0.11 | 0.909  |      -0.02 |    [-0.32,  0.29] |    \nid [pp_1412] |        7.06 | [ 5.83, 8.28] | 11.68 | &lt; .001 |      -0.16 |    [-0.74,  0.42] |    \nid [pp_2043] |        5.90 | [ 5.04, 6.76] | 13.93 | &lt; .001 |      -1.02 |    [-1.59, -0.46] |    \n\n\nDie Personen-Fixed-Effects interessieren uns substanziell nicht, sondern nur der TV-Nutzungseffekt, der den vorausgesagten Zuwachs/Verlust an Lebenszufriedenheit bei ein und derselben Person widergibt, wenn diese eine Stunde mehr fernsehen würde.\nHier das klassische FE-Modell mit plm().\n\nplm::plm(life_satisfaction ~ tv_time, data = d_johannes10, model = \"within\", index = \"id\") |&gt;\n  summary()\n\nOneway (individual) effect Within Model\n\nCall:\nplm::plm(formula = life_satisfaction ~ tv_time, data = d_johannes10, \n    model = \"within\", index = \"id\")\n\nUnbalanced Panel: n = 11, T = 2-5, N = 48\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-1.9000000 -0.2882804  0.0013022  0.2812500  1.6000000 \n\nCoefficients:\n         Estimate Std. Error t-value Pr(&gt;|t|)\ntv_time -0.013022   0.113382 -0.1148   0.9092\n\nTotal Sum of Squares:    18.888\nResidual Sum of Squares: 18.881\nR-Squared:      0.00036627\nAdj. R-Squared: -0.30508\nF-statistic: 0.0131904 on 1 and 36 DF, p-value: 0.9092\n\n\nDie “Vergleichsgruppe” sind im Gegensatz zum naiven Modell also nicht (nur) die anderen Personen, sondern ausschließlich die anderen Messungen derselben Person. Dies wird als kausaler Effekt der TV-Nutzung auf die Lebenszufriedenheit interpretiert. Im vorliegenden Beispiel ist der Effekt praktisch null (wobei wir nur eine kleine Substichprobe untersucht haben).\n\n\nDer zentrale Nachteil des FE-Modells ist die Tatsache, dass wir keine nicht-variierenden Personenmerkmale als Prädiktor ins Modell aufnehmen können, z.B. Geschlecht:\n\nresults_fe_gender &lt;- plm::plm(life_satisfaction ~ tv_time + gender, data = d_johannes, model = \"within\", index = \"id\")\nsummary(results_fe_gender)\n\nOneway (individual) effect Within Model\n\nCall:\nplm::plm(formula = life_satisfaction ~ tv_time + gender, data = d_johannes, \n    model = \"within\", index = \"id\")\n\nUnbalanced Panel: n = 2159, T = 2-5, N = 8882\n\nResiduals:\n   Min. 1st Qu.  Median 3rd Qu.    Max. \n-5.5005 -0.2997  0.0000  0.3000  4.5020 \n\nCoefficients:\n          Estimate Std. Error t-value Pr(&gt;|t|)\ntv_time -0.0025554  0.0051773 -0.4936   0.6216\n\nTotal Sum of Squares:    3816.2\nResidual Sum of Squares: 3816.1\nR-Squared:      3.6242e-05\nAdj. R-Squared: -0.32114\nF-statistic: 0.243626 on 1 and 6722 DF, p-value: 0.62162\n\n\nWeil alle beobachteten (und nicht beobachteten) Unterschiede zwischen den Befragten beim LSDV-Modell schon durch die id-Kovariate abgebildet werden bzw. beim FE-Modell die Unterschiede zwischen Personen verschwinden, sind alle Personenvariablen wie Alter oder Geschlecht perfekt multikollinear, und wir erhalten daher keine Schätzung für ihren Einfluss. Wenn wir gleichsam die Nicht-Unabhängigkeit der Daten und Personen-Kovariaten berücksichtigen wollen, brauchen wir ein alternatives Modell, das Random Effects Modell.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multilevel-Längsschnittanalyse</span>"
    ]
  },
  {
    "objectID": "multilevel-panel.html#multilevel-modelle",
    "href": "multilevel-panel.html#multilevel-modelle",
    "title": "5  Multilevel-Längsschnittanalyse",
    "section": "5.3 Multilevel-Modelle",
    "text": "5.3 Multilevel-Modelle\n\n5.3.1 Random Effects Modell\nIm Random Effects Modell werden nicht mehr alle Befragten als fixe Variablen ins Modell genommen, sondern es wird ein Multilevel-Modell geschätzt, bei dem Messungen auf Level 1 sind und Befragte auf Level 2. Die Annahme dabei ist, dass die Unterschiede in der mittleren Lebenszufriedenheit der Befragten einer Normalverteilung folgen, d.h. manche Befragten sind im Mittel (un-)zufriedener als andere. Diese Modell wird als Random Intercept Modell bezeichnet, wobei random hier nicht bedeutet, dass die Intercepts pro Person rein zufällig streuen, sondern sie einer Zufallsvariable (Normalverteilung) entsprechen, daher bezeichnen wir es auch lieber als Varying Intercept Modell\nIn R kann man Multilevel-Modelle mit dem lme4-Paket schätzen. Die Random (oder besser: nach Personen variierenden) Intercepts werden mit (1 | id) spezifiziert.\n\nresults_re &lt;- lme4::lmer(life_satisfaction ~ tv_time + (1 | id), data = d_johannes)\nreport::report_table(results_re)\n\nParameter        | Coefficient |        95% CI | t(8878) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n----------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.42 | [ 6.33, 6.51] |  140.43 | &lt; .001 |   fixed |          |  -8.95e-04 |     [-0.04, 0.04] |         \ntv time          |   -5.74e-03 | [-0.02, 0.00] |   -1.18 | 0.239  |   fixed |          |  -9.06e-03 |     [-0.02, 0.01] |         \n                 |        1.94 |               |         |        |  random |       id |            |                   |         \n                 |        0.75 |               |         |        |  random | Residual |            |                   |         \n                 |             |               |         |        |         |          |            |                   |         \nAIC              |             |               |         |        |         |          |            |                   | 27350.19\nAICc             |             |               |         |        |         |          |            |                   | 27350.19\nBIC              |             |               |         |        |         |          |            |                   | 27378.55\nR2 (conditional) |             |               |         |        |         |          |            |                   |     0.87\nR2 (marginal)    |             |               |         |        |         |          |            |                   | 8.25e-05\nSigma            |             |               |         |        |         |          |            |                   |     0.75\n\n\nDie Ergebnisse des RE-Modells zeigen einen winzigen, nicht-signifikanten Effekt der TV-Nutzung auf die Lebenszufriedenheit, was den Ergebnissen des naiven OLS-Modells oben widerspricht.\nIm Gegensatz zum FE-Modell ist es problemlos möglich, beliebige variierende oder stabile (Personen-)Variablen als Prädiktoren in das Modell aufzunehmen, z.B. wieder Geschlecht:\n\nresults_re_gender &lt;- lme4::lmer(life_satisfaction ~ tv_time + gender + (1 | id), data = d_johannes)\nreport::report_table(results_re_gender)\n\nParameter        | Coefficient |        95% CI | t(8876) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n----------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.46 | [ 6.33, 6.58] |  101.45 | &lt; .001 |   fixed |          |       0.02 |     [-0.04, 0.07] |         \ntv time          |   -5.71e-03 | [-0.02, 0.00] |   -1.17 | 0.241  |   fixed |          |  -9.02e-03 |     [-0.02, 0.01] |         \ngender [Female]  |       -0.07 | [-0.24, 0.10] |   -0.84 | 0.402  |   fixed |          |      -0.03 |     [-0.11, 0.05] |         \ngender [Other]   |       -0.75 | [-4.62, 3.12] |   -0.38 | 0.705  |   fixed |          |      -0.36 |     [-2.21, 1.49] |         \n                 |        1.94 |               |         |        |  random |       id |            |                   |         \n                 |        0.75 |               |         |        |  random | Residual |            |                   |         \n                 |             |               |         |        |         |          |            |                   |         \nAIC              |             |               |         |        |         |          |            |                   | 27353.24\nAICc             |             |               |         |        |         |          |            |                   | 27353.25\nBIC              |             |               |         |        |         |          |            |                   | 27395.79\nR2 (conditional) |             |               |         |        |         |          |            |                   |     0.87\nR2 (marginal)    |             |               |         |        |         |          |            |                   | 4.47e-04\nSigma            |             |               |         |        |         |          |            |                   |     0.75\n\n\nWir erkennen, dass es keine signifikanten Geschlechtsunterschiede in der Lebenszufriedenheit gibt, obwohl zumindest in der Stichprobe Frauen und vor allem andere Geschlechter etwas weniger zufrieden sind.\n\n\n5.3.2 REWB Modell\nObwohl das RE-Modell deutlich flexibler in der Anwendung ist, wird es in der Praxis oft kritisiert, weil beim RE-Modell nicht gewährleistet ist, dass der Effekt des Prädiktors als kausaler Effekt unter Kontrolle aller beobachteten und unbeobachteten Unterschiede zwischen den Befragten zu interpretieren ist. Dies kann man aber durch eine spezielle Spezifikation des Modells als Random Effects Within-Beween Modell beheben, dass die Vorteile des FE-Modells (unverzerrter Schätzer des kausalen Within-Person Effekts) mit denen des RE-Modells (flexible Integration weiterer Kovariaten) verbindet.\nPraktisch wird jede Prädiktorvariable in einen Within-Person und einen Between-Person-Bestandteil zerlegt. Die Between-Variable ist nichts anderes als der Personenmittelwert der TV-Nutzung einer Person über alle Wellen, also die mittlere TV-Nutzung pro Person. Die Vergleichsgruppe sind also wie im FE-Modell nicht die anderen Personen, sondern die jeweils anderen Messungen derselben Person. Daher braucht sowohl das FE als auch das REWB-Modell min. 3 Messungen pro Person, um überhaupt Personen-Mittelwert und Abweichungen vom Mittelwert berechnen zu können. Wir nutzen wieder group_by() + mutate(), um zusätzlich zum Within-Prädiktor auch den Between-Prädiktor, also den Personenmittelwert ins Modell zu integrieren:\n\nd_johannes &lt;- d_johannes |&gt;\n  group_by(id) |&gt;\n  mutate(\n    tv_time_between = mean(tv_time, na.rm = TRUE)\n  )\n\nAnschließend schätzen wir das REWB-Modell, bei dem für TV-Nutzung nun zwei Prädiktorvariablen im Modell sind - einmal within einmal between.\n\nresults_rewb &lt;- lme4::lmer(life_satisfaction ~ tv_time_within + tv_time_between + (1 | id), data = d_johannes)\nreport::report_table(results_rewb)\n\nParameter        | Coefficient |         95% CI | t(8877) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n-----------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.50 | [ 6.38,  6.63] |  100.40 | &lt; .001 |   fixed |          |  -4.82e-04 |    [-0.04,  0.04] |         \ntv time within   |   -2.56e-03 | [-0.01,  0.01] |   -0.49 | 0.622  |   fixed |          |  -1.89e-03 |    [-0.01,  0.01] |         \ntv time between  |       -0.03 | [-0.06,  0.00] |   -2.11 | 0.035  |   fixed |          |      -0.04 |    [-0.08,  0.00] |         \n                 |        1.94 |                |         |        |  random |       id |            |                   |         \n                 |        0.75 |                |         |        |  random | Residual |            |                   |         \n                 |             |                |         |        |         |          |            |                   |         \nAIC              |             |                |         |        |         |          |            |                   | 27355.43\nAICc             |             |                |         |        |         |          |            |                   | 27355.44\nBIC              |             |                |         |        |         |          |            |                   | 27390.89\nR2 (conditional) |             |                |         |        |         |          |            |                   |     0.87\nR2 (marginal)    |             |                |         |        |         |          |            |                   | 1.79e-03\nSigma            |             |                |         |        |         |          |            |                   |     0.75\n\n\nWie können wir nun die beiden Koeffizienten interpretieren: Der (minimale und nicht-signifikante) Within-Effekt entspricht exakt dem FE-Modell und zeigt, dass intra-individuelle Schwankungen in der wöchentlichen TV-Nutzung nicht mit Schwankungen in der Lebenszufriedenheit einhergehen. TV-Nutzung macht die Befragten offenbar weder zufriedener noch unzufriedener. Wir sehen aber am negativen Between-Effekt, dass es Unterschiede in der mittleren Lebenszufriedenheit zwischen intensiven und sporadischen TV-Nutzerinnen gibt: Personen, die im Mittel mehr fernsehen, sind im Mittel etwas unzufriedener, oder anders formuliert: Personen, die im Mittel zufriedener sind, schauen im Mittel etwas weniger fern. Diesen Between-Effekt kann man aber nicht kausal interpretieren, sondern nur als Korrelation.\nWir visualisieren hier noch einmal den Within-Effekt und sehen, dass selbst 10h mehr oder weniger tägliche TV-Nutzung als sonst die Lebenszufriedenheit nur minimal beeinflusst.\n\npreds_rewb &lt;- marginaleffects::avg_predictions(results_rewb, variables = \"tv_time_within\")\npreds_rewb |&gt;\n  ggplot(aes(x = tv_time_within, y = estimate, ymin = conf.low, ymax = conf.high)) +\n  geom_line() +\n  geom_ribbon(alpha = .1) +\n  labs(x = \"difference in TV use (hours per day)\", y = \"Predicted life satisfaction\")\n\n\n\n\n\n\n\n\nWie zuvor können wir weitere Kovariaten ins Modell aufnehmen, sowohl auf Ebene der wöchentlichen Messung als auch auf Personenebene.\n\nresults_rewb_gender &lt;- lme4::lmer(life_satisfaction ~ tv_time_within + tv_time_between + gender + (1 | id), data = d_johannes)\nreport::report_table(results_rewb_gender)\n\nParameter        | Coefficient |         95% CI | t(8875) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n-----------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.54 | [ 6.39,  6.69] |   83.91 | &lt; .001 |   fixed |          |       0.02 |    [-0.04,  0.07] |         \ntv time within   |   -2.56e-03 | [-0.01,  0.01] |   -0.49 | 0.622  |   fixed |          |  -1.89e-03 |    [-0.01,  0.01] |         \ntv time between  |       -0.03 | [-0.06,  0.00] |   -2.09 | 0.037  |   fixed |          |      -0.04 |    [-0.08,  0.00] |         \ngender [Female]  |       -0.07 | [-0.24,  0.10] |   -0.80 | 0.424  |   fixed |          |      -0.03 |    [-0.11,  0.05] |         \ngender [Other]   |       -0.78 | [-4.65,  3.08] |   -0.40 | 0.692  |   fixed |          |      -0.37 |    [-2.23,  1.48] |         \n                 |        1.94 |                |         |        |  random |       id |            |                   |         \n                 |        0.75 |                |         |        |  random | Residual |            |                   |         \n                 |             |                |         |        |         |          |            |                   |         \nAIC              |             |                |         |        |         |          |            |                   | 27358.54\nAICc             |             |                |         |        |         |          |            |                   | 27358.55\nBIC              |             |                |         |        |         |          |            |                   | 27408.18\nR2 (conditional) |             |                |         |        |         |          |            |                   |     0.87\nR2 (marginal)    |             |                |         |        |         |          |            |                   | 2.12e-03\nSigma            |             |                |         |        |         |          |            |                   |     0.75\n\n\n\n\n5.3.3 Wachstumsmodell\nNeben den klassischen FE- und RE-Modellen sind sogenannte Wachstumsmodelle in den Sozialwissenschaften weit verbreitet, vor allem im Bereich der Entwicklungspsychologie oder Jugendmedienforschung. Hier geht es zunächst gar nicht darum, den (kausalen) Effekt einer Variable auf eine andere zu schätzen, sondern zunächst zu prüfen, ob ein Outcome sich über die Zeit (linear) verändert. In unserem Beispiel könnten wir fragen, ob sich die Lebenszufriedenheit im Laufe der fünfwöchigen Studienphase verändert hat. Hierfür verwenden wir die Zeitvariable wave einfach als numerischen Prädiktor, lassen aber weiterhin personenspezifische Mittel- bzw. Ausgangswerte (Random Intercepts) zu:\n\nresults_time1 &lt;- lme4::lmer(life_satisfaction ~ wave + (1 | id), data = d_johannes)\nreport::report_table(results_time1)\n\nParameter        | Coefficient |       95% CI | t(8878) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n---------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.33 | [6.24, 6.43] |  130.67 | &lt; .001 |   fixed |          |  -1.69e-04 |     [-0.04, 0.04] |         \nwave             |        0.02 | [0.01, 0.03] |    2.96 | 0.003  |   fixed |          |       0.01 |     [ 0.00, 0.02] |         \n                 |        1.94 |              |         |        |  random |       id |            |                   |         \n                 |        0.75 |              |         |        |  random | Residual |            |                   |         \n                 |             |              |         |        |         |          |            |                   |         \nAIC              |             |              |         |        |         |          |            |                   | 27342.31\nAICc             |             |              |         |        |         |          |            |                   | 27342.31\nBIC              |             |              |         |        |         |          |            |                   | 27370.68\nR2 (conditional) |             |              |         |        |         |          |            |                   |     0.87\nR2 (marginal)    |             |              |         |        |         |          |            |                   | 1.42e-04\nSigma            |             |              |         |        |         |          |            |                   |     0.75\n\n\nIn der Tat sehen wir einen winzigen, positiven, statistisch signifikanten Regressionskoeffizienten für Wave: Jede Woche nahm die mittlere Lebenszufriedenheit der Befragten um 0,02 (!) Skalenpunkte zu. Der Intercept gibt den geschätzten Ausgangswert zu Woche 0 wider, in dem aber gar keine Messung stattfand. Wir können aber den Intercept durch zentrieren der wave-Variable interpretierbarer machen.\nMithilfe von Modellvorhersagen können wir das geschätzte Wachstum auch visualisieren:\n\nmarginaleffects::avg_predictions(results_time1, variables = c(\"wave\")) |&gt;\n  ggplot(aes(\n    x = wave, y = estimate, ymin = conf.low, ymax = conf.high,\n  )) +\n  geom_line() +\n  geom_ribbon(alpha = .1) +\n  labs(x = \"Week\", y = \"Predicted life satisfaction\")\n\n\n\n\n\n\n\n\nBei Wachstumsmodellen ist die Annahmen zumeist, dass nicht alle Individuen sich gleichartig entwickeln: Manche Befragten werden mit der Zeit vielleicht sehr viel zufriedener, andere unzufriedener, andere sind immer gleich zufrieden. Um dies zu modellieren, können wir den Koeffizienten für das Wachstum auch nach Personen variieren lassen (Random bzw. Varying Slope). Wir gehen also davon aus, dass Befragte unterschiedliche Ausgangswerte und unterschiedliche Entwicklungsverläufe haben können. Dies spezifizieren wir durch den Term (1 + wave | id), d.h. beides darf nach Personen variieren.\n\nresults_time2 &lt;- lme4::lmer(life_satisfaction ~ wave + (1 + wave | id), data = d_johannes)\n\nMit Hilfe der anova()-Funktion können wir die Güte der beiden Modelle vergleichen:\n\nanova(results_time1, results_time2)\n\nData: d_johannes\nModels:\nresults_time1: life_satisfaction ~ wave + (1 | id)\nresults_time2: life_satisfaction ~ wave + (1 + wave | id)\n              npar   AIC   BIC logLik deviance  Chisq Df Pr(&gt;Chisq)    \nresults_time1    4 27330 27358 -13661    27322                         \nresults_time2    6 27226 27268 -13607    27214 107.87  2  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWir sehen, dass das Modell mit den variierenden Intercepts und Slopes signifikant besser zu den Daten passt, d.h. es gibt bedeutsame Heterogenität in der Entwicklung der Lebenszufriedenheit. Ändert dies etwas an unserem Punktschätzer für wave?\n\nreport::report_table(results_time2)\n\nParameter        | Coefficient |       95% CI | t(8876) |      p | Effects |    Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n---------------------------------------------------------------------------------------------------------------------------------\n(Intercept)      |        6.33 | [6.24, 6.43] |  132.29 | &lt; .001 |   fixed |          |  -3.24e-04 |     [-0.04, 0.04] |         \nwave             |        0.02 | [0.00, 0.03] |    2.56 | 0.011  |   fixed |          |       0.01 |     [ 0.00, 0.02] |         \n                 |        1.93 |              |         |        |  random |       id |            |                   |         \n                 |        0.17 |              |         |        |  random |       id |            |                   |         \n                 |       -0.13 |              |         |        |  random |       id |            |                   |         \n                 |        0.71 |              |         |        |  random | Residual |            |                   |         \n                 |             |              |         |        |         |          |            |                   |         \nAIC              |             |              |         |        |         |          |            |                   | 27238.19\nAICc             |             |              |         |        |         |          |            |                   | 27238.20\nBIC              |             |              |         |        |         |          |            |                   | 27280.74\nR2 (conditional) |             |              |         |        |         |          |            |                   |     0.88\nR2 (marginal)    |             |              |         |        |         |          |            |                   | 1.36e-04\nSigma            |             |              |         |        |         |          |            |                   |     0.71\n\n\nNein.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multilevel-Längsschnittanalyse</span>"
    ]
  },
  {
    "objectID": "multilevel-panel.html#glossar",
    "href": "multilevel-panel.html#glossar",
    "title": "5  Multilevel-Längsschnittanalyse",
    "section": "5.4 Glossar",
    "text": "5.4 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nlme4::lmer\nMultilevel-Modelle schätzen",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multilevel-Längsschnittanalyse</span>"
    ]
  },
  {
    "objectID": "multilevel-panel.html#hausaufgabe",
    "href": "multilevel-panel.html#hausaufgabe",
    "title": "5  Multilevel-Längsschnittanalyse",
    "section": "5.5 Hausaufgabe",
    "text": "5.5 Hausaufgabe\nUntersuchen Sie den (kausalen) Zusammenhang zwischen wöchentlicher Musiknutzung (music_time) und Lebenszufriedenheit mit einem FE oder REWB-Modell.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Multilevel-Längsschnittanalyse</span>"
    ]
  },
  {
    "objectID": "multilevel.html",
    "href": "multilevel.html",
    "title": "6  Multilevel-Modelle",
    "section": "",
    "text": "6.1 Pakete und Daten\nWir laden zunächst wie immer die notwendigen R-Pakete. Für Multilevel-Modelle benötigen wir das lme4- und das marginaleffects-Paket. Wie immer laden wir außerdem tidyverse und report. Für eine schönere Darstellung der Plots setzen wir außerdem das Theme auf theme_minimal.\nlibrary(lme4)\nlibrary(marginaleffects)\nlibrary(tidyverse)\nlibrary(report)\ntheme_set(theme_minimal())\nFür die Multilevel-Analyse nutzen wir den Datensatz zoizner_etal.csv. Die Autor:innen untersuchen, inwieweit Bürger:innen nach dem Ausbruch der Covid19-Pandemie Informationen aus Quellen erhalten haben, deren Inhalte sie normalerweise nicht unbedingt konsumieren. Dazu führten sie eine zweiwellige Panelbefragung in 17 Ländern vor und nach dem Ausbruch der Pandemie durch. Der Datensatz enthält unter anderem die folgenden Variablen: Cross-cutting Exposure in Bezug auf traditionelle Medien (wie häufig werden Personen mit Informationen aus Quellen konfrontiert, deren Inhalte sie normalerweise nicht konsumieren), Besorgnis über die COVID-19-Pandemie und das Land, aus dem die Befragten stammen.\nUm die Cross-cutting Exposure zu bestimmen, wurden die Befragten zum einen nach der Häufigkeit der Nutzung bestimmer Medien (nie bis täglich) und ihrer politischen Einstellung (links bis rechts) gefragt. Zum anderen wurden die Medien mit Hilfe von Expert:innen nach ihrer Ideologie (links bis rechts) eingeordnet. Die politische Einstellung der Befragten wurde mit der ideologischen Einordnung der Medien und der Häufigkeit der Mediennutzung korreliert. Die Variable Cross-Cutting Exposure nimmt einen Wert zwischen 0 und 1 an (je höher, desto mehr Cross-Cutting Exposure).\nd_zoizner &lt;- read_csv(\"data/zoizner_etal.csv\")\nd_zoizner\n\n# A tibble: 14,218 × 36\n   ...1  wave date_W2_dateformat_1day_before cross_cutting_consumption_w2_01\n  &lt;dbl&gt; &lt;dbl&gt; &lt;date&gt;                                                   &lt;dbl&gt;\n1     1     2 2020-05-13                                              0.0333\n2     2     2 2020-05-04                                              0.233 \n3     3     2 2020-05-04                                              0     \n4     4     2 2020-05-11                                             NA     \n5     5     2 2020-05-11                                             NA     \n# ℹ 14,213 more rows\n# ℹ 32 more variables: worried_from_covid_total_01 &lt;dbl&gt;, age &lt;dbl&gt;,\n#   female &lt;chr&gt;, female_numeric &lt;dbl&gt;, education_numeric &lt;dbl&gt;,\n#   political_interest_w2 &lt;dbl&gt;, political_knowledge_w2 &lt;dbl&gt;,\n#   right_ideology_w2 &lt;dbl&gt;, right_ideology_w2_binary &lt;chr&gt;,\n#   news_consumption_internet_w2 &lt;dbl&gt;, news_consumption_socialmedia_w2 &lt;dbl&gt;,\n#   cross_cutting_consumption_w1_01 &lt;dbl&gt;, …\nMultilevel-Modelle werden für die Analyse von hierarchisch geschachtelten Daten verwendet. Diese Datenstruktur liegt hier ebenfalls vor, da Befragte aus unterschiedlichen Ländern enthalten sind. Die Befragten können in Länder geschachtelt werden, sie bilden damit eine Ebene unterhalb der Länder. Entsprechend liegen in unserem Datensatz zwei Ebenen vor: die Länder (Level 2) und die Befragten (Level 1). Unsere abhängige Variable, die Cross-Cutting Exposure zu T2,wurde auf dem Befragtenlevel (Level 1) gemessen.\nWir betrachten zunächst die Level-2-Variable (country), in dem wir uns die Anzahl der Befragten pro Land in unserer Stichprobe ausgeben lassen.\ncount(d_zoizner, dCountry_W2)\n\n# A tibble: 17 × 2\n  dCountry_W2     n\n  &lt;chr&gt;       &lt;int&gt;\n1 Austria       852\n2 Belgium       764\n3 Denmark       751\n4 France        889\n5 Germany       968\n# ℹ 12 more rows\nInsgesamt sind Befragte aus 17 Ländern in der Stichprobe enthalten.\nWie bei allen Analysen lohnt sich auch bei Mutlilevel-Modellen ein Blick auf die Verteilung der Outcome-Variable, in diesem Fall die Cross-Cutting Exposure zu T2 (Level 1).\nd_zoizner |&gt;\n  select(cross_cutting_consumption_w2_01) |&gt;\n  report::report_sample()\n\n# Descriptive Statistics\n\nVariable                                  |     Summary\n-------------------------------------------------------\nMean cross_cutting_consumption_w2_01 (SD) | 0.27 (0.26)\nÜber alle Länder hinweg beträgt die durchschnittliche Cross-Cutting Exposure zum Zeitpunkt T2 .27 (SD = .26).",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#nullmodell-und-icc",
    "href": "multilevel.html#nullmodell-und-icc",
    "title": "6  Multilevel-Modelle",
    "section": "6.2 Nullmodell und ICC",
    "text": "6.2 Nullmodell und ICC\nZunächst berechnen wir ein Nullmodel, welches Auskunft darüber gibt, wie sich die Varianz auf die verschiedenen Ebenen verteilt. Das Modell schätzt zunächst ohne erklärende Variablen die Durchschnittswerte der Variablen cross_cutting_consumption_w2_01 und berücksichtigt dabei die zufälligen Abweichungen zwischen den Ländern (dCountry_W2).\n\nm0_cc &lt;- lmer(cross_cutting_consumption_w2_01 ~ 1 + (1 | dCountry_W2), d_zoizner)\n\nDiese Varianzen können wir nutzen, um den Intraklassenkorrelationskoeffizient (ICC) zu berechnen, der einen Hinweis darauf gibt, ob ein Multilevel-Modell überhaupt nötig ist.\n\nperformance::icc(m0_cc)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.102\n  Unadjusted ICC: 0.102\n\n\nEtwa 10% der Varianz der Cross-Cutting Exposure lässt sich ausschließlich durch Unterschiede zwischen den Ländern erklären.\nWir können uns auch die vorhergesagte Cross-Cutting Exposure für die verschiedenen Länder ausgeben lassen. Dazu berechnen wir Modelvorhersagen mit der Funktion avg_predictions().\n\nmarginaleffects::avg_predictions(m0_cc, by = \"dCountry_W2\") |&gt;\n  as_tibble()\n\n# A tibble: 17 × 10\n  rowid dCountry_W2 estimate std.error statistic  p.value s.value conf.low\n  &lt;int&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1     1 Netherlands    0.244    0.0202     12.1  1.93e-33   109.     0.204\n2     2 Austria        0.311    0.0202     15.4  3.45e-53   174.     0.271\n3     3 France         0.172    0.0202      8.49 2.01e-17    55.5    0.132\n4     4 Germany        0.152    0.0202      7.53 5.07e-14    44.2    0.113\n5     5 Italy          0.303    0.0202     15.0  9.54e-51   166.     0.264\n# ℹ 12 more rows\n# ℹ 2 more variables: conf.high &lt;dbl&gt;, rowid_dedup &lt;int&gt;\n\n\nWie wir sehen, gibt es einige Unterschiede zwischen den Ländern, in Schweden und der Schweiz ist die vorhergesagte Cross-Cutting Exposure vergleichsweise hoch, während sie in Ungarn, Deutschland und Frankreich vergleichsweise niedrig ist. Dies können wir uns auch grafisch darstellen lassen:\n\nmarginaleffects::avg_predictions(m0_cc, by = \"dCountry_W2\") |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = reorder(dCountry_W2, estimate), y = estimate,\n    ymin = conf.low, ymax = conf.high\n  )) +\n  geom_pointrange() +\n  coord_flip() +\n  labs(x = \"\", y = \"Predicted cross-cutting exposure\")",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#varying-intercepts",
    "href": "multilevel.html#varying-intercepts",
    "title": "6  Multilevel-Modelle",
    "section": "6.3 Varying Intercepts",
    "text": "6.3 Varying Intercepts\n\n6.3.1 Modellschätzung\nNun fügen wir dem Nullmodell zwei Prädiktoren auf Level 1 hinzu, also auf Befragtenebene. Zum einen die Cross-Cutting Exposure zu T1 (cross_cutting_consumption_w1_01 zum ersten Messzeitpunkt, also den autoregressiven Effekt), zum anderen die Bersorgnis aufgrund von Covid (worried_from_covid_total_01) . Das Modell enthält damit wieder eine Lagged Dependent Variable.\n\nm1_cc &lt;- lmer(cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 + worried_from_covid_total_01 +\n  (1 | dCountry_W2), d_zoizner)\nreport::report_table(m1_cc)\n\nParameter                       | Coefficient |        95% CI | t(8434) |      p | Effects |       Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n----------------------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                     |        0.02 | [ 0.00, 0.03] |    1.73 | 0.083  |   fixed |             |   2.68e-03 |     [-0.04, 0.05] |         \ncross cutting consumption w1 01 |        0.76 | [ 0.75, 0.78] |  103.32 | &lt; .001 |   fixed |             |       0.75 |     [ 0.73, 0.76] |         \nworried from covid total 01     |        0.07 | [ 0.05, 0.09] |    7.71 | &lt; .001 |   fixed |             |       0.06 |     [ 0.04, 0.07] |         \n                                |        0.02 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.16 |               |         |        |  random |    Residual |            |                   |         \n                                |             |               |         |        |         |             |            |                   |         \nAIC                             |             |               |         |        |         |             |            |                   | -6814.46\nAICc                            |             |               |         |        |         |             |            |                   | -6814.46\nBIC                             |             |               |         |        |         |             |            |                   | -6779.26\nR2 (conditional)                |             |               |         |        |         |             |            |                   |     0.59\nR2 (marginal)                   |             |               |         |        |         |             |            |                   |     0.59\nSigma                           |             |               |         |        |         |             |            |                   |     0.16\n\n\nSowohl die Cross-Cutting Exposure zu T1 als auch die Besorgnis um Covid haben einen positiven sig. Effekt auf die Cross-Cutting Exposure zu T2 (p&lt;.001), wobei ersteres wieder nur als Stabilitätskoeffizient zu interpretieren ist.\nAuch für dieses Modell können wir Modellvorhersagen berechnen, hier zum Effekt der Cross-Cutting Exposure.\n\navg_predictions(m1_cc, variables = c(\"worried_from_covid_total_01\", \"dCountry_W2\")) |&gt;\n  as_tibble()\n\n# A tibble: 85 × 9\n  worried_from_covid_total_01 dCountry_W2 estimate std.error statistic   p.value\n                        &lt;dbl&gt; &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1                       0     Netherlands    0.214   0.00865      24.7 3.54e-135\n2                       0.5   Netherlands    0.250   0.00635      39.3 0        \n3                       0.667 Netherlands    0.261   0.00619      42.2 0        \n4                       0.833 Netherlands    0.273   0.00640      42.7 0        \n5                       1     Netherlands    0.285   0.00696      41.0 0        \n# ℹ 80 more rows\n# ℹ 3 more variables: s.value &lt;dbl&gt;, conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;\n\n\nDie Modellvorhersagen lassen sich dann auch wieder grafisch darstellen, wobei jedes Land einzeln dargestellt ist.\n\navg_predictions(m1_cc, variables = c(\"worried_from_covid_total_01\", \"dCountry_W2\")) |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = worried_from_covid_total_01, y = estimate,\n    color = dCountry_W2, group = dCountry_W2\n  )) +\n  geom_line(show.legend = FALSE) +\n  labs(x = \"Covid-related worries T1\", y = \"Predicted cross-cutting exposure\")\n\n\n\n\n\n\n\n\nDer positive Effekt der Besorgnis über Covid auf die Cross-Cutting Exposure zu T2 ist im vorliegenden Modell in allen Ländern gleich, d.h. in allen Ländern ist der Anstieg identisch, was sich in den parallelen Linien zeigt. Die Länder unterscheiden sich hier nur durch die Varying Intercepts, d.h. durch die unterschiedliche Ausgangswerte. Diese Annahme können wir im nächsten Modell aufheben.\n\n\n6.3.2 Voraussetzungen\nAuch bei Mehrebenenmodellen können wir die klassischen Regressions-Annahmen wie Linearität, Normalverteilung der Residuen, Homoskedastizität und Multikollinearität überprüfen. Hierfür nutzen wir wieder die check_model()-Funktion aus dem performance-Paket.\n\nchecks &lt;- performance::check_model(m1_cc, panel = F)\nplot(checks)\n\n$PP_CHECK\n\n\n\n\n\n\n\n\n\n\n$NCV\n\n\n\n\n\n\n\n\n\n\n$HOMOGENEITY\n\n\n\n\n\n\n\n\n\n\n$OUTLIERS\n\n\n\n\n\n\n\n\n\n\n$VIF\n\n\n\n\n\n\n\n\n\n\n$QQ\n\n\n\n\n\n\n\n\n\n\n[[7]]",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#varying-slopes",
    "href": "multilevel.html#varying-slopes",
    "title": "6  Multilevel-Modelle",
    "section": "6.4 Varying Slopes",
    "text": "6.4 Varying Slopes\n\n6.4.1 Modellschätzung\nMultilevel-Modelle können neben Varying Intercepts auch Varying Slopes enthalten. Kurz gesagt bilden Varying Slopes unterschiedliche Effekte einer Variable in den verschiedenen Gruppen (hier: in den Ländern) ab. In der nachfolgenden Analyse nehmen wir an, dass die Besorgnis über Covid und die Cross-Cutting Exposure zu T1 bei den Befragten nicht in allen Ländern den gleichen (positiven) Effekt auf die Cross-Cutting Exposure zu T2 hat. Die Varying Slopes fügen wir hinzu, indem wir die Variablen worried_from_covid_total_01 und cross_cutting_consumption_w1_01 in die Klammer (1 | dCountry_W2), welche die Varying Intercepts kennzeichnet, aufnehmen.\n\nm2_cc &lt;- lmer(cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 + worried_from_covid_total_01 +\n  (1 + cross_cutting_consumption_w1_01 + worried_from_covid_total_01 | dCountry_W2), d_zoizner)\nreport::report_table(m2_cc)\n\nRandom effect variances not available. Returned R2 does not account for random effects.\n\n\nParameter                       | Coefficient |       95% CI | t(8429) |      p | Effects |       Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n---------------------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                     |        0.02 | [0.00, 0.03] |    2.66 | 0.008  |   fixed |             |   3.68e-03 |     [-0.05, 0.05] |         \ncross cutting consumption w1 01 |        0.76 | [0.75, 0.78] |   85.26 | &lt; .001 |   fixed |             |       0.74 |     [ 0.73, 0.76] |         \nworried from covid total 01     |        0.07 | [0.05, 0.09] |    5.67 | &lt; .001 |   fixed |             |       0.06 |     [ 0.04, 0.08] |         \n                                |        0.02 |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.03 |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |             |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.00 |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.58 |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.16 |              |         |        |  random |    Residual |            |                   |         \n                                |             |              |         |        |  random | dCountry_W2 |            |                   |         \n                                |             |              |         |        |         |             |            |                   |         \nAIC                             |             |              |         |        |         |             |            |                   | -6819.06\nAICc                            |             |              |         |        |         |             |            |                   | -6819.04\nBIC                             |             |              |         |        |         |             |            |                   | -6748.66\nR2 (marginal)                   |             |              |         |        |         |             |            |                   |     0.59\nSigma                           |             |              |         |        |         |             |            |                   |     0.16\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn der report_table() werden leider die Varianzen bzw. Standardabweichungen der variierenden Slopes und Intercepts nicht gut gelabelt, daher greifen wir hier auf summary() zurück.\n\nsummary(m2_cc)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 +  \n    worried_from_covid_total_01 + (1 + cross_cutting_consumption_w1_01 +  \n    worried_from_covid_total_01 | dCountry_W2)\n   Data: d_zoizner\n\nREML criterion at convergence: -6839.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.4248 -0.4616 -0.1690  0.4677  5.9361 \n\nRandom effects:\n Groups      Name                            Variance  Std.Dev. Corr     \n dCountry_W2 (Intercept)                     0.0000000 0.00000           \n             cross_cutting_consumption_w1_01 0.0004027 0.02007   NaN     \n             worried_from_covid_total_01     0.0011544 0.03398   NaN 0.58\n Residual                                    0.0258233 0.16070           \nNumber of obs: 8439, groups:  dCountry_W2, 17\n\nFixed effects:\n                                Estimate Std. Error t value\n(Intercept)                     0.016574   0.006230   2.661\ncross_cutting_consumption_w1_01 0.762807   0.008947  85.258\nworried_from_covid_total_01     0.069850   0.012328   5.666\n\nCorrelation of Fixed Effects:\n            (Intr) c___1_\ncrss___1_01 -0.149       \nwrrd_f___01 -0.672  0.125\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n\n\nDas Modell unterstellt jetzt, dass es einen Gesamt-Intercept und Slopes über alle Befragten und Länder gibt sowie länderspezifische Abweichungen davon. Der länderspezifische Effekt ist dann die Summe aus Gesamt-Slope und länderspezifischen Abweichungen. Um diese zu schätzen, gibt es eine spezielle Funktion avg_slopes() mit dem by Parameter.\n\nmarginaleffects::avg_slopes(m2_cc, variables = \"worried_from_covid_total_01\", by = \"dCountry_W2\") |&gt;\n  as_tibble()\n\n# A tibble: 17 × 13\n  term        contrast dCountry_W2 estimate std.error statistic  p.value s.value\n  &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1 worried_fr… mean(dY… Austria       0.0833    0.0123      6.76 1.37e-11   36.1 \n2 worried_fr… mean(dY… Belgium       0.0590    0.0123      4.79 1.68e- 6   19.2 \n3 worried_fr… mean(dY… Denmark       0.0453    0.0123      3.67 2.41e- 4   12.0 \n4 worried_fr… mean(dY… France        0.0318    0.0123      2.58 9.99e- 3    6.65\n5 worried_fr… mean(dY… Germany       0.0404    0.0123      3.28 1.04e- 3    9.91\n# ℹ 12 more rows\n# ℹ 5 more variables: conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, predicted_lo &lt;dbl&gt;,\n#   predicted_hi &lt;dbl&gt;, predicted &lt;dbl&gt;\n\n\nWir sehen, dass sich die geschätzten Regressionskoeffizienten für die Besorgnis über Covid zwischen den Ländern unterscheiden. Auch für dieses Modell können wir die Modellvorhersagen berechnen und grafisch darstellen.\n\navg_predictions(m2_cc, variables = c(\"worried_from_covid_total_01\", \"dCountry_W2\")) |&gt;\n  as_tibble() |&gt;\n  ggplot(aes(\n    x = worried_from_covid_total_01, y = estimate,\n    color = dCountry_W2, group = dCountry_W2\n  )) +\n  geom_line(show.legend = FALSE) +\n  labs(x = \"Covid-related worries T1\", y = \"Predicted cross-cutting exposure\")\n\n\n\n\n\n\n\n\nIm Unterschied zum vorherigen Modell sehen wir nun länderspezifische Ausgangswerte und Anstiege der Regressionsgeraden.\n\n\n6.4.2 Modellvergleich Fixed vs. Varying Slopes\nUm unsere beiden Modelle zu vergleichen, können wir die anova()-Funktion nutzen, um einen Likelihood-Ratio-Test durchzuführen.\n\nanova(m1_cc, m2_cc)\n\nData: d_zoizner\nModels:\nm1_cc: cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 + worried_from_covid_total_01 + (1 | dCountry_W2)\nm2_cc: cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 + worried_from_covid_total_01 + (1 + cross_cutting_consumption_w1_01 + worried_from_covid_total_01 | dCountry_W2)\n      npar     AIC     BIC logLik deviance  Chisq Df Pr(&gt;Chisq)   \nm1_cc    5 -6838.4 -6803.2 3424.2  -6848.4                        \nm2_cc   10 -6845.5 -6775.1 3432.8  -6865.5 17.176  5   0.004178 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer Test zeigt an, dass das Varying Slopes Modell signifikant besser ist als das Varying Intercept Modell (p&lt;.001), d.h. es gibt signifikante Effektheterogenität bezüglich der Prädiktoren Cross-cutting Exposure zu T1 und Besorgnis über Covid.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#level-2-prädiktoren",
    "href": "multilevel.html#level-2-prädiktoren",
    "title": "6  Multilevel-Modelle",
    "section": "6.5 Level-2 Prädiktoren",
    "text": "6.5 Level-2 Prädiktoren\nBislang haben wir mit cross_cutting_consumption_w1_01 und worried_from_covid_total_01 lediglich Level-1-Prädiktoren für unsere Analyse verwendet. Es ist aber ebenso möglich, einen Level-2-Prädiktor in das Modell aufzunehmen, um die Unterschiede zwischen den Gruppen zu erklären. So könnte der Schweregrad von Covid19 (die Anzahl der Fälle im Land) die Cross-Cutting Exposure beeinflussen. Deshalb fügen wir die Variable confirmed_per_100k in die Formel ein.\n\nm3_cc &lt;- lmer(cross_cutting_consumption_w2_01 ~ cross_cutting_consumption_w1_01 + worried_from_covid_total_01 + confirmed_per_100k + (1 + cross_cutting_consumption_w1_01 + worried_from_covid_total_01 | dCountry_W2), d_zoizner)\nreport::report_table(m3_cc)\n\nParameter                       | Coefficient |        95% CI | t(8428) |      p | Effects |       Group | Std. Coef. | Std. Coef. 95% CI |      Fit\n----------------------------------------------------------------------------------------------------------------------------------------------------\n(Intercept)                     |        0.01 | [-0.01, 0.04] |    1.21 | 0.227  |   fixed |             |   3.77e-03 |     [-0.05, 0.05] |         \ncross cutting consumption w1 01 |        0.76 | [ 0.74, 0.78] |   78.17 | &lt; .001 |   fixed |             |       0.74 |     [ 0.73, 0.76] |         \nworried from covid total 01     |        0.07 | [ 0.05, 0.10] |    5.69 | &lt; .001 |   fixed |             |       0.06 |     [ 0.04, 0.08] |         \nconfirmed per 100k              |    3.38e-06 | [ 0.00, 0.00] |    0.09 | 0.932  |   fixed |             |   1.85e-03 |     [-0.04, 0.04] |         \n                                |        0.02 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.03 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.04 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |       -0.77 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |       -0.34 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.87 |               |         |        |  random | dCountry_W2 |            |                   |         \n                                |        0.16 |               |         |        |  random |    Residual |            |                   |         \n                                |             |               |         |        |         |             |            |                   |         \nAIC                             |             |               |         |        |         |             |            |                   | -6801.93\nAICc                            |             |               |         |        |         |             |            |                   | -6801.90\nBIC                             |             |               |         |        |         |             |            |                   | -6724.49\nR2 (conditional)                |             |               |         |        |         |             |            |                   |     0.60\nR2 (marginal)                   |             |               |         |        |         |             |            |                   |     0.58\nSigma                           |             |               |         |        |         |             |            |                   |     0.16\n\n\nWie wir sehen, hängt die Anzahl der Fälle im Land nicht signifikant mit der Cross-Cutting Exposure zusammen (p &gt;.05).\n\n\n\n\n\n\nWeiterführende Materialien\n\n\n\nWeitere detaillierte Beispiele mit R-Code und Daten finden sich in den Materialien zur Vorlesung Anwendungsorientierte Analyseverfahren, u.a. zu\n\nVarying Intercept und Slope Modellen\nModellvorhersagen und -visualisierungen",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#glossar",
    "href": "multilevel.html#glossar",
    "title": "6  Multilevel-Modelle",
    "section": "6.6 Glossar",
    "text": "6.6 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nlme4::lmer\nMultilevel-Modelle schätzen\n\n\nperformance::check_model\nModellannahmen prüfen\n\n\nperformance::icc\nIntraklassenkorrelationskoeffizient berechnen",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "multilevel.html#hausaufgabe",
    "href": "multilevel.html#hausaufgabe",
    "title": "6  Multilevel-Modelle",
    "section": "6.7 Hausaufgabe",
    "text": "6.7 Hausaufgabe\n\nWie beeinflusst die Angst vor Covid (worried_from_covid_total_01) und das Alter der Befragten (age) auf Befragtenebene sowie die Anzahl der Fälle im Land (confirmed_per_100k) auf Länderebene die Nachrichtennutzung auf Social Media (news_consumption_socialmedia_w2)?\nSchätzen Sie das ganze als REWB-Modell. Interpretieren Sie die Ergebnisse und vergleichen mit dem RE-Modell aus Aufgabe 1.",
    "crumbs": [
      "Längsschnitts - und Multilevelmodelle",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Multilevel-Modelle</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html",
    "href": "explorative-faktorenanalyse.html",
    "title": "7  Explorative Faktorenanalyse",
    "section": "",
    "text": "7.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für die explorative Faktorenanalyse benötigen wir das psych- Paket. Wie immer laden wir außerdem tidyverse und report.\nlibrary(psych)\nlibrary(tidyverse)\nlibrary(report)\nFür die explorative Faktorenanalyse nutzen wir den Excel-Datensatz gewohnheiten.xlsx. Dieser enthält u.a. Skalen zur Messung der Gewohnheitsstärke bei der Nutzung von Fernsehen, Computer und Smartphone.\nd_habit &lt;- readxl::read_excel(\"data/gewohnheiten.xlsx\")\nd_habit\n\n# A tibble: 791 × 195\n         id vf_fernseher vf_computer vf_tablet vf_radio vf_zeitung vf_smartphone\n      &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n1 403074747            1           1         0        1          0             1\n2 403087148            1           1         1        1          0             1\n3 403129944            1           1         0        1          1             2\n4 403143142            1           1         0        0          0             2\n5 403200247            1           1         0        1          0             1\n# ℹ 786 more rows\n# ℹ 188 more variables: i1_fernseher &lt;dbl&gt;, i1_computer &lt;dbl&gt;, i1_tablet &lt;dbl&gt;,\n#   i1_smartphone &lt;dbl&gt;, i1_radio &lt;dbl&gt;, i1_zeitung &lt;dbl&gt;, vm_ferseher &lt;dbl&gt;,\n#   vm_computer &lt;dbl&gt;, vm_tablet &lt;dbl&gt;, vm_smartphone &lt;dbl&gt;, vm_radio &lt;dbl&gt;,\n#   vm_zeitung &lt;dbl&gt;, r_fernseher &lt;dbl&gt;, r_computer &lt;dbl&gt;, r_tablet &lt;dbl&gt;,\n#   r_smartphone &lt;dbl&gt;, r_radio &lt;dbl&gt;, r_zeitung &lt;dbl&gt;, f_einst1 &lt;dbl&gt;,\n#   f_einst2 &lt;dbl&gt;, f_einst3 &lt;dbl&gt;, f_einst4 &lt;dbl&gt;, f_srhi_r1 &lt;dbl&gt;, …",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html#überprüfung-der-items",
    "href": "explorative-faktorenanalyse.html#überprüfung-der-items",
    "title": "7  Explorative Faktorenanalyse",
    "section": "7.2 Überprüfung der Items",
    "text": "7.2 Überprüfung der Items\nZunächst machen wir uns mit den relevanten Variablen vertraut und nutzen dafür die report_table()-Funktion. Die Skala für die Gewohnheitsstärke bei der Computer-Nutzung ist in den elf Variablen c_srhi_X enthalten, die wir für die weiteren Schnitte ausschneiden und in einem neuen Datensatz speichern.\n\nd_efa &lt;- d_habit |&gt;\n  select(c_srhi_r1:c_srhi_c2)\n\nd_efa |&gt;\n  report::report_table()\n\nVariable  | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | percentage_Missing\n--------------------------------------------------------------------------------------------------------\nc_srhi_r1 |   791 | 4.57 | 0.85 |        | 0.00 | 1.00 | 5.00 |    -2.37 |     5.67 |               2.65\nc_srhi_r2 |   791 | 4.31 | 1.04 |        | 0.00 | 1.00 | 5.00 |    -1.67 |     2.23 |               2.65\nc_srhi_r3 |   791 | 4.45 | 0.92 |        | 0.00 | 1.00 | 5.00 |    -2.02 |     4.02 |               2.65\nc_srhi_a1 |   791 | 2.03 | 1.31 |        | 0.00 | 1.00 | 5.00 |     1.03 |    -0.22 |               2.65\nc_srhi_a2 |   791 | 2.49 | 1.38 |        | 1.48 | 1.00 | 5.00 |     0.44 |    -1.08 |               2.65\nc_srhi_a3 |   791 | 1.79 | 1.19 |        | 0.00 | 1.00 | 5.00 |     1.40 |     0.79 |               2.65\nc_srhi_a4 |   791 | 2.68 | 1.28 |        | 1.48 | 1.00 | 5.00 |     0.20 |    -1.01 |               2.65\nc_srhi_a5 |   791 | 2.46 | 1.41 |        | 1.48 | 1.00 | 5.00 |     0.45 |    -1.15 |               2.65\nc_srhi_a6 |   791 | 1.87 | 1.19 |        | 0.00 | 1.00 | 5.00 |     1.25 |     0.47 |               2.65\nc_srhi_c1 |   791 | 3.52 | 1.23 |        | 1.48 | 1.00 | 5.00 |    -0.50 |    -0.66 |               2.65\nc_srhi_c2 |   791 | 3.89 | 1.25 |        | 1.48 | 1.00 | 5.00 |    -0.94 |    -0.19 |               2.65\n\n\nGrundsätzlich sollten die Items, die wir für eine Faktoranalyse verwenden wollen, ein metrisches Skalenniveau aufweisen (d.h. mindestens intervallskaliert) oder dichotom sein. Es sollten außerdem mindestens 100 Fälle sein (eher mehr) bzw. insgesamt mindestens 10x mehr Personen als Items, die in die Analyse einbezogen werden sollen (Daumenregel). In unserem Datensatz erfüllen wir diese Mindestanzahl locker. Die Items sind alle auf einer 5-er Skala erhoben und wenigstens quasi-metrisch.\n\n7.2.1 Korrelationsmatrix und Bartlett-Test\nAnschließend überprüfen wir, ob die Items überhaupt für eine explorative Faktorenanalyse geeignet sind, d.h. ob es gemeinsame Varianz gibt. Die Korrelationsmatrix zeigt, ob und wie die einzelnen Variablen miteinander zusammenhängen. Die Items, die auf einen Faktor laden, müssen zwangsweise miteinander korrelieren, daher können wir durch Inspektion der Korrelationsmatrix bereits einen ersten Eindruck gewinnen, ob eine oder mehrere Faktoren dahinterliegen könnten. Wir berücksichtigen nur die Befragten, die für alle 9 Variablen gültige Werte angegeben haben.\n\nd_efa |&gt;\n  cor(use = \"complete.obs\") |&gt;\n  round(2)\n\n          c_srhi_r1 c_srhi_r2 c_srhi_r3 c_srhi_a1 c_srhi_a2 c_srhi_a3 c_srhi_a4\nc_srhi_r1      1.00      0.62      0.57     -0.04      0.05     -0.10      0.09\nc_srhi_r2      0.62      1.00      0.63      0.05      0.17      0.03      0.16\nc_srhi_r3      0.57      0.63      1.00     -0.04      0.12     -0.07      0.07\nc_srhi_a1     -0.04      0.05     -0.04      1.00      0.53      0.69      0.45\nc_srhi_a2      0.05      0.17      0.12      0.53      1.00      0.53      0.46\nc_srhi_a3     -0.10      0.03     -0.07      0.69      0.53      1.00      0.39\nc_srhi_a4      0.09      0.16      0.07      0.45      0.46      0.39      1.00\nc_srhi_a5      0.13      0.24      0.16      0.57      0.59      0.57      0.41\nc_srhi_a6     -0.10      0.03     -0.05      0.68      0.56      0.79      0.41\nc_srhi_c1      0.36      0.51      0.39      0.21      0.26      0.22      0.18\nc_srhi_c2      0.36      0.49      0.45      0.12      0.18      0.11      0.13\n          c_srhi_a5 c_srhi_a6 c_srhi_c1 c_srhi_c2\nc_srhi_r1      0.13     -0.10      0.36      0.36\nc_srhi_r2      0.24      0.03      0.51      0.49\nc_srhi_r3      0.16     -0.05      0.39      0.45\nc_srhi_a1      0.57      0.68      0.21      0.12\nc_srhi_a2      0.59      0.56      0.26      0.18\nc_srhi_a3      0.57      0.79      0.22      0.11\nc_srhi_a4      0.41      0.41      0.18      0.13\nc_srhi_a5      1.00      0.58      0.35      0.23\nc_srhi_a6      0.58      1.00      0.22      0.09\nc_srhi_c1      0.35      0.22      1.00      0.73\nc_srhi_c2      0.23      0.09      0.73      1.00\n\n\nWir sehen, dass es einige Items gibt, die relativ hoch miteinander korrelieren. Mit dem Bartlett-Test können wir diese visuelle Inspektion auch formalisieren. Er überprüft die Nullhypothese, dass die Stichprobe aus einer Population stammt, in der die Variablen unkorreliert sind. Dies ist ein relativ schwacher Test, da mit ausreichend großen Stichproben fast immer auch kleinere Inter-Item-Korrelationen statistisch signifikant sein werden.\n\npsych::cortest.bartlett(d_efa)\n\n$chisq\n[1] 4432.899\n\n$p.value\n[1] 0\n\n$df\n[1] 55\n\n\nDer Bartlett-Test ist wie erwartet signifikant (p &lt; .001), d.h. die Items sind korreliert und die Voraussetzung für eine Faktorenanalyse erfüllt.\n\n\n7.2.2 KMO-Wert\nDer KMO-wert (Kaiser-Meyer-Olkin-Wert) ist ein Maß für den Anteil der Varianz zwischen den Variablen, der vermutlich gemeinsame Varianz ist. D. h., der KMO-Wert gibt an, wie stark die Variablen zusammengehören und ob eine EFA sinnvoll ist. Der KMO-Wert kann Werte zwischen 0 und 1 annehmen. Je höher der KMO-Wert, desto besser eignen sich die Daten für eine Faktorenanalyse.\nKaiser (1975) schlägt als Bewertung des KMO-Werts folgendes vor:\n≥ .90 = marvelous (“erstaunlich”) ≥ .80 = meritorius (“verdienstvoll”) ≥ .70 = middling (“ziemlich gut”) ≥ .60 = mediocre (“mittelmäßig”) ≥ .50 = miserable (“kläglich”) &lt; .50 = unacceptable (“untragbar”)\n\npsych::KMO(d_efa)\n\nKaiser-Meyer-Olkin factor adequacy\nCall: psych::KMO(r = d_efa)\nOverall MSA =  0.84\nMSA for each item = \nc_srhi_r1 c_srhi_r2 c_srhi_r3 c_srhi_a1 c_srhi_a2 c_srhi_a3 c_srhi_a4 c_srhi_a5 \n     0.82      0.82      0.83      0.91      0.91      0.83      0.92      0.92 \nc_srhi_a6 c_srhi_c1 c_srhi_c2 \n     0.84      0.76      0.74 \n\n\nWir erhalten eine KMO-Wert für alle Items (insgesamt) und für jedes einzelne Item. Da alle Items &gt; .70 (ziemlich gut) sind und auch der Gesamtwert &gt; .80 (verdienstvoll) ist, können wir darauf schließen, dass sich die Items gut für die Durchführung einer Faktorenanalyse eignen.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html#explorative-faktorenanalyse",
    "href": "explorative-faktorenanalyse.html#explorative-faktorenanalyse",
    "title": "7  Explorative Faktorenanalyse",
    "section": "7.3 Explorative Faktorenanalyse",
    "text": "7.3 Explorative Faktorenanalyse\n\n7.3.1 Extraktions-Methode\nIn der Literatur zur EFA werden in der Regel drei alternative Ansätze diskutiert:\n\nHauptkomponentenanalyse (Principal component analysis, PCA)\nHauptachsenanalyse (Principal axis factoring, PAF)\nMaximum-Likelihood-Faktoranalyse (ML)\n\nDie Hauptkomponentenanalyse wenden wir ausschließlich an, wenn unser Ziel eine Datenreduktion ist, d.h. wir eine größere Anzahl Items durch eine geringere Anzahl Komponenten ersetzen wollen und dabei aber deren Varianz möglichst maximal erhalten wollen.\nDie Hauptachsenanalyse oder Maximum Likelihood Schätzung verwenden wir, wenn latente Variablen identifiziert werden sollen, die für die Beantwortung der Items ausschlaggebend sind. Anders formuliert: Die Antworten auf die gemessenen Items lassen sich durch einen oder mehrere Faktoren erklären bzw. spiegeln die latenten Variablen wider (reflektives Messmodell). Dies ist in fast allen kommunikationswissenschaftlichen Anwendungen das Ziel, daher wählen wir die Hauptachsenanalyse.\n\n\n7.3.2 Anzahl der Faktoren bestimmen\nBevor wir eine EFA durchführen, müssen wir die optimale Anzahl von Faktoren bestimmen, die extrahiert werden sollen. Leider gibt es kein einheitliches Konzept oder Kriterium für die Extraktion von Faktoren (von einem einzigen Faktor bis jedes Item = ein Faktor ist alles möglich). Technisch gibt es immer so viele Faktoren wie Items, aber wir extrahieren nur die wichtigsten. Unsere Entscheidung sollte im Idealfall auf mehreren Kriterien beruhen, von denen die klare Interpretierbarkeit das wichtigste ist: Möglichst alle Items sollten nur zu einem Faktoren gehören (auf einen Faktor laden), was als Einfachstruktur bezeichnet wird, und jeder Faktor sollte sich in mehreren Items widerspiegeln (sonst wäre Item = Faktor, keine gemeinsame Varianz).\nVerfahren zur Bestimmung der Faktoranzahl sind:\n\nA-priori-Kriterium: Wir definieren eine Faktorenanzahl aufgrund theoretischer Überlegungen (dann sind wir aber schon fast bei der konfirmatorischen Faktorenanalyse)\nParallel-Analyse: die empirische Faktorstruktur wird mit einer zufälligen Datenmatrix auf Basis derselben Variablenzahl verglichen\nKaiser-Kriterium: Identifikation von Faktoren, deren Eigenwert &gt; 1 ist, da Faktoren unterhalb dieser Grenze weniger Varianz erklären als eine einzelne Variable\n\nEine Parallel-Analyse führen wir mit der fa.parallel()-Funktion durch. Hier wählen wir aus, dass wir eine Faktorenanalyse (keine Hauptkomponentenanalyse) durchführen wollen verwenden dafür fm = \"pa\" (Principal Axis) zur Extraktion.\n\npsych::fa.parallel(d_efa, fa = \"fa\", fm = \"pa\")\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  3  and the number of components =  NA \n\n\nDa es keine inferenzstatistischen Tests für die optimale Anzahl an Faktoren gibt, wird oft mit Hilfe eines Scree-Plots visuell inspiziert, wie viele Faktoren es geben könnte. Hierbei sucht man entweder nach dem Knick (Ellenbogen-Kriterium) oder dem Schnittpunkt für ein Kriteriumswert.\nMit Hilfe der scree()-Funktion sehen wir, wie viele Faktoren einen Eigenwert &gt; 1 haben (Kaiser-Kriterium) und wo optisch der “Knick” ist.\n\npsych::scree(d_efa, pc = F)\n\n\n\n\n\n\n\n\nDie Parallel-Analyse schlägt drei Faktoren vor, nach dem Kaiser-Kriterium und dem Scree-Plot ergeben sich jedoch zwei Faktoren. Dies zeigt ganz anschaulich, dass es bei explorativen Faktoranalysen häufig kein eindeutiges Ergebnis gibt. Wir entscheiden uns dafür, die Analyse mit drei Faktoren zu rechnen.\n\n\n7.3.3 Durchführung der eigentlichen Faktoranalyse und Rotation\nFür die eigentliche explorative Faktorenanalyse nutzen wir die fa()-Funktion. Hier müssen wir die Anzahl der Faktoren, die Methode (pa = principal axis factoring) und die Art der Rotation unserer Matrix angeben.\nRotationen minimieren die Komplexität der Faktorenladungen, um die Struktur einfacher zu interpretieren. Es gibt zwei Arten der Rotation:\nOrthogonale Rotationen erzwingen, dass die Faktoren unkorreliert sind, was aber häufig unrealistisch ist (wir nehmen ja an, dass die Items korrelieren und zu einem latenten Faktor gehören). Die Erzwingung der Unkorreliertheit macht es weniger wahrscheinlich, dass die Rotation eine Lösung mit einer einfachen Struktur ergibt. Oblique Rotationen erlauben es, dass die Faktoren miteinander korreliert sind. Dies führt häufig zu Lösungen mit einer einfacheren Struktur und steht im Einklang mit der Theorie.\nWir empfehlen, zuerst eine oblique Rotation (z. B. ‘oblimin’) durchzuführen und die Korrelationen der Faktoren zu überprüfen. Korrelieren diese tatsächlich nicht, ist auch eine orthogonale Rotation angemessen.\n\nresults_efa &lt;- d_efa %&gt;%\n  fa(\n    nfactors = 3,\n    fm = \"pa\",\n    rotate = \"oblimin\"\n  )\n\n# Output anpassen\nprint(results_efa,\n  digits = 2, ## auf 2 Nachkommastellen runden\n  sort = TRUE ## Items zu den Faktoren sortieren\n)\n\nFactor Analysis using method =  pa\nCall: fa(r = ., nfactors = 3, rotate = \"oblimin\", fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n          item   PA1   PA2   PA3   h2   u2 com\nc_srhi_a6    9  0.85 -0.10  0.01 0.74 0.26 1.0\nc_srhi_a3    6  0.83 -0.14  0.06 0.72 0.28 1.1\nc_srhi_a1    4  0.81 -0.03 -0.01 0.64 0.36 1.0\nc_srhi_a5    8  0.72  0.19  0.03 0.57 0.43 1.1\nc_srhi_a2    5  0.71  0.17 -0.04 0.51 0.49 1.1\nc_srhi_a4    7  0.55  0.18 -0.08 0.31 0.69 1.3\nc_srhi_r1    1 -0.04  0.77 -0.03 0.57 0.43 1.0\nc_srhi_r2    2  0.06  0.76  0.11 0.70 0.30 1.1\nc_srhi_r3    3 -0.03  0.72  0.06 0.57 0.43 1.0\nc_srhi_c1   10  0.06  0.00  0.85 0.76 0.24 1.0\nc_srhi_c2   11 -0.06  0.04  0.83 0.70 0.30 1.0\n\n                       PA1  PA2  PA3\nSS loadings           3.39 1.89 1.51\nProportion Var        0.31 0.17 0.14\nCumulative Var        0.31 0.48 0.62\nProportion Explained  0.50 0.28 0.22\nCumulative Proportion 0.50 0.78 1.00\n\n With factor correlations of \n     PA1  PA2  PA3\nPA1 1.00 0.02 0.27\nPA2 0.02 1.00 0.59\nPA3 0.27 0.59 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  55  with the objective function =  5.64 with Chi Square =  4432.9\ndf of  the model are 25  and the objective function was  0.17 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  770 with the empirical chi square  40.69  with prob &lt;  0.025 \nThe total n.obs was  791  with Likelihood Chi Square =  129.92  with prob &lt;  3.8e-16 \n\nTucker Lewis Index of factoring reliability =  0.947\nRMSEA index =  0.073  and the 90 % confidence intervals are  0.061 0.086\nBIC =  -36.91\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2  PA3\nCorrelation of (regression) scores with factors   0.95 0.92 0.93\nMultiple R square of scores with factors          0.91 0.84 0.86\nMinimum correlation of possible factor scores     0.81 0.69 0.72\n\n\nDie Mustermatrix enthält die standardisierten Ladungen der einzelnen Items auf die jeweiligen Faktoren. Für die Übersichtlichkeit ist es häufig schöner, wenn geringe Faktorladungen nicht in der Matrix angezeigt werden. Dies erreichen wir mit cut = .3:\n\nprint(results_efa,\n  digits = 2, ## auf 2 Nachkommastellen runden\n  cut = .3, ## Ladungen unter .3 nicht anzeigen\n  sort = TRUE\n) ## Items zu den Faktoren sortieren\n\nFactor Analysis using method =  pa\nCall: fa(r = ., nfactors = 3, rotate = \"oblimin\", fm = \"pa\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n          item   PA1   PA2   PA3   h2   u2 com\nc_srhi_a6    9  0.85             0.74 0.26 1.0\nc_srhi_a3    6  0.83             0.72 0.28 1.1\nc_srhi_a1    4  0.81             0.64 0.36 1.0\nc_srhi_a5    8  0.72             0.57 0.43 1.1\nc_srhi_a2    5  0.71             0.51 0.49 1.1\nc_srhi_a4    7  0.55             0.31 0.69 1.3\nc_srhi_r1    1        0.77       0.57 0.43 1.0\nc_srhi_r2    2        0.76       0.70 0.30 1.1\nc_srhi_r3    3        0.72       0.57 0.43 1.0\nc_srhi_c1   10              0.85 0.76 0.24 1.0\nc_srhi_c2   11              0.83 0.70 0.30 1.0\n\n                       PA1  PA2  PA3\nSS loadings           3.39 1.89 1.51\nProportion Var        0.31 0.17 0.14\nCumulative Var        0.31 0.48 0.62\nProportion Explained  0.50 0.28 0.22\nCumulative Proportion 0.50 0.78 1.00\n\n With factor correlations of \n     PA1  PA2  PA3\nPA1 1.00 0.02 0.27\nPA2 0.02 1.00 0.59\nPA3 0.27 0.59 1.00\n\nMean item complexity =  1.1\nTest of the hypothesis that 3 factors are sufficient.\n\ndf null model =  55  with the objective function =  5.64 with Chi Square =  4432.9\ndf of  the model are 25  and the objective function was  0.17 \n\nThe root mean square of the residuals (RMSR) is  0.02 \nThe df corrected root mean square of the residuals is  0.03 \n\nThe harmonic n.obs is  770 with the empirical chi square  40.69  with prob &lt;  0.025 \nThe total n.obs was  791  with Likelihood Chi Square =  129.92  with prob &lt;  3.8e-16 \n\nTucker Lewis Index of factoring reliability =  0.947\nRMSEA index =  0.073  and the 90 % confidence intervals are  0.061 0.086\nBIC =  -36.91\nFit based upon off diagonal values = 1\nMeasures of factor score adequacy             \n                                                   PA1  PA2  PA3\nCorrelation of (regression) scores with factors   0.95 0.92 0.93\nMultiple R square of scores with factors          0.91 0.84 0.86\nMinimum correlation of possible factor scores     0.81 0.69 0.72\n\n\nJe stärker die Faktorladung (= Korrelation zwischen Variable und Faktor), desto stärker wird das Item bei der Interpretation des Faktors berücksichtigt (Hair et al., 1998, S. 111). Dabei ist eine Ladung von 0,30 das minimale Level (weshalb wir alles &lt; .30 nicht anzeigen), ab 0,50 ist die Ladung bedeutsam und ab 0,70 hoch. Wünschenswert ist, dass die Variablen auf einen Faktor hoch laden und auf die anderen Faktoren niedrig.\nDie Spalte „h2“ gibt den Anteil der Varianz an, der durch die Faktoren erklärt wird (Kommunalitäten). Die Spalte „u2“ steht für die Einzigartigkeit und ist einfach 1-h2. Die Spalte „com“ steht für den Hoffmannschen Komplexitätsindex. Er ist gleich 1, wenn ein Item nur auf einen Faktor lädt. Wir erhalten außerdem Tabellen für die erklärte Varianz und die Korrelationen zwischen den Faktoren und Informationen über die Modellanpassung.\n\n\n7.3.4 Ausschluss von Variablen\nBeim Betrachten der Faktorladungen sollten wir immer überlegen ob es Items gibt, die wir ausschließen sollten. Ein Item (c_srhi_a4) lädt wesentlich weniger auf den zugehörigen Faktor (PA1) - betrachtet man die Itemformulierung, kann man sich auch denken, warum dieses Item so schlecht lädt (“Während ich den Computer einschalte, denke ich oft an ganz andere Dinge.”). Das Item c_srhi_a4 beinhaltet eher Ablenkungsaspekte oder Multitasking und streng genommen nicht eine fehlende Bewusstheit der Nutzung. Wir schließen dieses Item jedoch zunächst nicht aus.\nGenerell sollten Items ausgeschlossen werden, wenn\n\nsie zu niedrige Ladungen aufweisen\nsie auf zwei Faktoren hochladen (Daumenregel: weniger als .3 auseinander)\nsie alleine einen eigenen Faktor aufspannen\ndie Kommunalität &lt; .50 ist.\n\n\n\n7.3.5 Interpretation der Faktorenlösung\nWir sehen, dass der erste Faktor (PA1) aus sechs Items, der zweite (PA2) aus drei Items und der dritte Faktor (PA3) aus zwei Items besteht. Betrachten wir die Items inhaltlich, sehen wir, dass die drei Faktoren verschiedene Dimensionen der Gewohnheit bei der Computernutzung darstellen: PA1 die fehlende Bewusstheit der Computernutzung, PA2 den Wiederholungscharakter der Computernutzung und PA3 die geringe Kontrollierbarkeit der Computernutzung.\nWir können die Beziehungen und Ladungen zwischen den Items und den Faktoren auch grafisch darstellen:\n\npsych::fa.diagram(results_efa)",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html#exkurs-hauptkomponentenanalyse",
    "href": "explorative-faktorenanalyse.html#exkurs-hauptkomponentenanalyse",
    "title": "7  Explorative Faktorenanalyse",
    "section": "7.4 Exkurs: Hauptkomponentenanalyse",
    "text": "7.4 Exkurs: Hauptkomponentenanalyse\nIn Kapitel [extraktion] haben wir gelernt, dass wir in der Regel eine Hauptachsenanalyse durchführen, weil wir latente Variablen hinter den manifesten Variablen vermuten. Manchmal möchten wir jedoch eine große Menge an Variablen reduzieren und durch eine geringere Anzahl an Komponenten ersetzen. Hier kann die Hauptkomponentenanalyse sinnvoll sein.\nGrundsätzlich sind viele Schritte bei der Hauptkomponentenanalyse die Gleichen wie bei der Faktorenanalyse. Jedoch sollten wir eben von Komponenten und nicht von Faktoren sprechen. Ein zentraler Unterschied zur explorativen Faktorenanalyse ist, dass die Variablen nicht miteinander korrelieren müssen.\nWir nutzen im Folgenden einen SPSS-Datensatz, der mögliche Funktionen von informeller Kommunikation in Organisationen enthält. In einer Literaturanalyse wurden neun Funktionen herausgearbeitet, deren Relevanz für Mitarbeitende mit Hilfe von je drei Items auf einer 5er-Skala erhoben wurde. Diese 27 Items sollen mit Hilfe einer Hauptkomponentenanalyse verdichtet werden.\nWir machen uns zunächst wieder mit den relevanten Variablen vertraut und nutzen dafür die report_table()-Funktion. Die Items zu den Funktionen informeller Kommunikation ist in den 27 Variablen F201_x enthalten, die wir wieder für die weiteren Schritte ausschneiden und in einem neuen Datensatz speichern.\n\nd_informell &lt;- haven::read_sav(\"data/InfKomm.sav\") |&gt;\n  haven::zap_labels()\n\nd_pca &lt;- d_informell |&gt;\n  select(F201_01:F201_52)\n\nd_pca |&gt;\n  report::report_table()\n\nVariable | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | percentage_Missing\n-------------------------------------------------------------------------------------------------------\nF201_01  |  1380 | 3.36 | 1.20 |        | 1.48 | 1.00 | 5.00 |    -0.37 |    -0.80 |               1.38\nF201_02  |  1380 | 3.25 | 1.25 |        | 1.48 | 1.00 | 5.00 |    -0.30 |    -0.94 |               0.51\nF201_03  |  1380 | 3.57 | 1.16 |        | 1.48 | 1.00 | 5.00 |    -0.53 |    -0.58 |               1.09\nF201_05  |  1380 | 3.68 | 1.11 |        | 1.48 | 1.00 | 5.00 |    -0.69 |    -0.21 |               0.65\nF201_07  |  1380 | 2.40 | 1.19 |        | 1.48 | 1.00 | 5.00 |     0.50 |    -0.76 |               0.58\nF201_08  |  1380 | 3.42 | 1.17 |        | 1.48 | 1.00 | 5.00 |    -0.43 |    -0.67 |               0.87\nF201_13  |  1380 | 3.89 | 0.98 |        | 1.48 | 1.00 | 5.00 |    -0.84 |     0.49 |               0.29\nF201_15  |  1380 | 3.06 | 1.38 |        | 1.48 | 1.00 | 5.00 |    -0.11 |    -1.24 |               2.32\nF201_16  |  1380 | 3.80 | 1.05 |        | 1.48 | 1.00 | 5.00 |    -0.70 |    -0.10 |               1.16\nF201_17  |  1380 | 3.95 | 1.00 |        | 1.48 | 1.00 | 5.00 |    -0.82 |     0.12 |               1.09\nF201_18  |  1380 | 3.22 | 1.22 |        | 1.48 | 1.00 | 5.00 |    -0.17 |    -0.90 |               1.52\nF201_20  |  1380 | 3.41 | 1.19 |        | 1.48 | 1.00 | 5.00 |    -0.39 |    -0.75 |               1.09\nF201_25  |  1380 | 3.68 | 1.06 |        | 1.48 | 1.00 | 5.00 |    -0.56 |    -0.33 |               0.22\nF201_26  |  1380 | 4.14 | 0.89 |        | 1.48 | 1.00 | 5.00 |    -1.06 |     1.04 |               0.94\nF201_27  |  1380 | 3.84 | 0.99 |        | 1.48 | 1.00 | 5.00 |    -0.73 |     0.11 |               0.43\nF201_29  |  1380 | 3.82 | 1.01 |        | 1.48 | 1.00 | 5.00 |    -0.77 |     0.20 |               1.16\nF201_30  |  1380 | 3.29 | 1.18 |        | 1.48 | 1.00 | 5.00 |    -0.34 |    -0.73 |               1.30\nF201_31  |  1380 | 3.40 | 1.14 |        | 1.48 | 1.00 | 5.00 |    -0.40 |    -0.65 |               2.61\nF201_41  |  1380 | 3.93 | 0.98 |        | 1.48 | 1.00 | 5.00 |    -0.85 |     0.38 |               0.72\nF201_42  |  1380 | 3.73 | 1.10 |        | 1.48 | 1.00 | 5.00 |    -0.65 |    -0.34 |               1.67\nF201_44  |  1380 | 4.08 | 0.90 |        | 1.48 | 1.00 | 5.00 |    -0.97 |     0.83 |               1.16\nF201_45  |  1380 | 3.60 | 1.11 |        | 1.48 | 1.00 | 5.00 |    -0.59 |    -0.35 |               1.23\nF201_47  |  1380 | 3.77 | 1.05 |        | 1.48 | 1.00 | 5.00 |    -0.69 |    -0.12 |               1.45\nF201_48  |  1380 | 3.97 | 0.95 |        | 1.48 | 1.00 | 5.00 |    -0.86 |     0.46 |               0.72\nF201_49  |  1380 | 3.67 | 1.06 |        | 1.48 | 1.00 | 5.00 |    -0.60 |    -0.24 |               3.33\nF201_51  |  1380 | 3.22 | 1.19 |        | 1.48 | 1.00 | 5.00 |    -0.21 |    -0.87 |               2.83\nF201_52  |  1380 | 4.06 | 0.92 |        | 1.48 | 1.00 | 5.00 |    -0.91 |     0.62 |               0.87\n\n# F201_01: Informelle Kommunikation ist ein Mittel, mit dem ich Spannungen und Stress abbauen kann.\n# F201_02: Ich nutze informelle Kommunikation, um eine Pause zu machen und mich zu erholen.\n# F201_03: Informelle Kommunikation hilft mir, meinem Ärger Luft zu machen, wenn mich etwas stört.\n# F201_05: Informelle Kommunikation bietet mir Abwechslung vom Arbeitsalltag.\n# F201_07: Ich nutze informelle Kommunikation, um mich von der Arbeit abzulenken.\n# F201_08: Ich nutze informelle Kommunikation zur Unterhaltung.\n# F201_13: Durch informelle Kommunikation fühle ich mich mit meinen Kolleg:innen verbunden.\n# F201_15: Durch informelle Kommunikation fühle ich mich weniger einsam.\n# F201_16: Durch informelle Kommunikation fühle ich mich sozial zugehörig.\n# F201_17: Informelle Kommunikation hilft mir dabei, meine Kolleg:innen privat besser kennenzulernen.\n# F201_18: Durch informelle Kommunikation kann ich Freundschaften schließen.\n# F201_20: Informelle Kommunikation hilft mir dabei, Bekanntschaften zu knüpfen.\n# F201_25: Durch informelle Kommunikation erhalte ich Informationen, die mir helfen, meine Arbeit zu erledigen.\n# F201_26: Informelle Kommunikation liefert zusätzliche Informationen zu der formellen Kommunikation in der Organisation.\n# F201_27: Informelle Kommunikation informiert mich über aktuelle Ereignisse und bevorstehende Veränderungen im Unternehmen.\n# F201_29: Informelle Kommunikation hilft mir, mich persönlich in mein Team einzufinden.\n# F201_30: Durch informelle Kommunikation fühle ich mich der Organisation zugehörig.\n# F201_31: Durch informelle Kommunikation habe ich das Gefühl, dass ich ein geschätztes Mitglied der Organisation bin.\n# F201_41: Für mich ist die informelle Kommunikation eine Möglichkeit, berufliche Beziehungen zu meinen Kolleg:innen aufzubauen und zu pflegen.\n# F201_42: Informelle Kommunikation unterstützt mich dabei, ein berufliches Netzwerk aufzubauen.\n# F201_44: Informelle Kommunikation hilft mir und meinem Team zusammenzuwachsen.\n# F201_45: Informelle Kommunikation hilft dabei, den Arbeitsalltag im Team zu organisieren.\n# F201_47: Informelle Kommunikation erleichtert die Koordination und Planung von Teamarbeit.\n# F201_48: Durch informelle Kommunikation fällt es leichter, gemeinsam Probleme zu lösen.\n# F201_49: Informelle Kommunikation kann dabei helfen, die Organisationskultur gemeinsam zu entwickeln.\n# F201_51: Informelle Kommunikation hilft mir, die Organisation zu verstehen, einschließlich ihrer Mission, Vision, Werte, Überzeugungen und Ziele.\n# F201_52: Durch informelle Kommunikation entsteht ein positives Arbeitsklima.\n\nDa die Variablen nicht korrelieren müssen, brauchen wir uns auch die Korrelationsmatrix nicht anzusehen und auch den Bartlett-Test sowie den KMO-Wert nicht zu berechnen (wir können es natürlich trotzdem tun).\nBevor wir eine PCA durchführen, müssen wir auch hier wieder die optimale Anzahl von Komponenten bestimmen, die extrahiert werden sollen. Dies tun wir mit den bekannten Methoden (Parallel-Analyse, Kaiser-Kriterium, Scree-Plot).\n\npsych::fa.parallel(d_pca, fa = \"pc\", fm = \"pa\")\n\n\n\n\n\n\n\n\nParallel analysis suggests that the number of factors =  NA  and the number of components =  3 \n\npsych::scree(d_pca, fa = F)\n\n\n\n\n\n\n\n\nDie Parallel-Analyse schlägt drei Komponenten vor, nach dem Kaiser-Kriterium und dem Scree-Plot ergeben sich jedoch vier Komponenten (wobei der Screeplot nicht eindeutig ist). Wir entscheiden uns dafür, die Analyse mit vier Komponenten zu rechnen.\nFür die eigentliche Hauptkomponentenanalyse nutzen wir wieder die principal()-Funktion. Hier müssen wir erneut die Anzahl der Komponenten, die Methode (pc = principal component analysis) und die Art der Rotation unserer Matrix angeben.\n\nresults_pca &lt;- d_pca %&gt;%\n  principal(\n    nfactors = 4,\n    rotate = \"oblimin\"\n  )\n\n# Output anpassen\nprint(results_pca,\n  digits = 2, ## auf 2 Nachkommastellen runden\n  cut = .3, ## Ladungen unter .3 nicht anzeigen\n  sort = TRUE ## Items zu den Komponenten sortieren\n)\n\nPrincipal Components Analysis\nCall: principal(r = ., nfactors = 4, rotate = \"oblimin\")\nStandardized loadings (pattern matrix) based upon correlation matrix\n        item   TC1   TC3   TC2   TC4   h2   u2 com\nF201_16    9  0.75                   0.70 0.30 1.1\nF201_31   18  0.71                   0.57 0.43 1.0\nF201_30   17  0.69                   0.56 0.44 1.2\nF201_13    7  0.67                   0.64 0.36 1.2\nF201_52   27  0.58                   0.47 0.53 1.2\nF201_15    8  0.58        0.34       0.52 0.48 1.7\nF201_44   21  0.54                   0.60 0.40 1.8\nF201_29   16  0.53                   0.57 0.43 1.5\nF201_25   13        0.79             0.59 0.41 1.1\nF201_27   15        0.69             0.50 0.50 1.3\nF201_47   23        0.67             0.60 0.40 1.4\nF201_26   14        0.63             0.50 0.50 1.2\nF201_45   22        0.63             0.56 0.44 1.4\nF201_51   26        0.62             0.44 0.56 1.0\nF201_49   25        0.54             0.50 0.50 1.6\nF201_48   24  0.33  0.49             0.51 0.49 1.8\nF201_41   19        0.38        0.35 0.49 0.51 2.6\nF201_07    5              0.81       0.59 0.41 1.0\nF201_02    2              0.78       0.60 0.40 1.0\nF201_08    6              0.67       0.58 0.42 1.2\nF201_05    4              0.62       0.59 0.41 1.2\nF201_03    3              0.49       0.40 0.60 1.6\nF201_01    1  0.33        0.46       0.48 0.52 2.0\nF201_20   12                    0.74 0.67 0.33 1.1\nF201_18   11                    0.68 0.64 0.36 1.2\nF201_17   10  0.34              0.56 0.60 0.40 1.9\nF201_42   20        0.49        0.51 0.52 0.48 2.2\n\n                       TC1  TC3  TC2  TC4\nSS loadings           4.86 4.44 3.11 2.58\nProportion Var        0.18 0.16 0.12 0.10\nCumulative Var        0.18 0.34 0.46 0.55\nProportion Explained  0.32 0.30 0.21 0.17\nCumulative Proportion 0.32 0.62 0.83 1.00\n\n With component correlations of \n     TC1  TC3  TC2  TC4\nTC1 1.00 0.48 0.32 0.43\nTC3 0.48 1.00 0.10 0.26\nTC2 0.32 0.10 1.00 0.33\nTC4 0.43 0.26 0.33 1.00\n\nMean item complexity =  1.4\nTest of the hypothesis that 4 components are sufficient.\n\nThe root mean square of the residuals (RMSR) is  0.05 \n with the empirical chi square  2042.23  with prob &lt;  1.2e-278 \n\nFit based upon off diagonal values = 0.98\n\n\nDie vier Komponenten können als “Zugehörigkeit und Verbundenheit” (TC1) zu Kolleg:innen und der Organisation, “Information und Koordination” (TC3), “Stressbewältigung und Erholung” (TC2) sowie “soziale Beziehungspflege” (TC4) bezeichnet werden. Wir sehen, dass einige Items Doppelladungen haben, also zu zwei Komponenten gehören, zum Beispiel lädt F201_15 (“Durch informelle Kommunikation fühle ich mich weniger einsam”) auf “Zugehörigkeit und Verbundenheit” (TC1) und “Stressbewältigung und Erholung” (TC2), was inhaltlich ja durchaus Sinn macht.\nWollen wir mit den Komponenten weiter rechnen, bieten sich die sog. Scores an, welche die Ausprägung einer Person bzw. eines Falls auf einem Faktor angibt. Scores sind standardisiert, d. h. sie haben einen Mittelwert von 0 und eine Standardabweichung von 1. Positive Werte bedeuten, dass der Fall in Bezug auf eine Komponente und im Vergleich zu allen anderen Fällen ein überdurchschnittliche Ausprägung aufweist und negative Werte bedeuten, dass der Fall gegenüber einer Komponente und im Vergleich zu allen anderen Fällen eine unterdurchschnittliche Die Schätzung der Scores sind in der Regel regressionsbasiert und könnnen korrelieren. Um für jeden Fall die Scores der verschiedenen Komponenten im Datensatz zu haben, speichern wir diese in ein Objekt und binden Sie an den Datensatz. Die ist auch bei der explorativen Faktoranalyse möglich.\n\nscores &lt;- results_pca$scores # Scores extrahieren\n\nd_pca &lt;- cbind(d_pca, scores) # an den Datensatz binden\n\n\n\n\n\n\n\nWeiterführende Materialien\n\n\n\nDas Codebuch für den Datensatz gewohnheiten.xlsx finden Sie hier: Bachelor Kursmaterialien",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html#glossar",
    "href": "explorative-faktorenanalyse.html#glossar",
    "title": "7  Explorative Faktorenanalyse",
    "section": "7.5 Glossar",
    "text": "7.5 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nprincipal\nHauptkomponentenanalyse durchführen\n\n\npsych::cortest.bartlett\nBarlett-Test durchführen\n\n\npsych::fa.diagram\nVisualisierung der Beziehungen/ Ladungen zwischen den Items und den Faktoren\n\n\npsych::fa.parallel\nParallel-Analyse durchführen\n\n\npsych::KMO\nKMO-Wert berechnen\n\n\npsych::scree\nVisualisierung der Eigenwerte zur Bestimmung der Faktorenanzahl",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "explorative-faktorenanalyse.html#hausaufgabe",
    "href": "explorative-faktorenanalyse.html#hausaufgabe",
    "title": "7  Explorative Faktorenanalyse",
    "section": "7.6 Hausaufgabe",
    "text": "7.6 Hausaufgabe\nSie möchten wissen, ob und welche latenten Faktoren hinter den Gewohnheitsstärke-Items für das Fernsehen stehen. Die Items sind in den elf Variablen f_srhi_X enthalten. Eignen sich die vorliegenden Daten für die Analyse? Begründen Sie ggf. die Wahl des Rotationsverfahrens und benennen Sie die Faktoren.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Explorative Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html",
    "href": "konfirmatorische-faktorenanalyse.html",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "",
    "text": "8.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für die konfirmatorische Faktorenanalyse benötigen wir das das lavaan-Paket, für die Reliabilitätsbestimmung semTools. Wie immer laden wir außerdem tidyverse und report.\nlibrary(lavaan)\nlibrary(semTools)\nlibrary(tidyverse)\nlibrary(report)\nFür die konfirmatorische Faktorenanalyse nutzen wir wieder den Excel-Datensatz gewohnheiten.xlsx.\nd_habit &lt;- readxl::read_excel(\"data/gewohnheiten.xlsx\")\nd_habit\n\n# A tibble: 791 × 195\n         id vf_fernseher vf_computer vf_tablet vf_radio vf_zeitung vf_smartphone\n      &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;\n1 403074747            1           1         0        1          0             1\n2 403087148            1           1         1        1          0             1\n3 403129944            1           1         0        1          1             2\n4 403143142            1           1         0        0          0             2\n5 403200247            1           1         0        1          0             1\n# ℹ 786 more rows\n# ℹ 188 more variables: i1_fernseher &lt;dbl&gt;, i1_computer &lt;dbl&gt;, i1_tablet &lt;dbl&gt;,\n#   i1_smartphone &lt;dbl&gt;, i1_radio &lt;dbl&gt;, i1_zeitung &lt;dbl&gt;, vm_ferseher &lt;dbl&gt;,\n#   vm_computer &lt;dbl&gt;, vm_tablet &lt;dbl&gt;, vm_smartphone &lt;dbl&gt;, vm_radio &lt;dbl&gt;,\n#   vm_zeitung &lt;dbl&gt;, r_fernseher &lt;dbl&gt;, r_computer &lt;dbl&gt;, r_tablet &lt;dbl&gt;,\n#   r_smartphone &lt;dbl&gt;, r_radio &lt;dbl&gt;, r_zeitung &lt;dbl&gt;, f_einst1 &lt;dbl&gt;,\n#   f_einst2 &lt;dbl&gt;, f_einst3 &lt;dbl&gt;, f_einst4 &lt;dbl&gt;, f_srhi_r1 &lt;dbl&gt;, …",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#überprüfung-der-items",
    "href": "konfirmatorische-faktorenanalyse.html#überprüfung-der-items",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.2 Überprüfung der Items",
    "text": "8.2 Überprüfung der Items\nZunächst machen wir uns wie immer mit den relevanten Variablen vertraut und nutzen dafür die report_table()-Funktion. Wir nutzen wieder die Skala für die Gewohnheitsstärke bei der Computer-Nutzung (c_srhi_X), die wir für die weiteren Schnitte ausschneiden und in einem neuen Datensatz speichern.\n\nd_cfa &lt;- d_habit |&gt;\n  select(c_srhi_r1:c_srhi_c2)\n\nd_cfa |&gt;\n  report::report_table()\n\nVariable  | n_Obs | Mean |   SD | Median |  MAD |  Min |  Max | Skewness | Kurtosis | percentage_Missing\n--------------------------------------------------------------------------------------------------------\nc_srhi_r1 |   791 | 4.57 | 0.85 |        | 0.00 | 1.00 | 5.00 |    -2.37 |     5.67 |               2.65\nc_srhi_r2 |   791 | 4.31 | 1.04 |        | 0.00 | 1.00 | 5.00 |    -1.67 |     2.23 |               2.65\nc_srhi_r3 |   791 | 4.45 | 0.92 |        | 0.00 | 1.00 | 5.00 |    -2.02 |     4.02 |               2.65\nc_srhi_a1 |   791 | 2.03 | 1.31 |        | 0.00 | 1.00 | 5.00 |     1.03 |    -0.22 |               2.65\nc_srhi_a2 |   791 | 2.49 | 1.38 |        | 1.48 | 1.00 | 5.00 |     0.44 |    -1.08 |               2.65\nc_srhi_a3 |   791 | 1.79 | 1.19 |        | 0.00 | 1.00 | 5.00 |     1.40 |     0.79 |               2.65\nc_srhi_a4 |   791 | 2.68 | 1.28 |        | 1.48 | 1.00 | 5.00 |     0.20 |    -1.01 |               2.65\nc_srhi_a5 |   791 | 2.46 | 1.41 |        | 1.48 | 1.00 | 5.00 |     0.45 |    -1.15 |               2.65\nc_srhi_a6 |   791 | 1.87 | 1.19 |        | 0.00 | 1.00 | 5.00 |     1.25 |     0.47 |               2.65\nc_srhi_c1 |   791 | 3.52 | 1.23 |        | 1.48 | 1.00 | 5.00 |    -0.50 |    -0.66 |               2.65\nc_srhi_c2 |   791 | 3.89 | 1.25 |        | 1.48 | 1.00 | 5.00 |    -0.94 |    -0.19 |               2.65\n\n\nDie Ergebnisse der explorativen Faktoranalyse zur Gewohnheitsstärke bei der Computernutzung (Variablen c_srhi_X) haben drei Faktoren offengelegt: die fehlende Bewusstheit der Computernutzung, den Wiederholungscharakter der Computernutzung und die geringe Kontrollierbarkeit der Computernutzung. Hätten wir uns eingehend mit Gewohnheiten bei der Mediennutzung befasst, hätten wir diese drei Dimensionen auch theoretisch herleiten können vgl. Schnauber, A. (2017). Medienselektion im Alltag. Springer Fachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-15441-7. Mit der konfirmatorischen Faktoranalyse (CFA) testen wir, ob die Items tatsächlich die drei Dimensionen abbilden können, d.h. im Gegensatz zur explorativen Faktorenanalyse wird nicht nur die Anzahl der Faktoren, sondern auch konkret die Zugehörigkeit der Items zu den Faktoren sowie deren Korrelationen untereinander getestet (sog. Messhypothesen).\nGrundsätzlich sollten die Items, die wir für eine konfirmatorische Faktoranalyse verwenden wollen, ein metrisches Skalenniveau aufweisen (d.h. mindestens intervallskaliert) oder dichotom sein. Die verwendeten Items sind alle auf einer 5-er Skala erhoben und wenigstens quasi-metrisch.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#modellschätzung",
    "href": "konfirmatorische-faktorenanalyse.html#modellschätzung",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.3 Modellschätzung",
    "text": "8.3 Modellschätzung\nFür die Modellschätzung (d.h. wir gehen von drei Dimensionen bei der Gewohnheitsstärke aus) nutzen wir das Paket lavaan, das wir schon aus dem Kapitel zur Pfadanalyse kennen (Messmodelle sind nichts anderes als Strukturgleichungsmodelle). Auch hier wird zunächst das Modell spezifiziert und anschließend mit den empirischen Daten geschätzt.\nWir definieren im lavaan-Modell jede latente Variable bzw. Faktor mit einem character-Objekt im folgenden Format:\nlatente_variable =~ variable1 + variable2 + ... + variable_n\nFür unsere CFA mit 3 Faktoren heißt das:\n\ncfa_model &lt;- \"\n   repetition =~ c_srhi_r1 + c_srhi_r2 + c_srhi_r3\n   automatism =~ c_srhi_a1 + c_srhi_a2 + c_srhi_a3 + c_srhi_a4 + c_srhi_a5 + c_srhi_a6\n   control =~ c_srhi_c1 + c_srhi_c2\n\"\n\nIm nächsten Schritt nutzen wir die Funktion cfa() mit unserer Spezifikation, das die latenten Faktoren enthält.\n\ncfa_results &lt;- lavaan::cfa(cfa_model, data = d_cfa)\n\nSobald das Modell geschätzt wurde, können wir uns mit Hilfe der Funktion summary() eine Modellzusammenfassung ansehen. Dabei fordern wir sowohl Modellgütemaße als auch vollstandardisierte Koeffizienten (z.B. für Faktorladungen) an.\n\nsummary(cfa_results, fit = TRUE, std = TRUE)\n\nlavaan 0.6-18 ended normally after 35 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        25\n\n                                                  Used       Total\n  Number of observations                           770         791\n\nModel Test User Model:\n                                                      \n  Test statistic                               301.621\n  Degrees of freedom                                41\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              4345.426\n  Degrees of freedom                                55\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.939\n  Tucker-Lewis Index (TLI)                       0.919\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -11352.785\n  Loglikelihood unrestricted model (H1)     -11201.975\n                                                      \n  Akaike (AIC)                               22755.570\n  Bayesian (BIC)                             22871.730\n  Sample-size adjusted Bayesian (SABIC)      22792.343\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.091\n  90 Percent confidence interval - lower         0.081\n  90 Percent confidence interval - upper         0.101\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.970\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.069\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  repetition =~                                                         \n    c_srhi_r1         1.000                               0.624    0.731\n    c_srhi_r2         1.427    0.070   20.282    0.000    0.890    0.856\n    c_srhi_r3         1.106    0.058   18.917    0.000    0.690    0.749\n  automatism =~                                                         \n    c_srhi_a1         1.000                               1.046    0.798\n    c_srhi_a2         0.881    0.045   19.447    0.000    0.922    0.669\n    c_srhi_a3         0.984    0.037   26.720    0.000    1.029    0.863\n    c_srhi_a4         0.622    0.044   14.208    0.000    0.651    0.509\n    c_srhi_a5         0.948    0.046   20.657    0.000    0.991    0.703\n    c_srhi_a6         0.992    0.037   27.002    0.000    1.037    0.871\n  control =~                                                            \n    c_srhi_c1         1.000                               1.091    0.885\n    c_srhi_c2         0.943    0.046   20.362    0.000    1.028    0.820\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  repetition ~~                                                         \n    automatism        0.028    0.027    1.037    0.300    0.043    0.043\n    control           0.440    0.037   11.775    0.000    0.647    0.647\n  automatism ~~                                                         \n    control           0.320    0.049    6.501    0.000    0.281    0.281\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .c_srhi_r1         0.340    0.022   15.304    0.000    0.340    0.466\n   .c_srhi_r2         0.289    0.030    9.625    0.000    0.289    0.267\n   .c_srhi_r3         0.372    0.025   14.722    0.000    0.372    0.439\n   .c_srhi_a1         0.624    0.039   16.081    0.000    0.624    0.363\n   .c_srhi_a2         1.047    0.058   18.014    0.000    1.047    0.552\n   .c_srhi_a3         0.362    0.027   13.620    0.000    0.362    0.255\n   .c_srhi_a4         1.208    0.064   18.933    0.000    1.208    0.740\n   .c_srhi_a5         1.003    0.057   17.674    0.000    1.003    0.505\n   .c_srhi_a6         0.342    0.026   13.185    0.000    0.342    0.241\n   .c_srhi_c1         0.330    0.050    6.551    0.000    0.330    0.217\n   .c_srhi_c2         0.514    0.050   10.339    0.000    0.514    0.327\n    repetition        0.389    0.036   10.904    0.000    1.000    1.000\n    automatism        1.093    0.085   12.938    0.000    1.000    1.000\n    control           1.190    0.089   13.321    0.000    1.000    1.000\n\n\nDie Ausgabe besteht aus drei Teilen:\n\nDie Kopfzeile: Informationen über Lavaan, die Optimierungsmethode, die Anzahl der freien Parameter und die Anzahl der in der Analyse verwendeten Beobachtungen (in diesem Fall n = 770)\nInformationen zum Modellfit: Enthält verschiedene Anpassungsindizes zur Bewertung der Modellanpassung\nParameter-Schätzunger: Der letzte Abschnitt enthält alle Parameter, die geschätzt wurden (einschließlich der Faktorladungen, Varianzen, Schwellenwerte…)\n\nZunächst schauen wir, ob das Modell konvergiert ist, dann auf die Fit-Indizes .\nEine signifikante Teststatistik (ein signifikanter Chi-Quadrat-Wert) weist auf eine Diskrepanz zwischen dem vorgeschlagenen Modell und den beobachteten Daten hin (Nullhypothese: die modellimplizierte Kovarianzmatrix entspricht der empirischen Kovarianzmatrix). Der signifikante Chi-Quadrat-Wert zeigt, dass das Modell nicht perfekt zu den Daten passt, was aber bei größeren Stichproben häufig vorkommt, da dort auch kleinere Abweichungen signifikant sind. Daher betrachten wir auch immer eine Reihe von alternativen Fit-Indizes.\n\n\n\n\n\n\nFit-Indizes für die CFA\n\n\n\n\n\n\nCFI (Comparative Fit Index) und TLI (Tucker-Lewis-Index) messen die Verbesserung der Modellanpassung im Vergleich zu einem Basismodell, in dem nichts korreliert. Sie sollten bei guten Modellen &gt;= 0.95 sein.\nRMSEA (Root mean Square Error of Approximation) bewertet die Modellpassung zwischen dem Modell und den beobachteten Daten unter Berücksichtigung des Approximationsfehlers, sollte &lt;= 0.05 und nicht signifikant sein.\nSRMR (Standardized Root Mean Square Residual): misst die standardisierte Diskrepanz zwischen beobachteten und modellimplzierten Korrelationen zwischen den gemessenen Variablen. Ein kleinerer SRMR-Wert zeigt eine bessere Anpassung an, sollte &lt;= 0.08, besser &lt;= .05 sein.\n\n\n\n\nIm Beispiel ist der Chi-Quadrat-Test signifikant \\(\\chi^2\\)(41) = 301.6, p &lt; .05, CFI und TLI liegen unter 0.95, RMSEA über 0.05, d.h. diese Anpassungsindizes weisen auf einen moderaten bis schlechten Modelfit hin, auch wenn der SRMR befriedigend ist.\nBetrachten wir anschließend die standardisierten Faktorladungen, können wir sehen, dass die meisten Items recht hoch auf “ihren” Faktor laden (&gt;= .7). Das bedeutet, dass die latente Variable mindestens 50% der Varianz in den Items erklären kann (\\(R^2\\) = .7^2 = .49) Kurz, es gibt noch Verbesserungsbedarf, aber die Skala scheint die angenommene dreidimensionale Faktorstruktur zu haben. Die Faktoren Kontrolle und Wiederholung korrelieren sehr stark (r = .648), Wiederholung und Automatismus hingegen fast gar nicht, wie wir im Abschnitt Covariances des Outputs sehen können.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#modellverbesserung",
    "href": "konfirmatorische-faktorenanalyse.html#modellverbesserung",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.4 Modellverbesserung",
    "text": "8.4 Modellverbesserung\nWas kann die Ursache für fehlende Modellgüte sein?\n\nEinige Items gehören zu einem anderen oder auch zu gar keinem der spezifizierten Faktoren, sie sind schlicht keine validen Indikatoren des Konstrukts.\nEinige Items gehören zu mehr als einem spezifizierten Faktor, d.h. es gibt nicht-modellierte Doppelladungen, deren Nicht-Berücksichtigung den Modellfit verschlechtern.\nDie Variablen sind nicht (annähernd) normalverteilt, so dass man mit einem anderen Schätzverfahren arbeiten sollte.\nDie Messhypothesen sind schlicht falsch, d.h. die unterstellte Faktorstruktur stimmt insgesamt nicht\n\n\n8.4.1 Faktorladungen\nBei den Faktorladungen sehen wir, dass wieder das Item c_srhi_a4 deutlich geringer lädt als die anderen (wie bei der explorativen Faktoranalyse auch). Wir könnten daher versuchen, durch das Weglassen von c_srhi_a4 den Modellfit zu verbessern. Beim Löschen von Items muss allerdings auch der Validitätsaspekt berücksichtigt werden. Eine Skala mit vielen fast identisch formulierten Items wird eine hohe Reliabilität und Items hohe Ladungen haben, allerdings auch nur einen (zu) schmalen Aspekt des theoretischen Konstrukts abdecken, daher muss man überlegen, ob das zu löschende Item aus dieser Perspektive verzichtbar ist.\n\ncfa_model2 &lt;- \"\n   repetition =~ c_srhi_r1 + c_srhi_r2 + c_srhi_r3\n   automatism =~ c_srhi_a1 + c_srhi_a2 + c_srhi_a3 + c_srhi_a5 + c_srhi_a6\n   control =~ c_srhi_c1 + c_srhi_c2\n\"\n\ncfa_results2 &lt;- lavaan::cfa(cfa_model2, data = d_cfa)\nsummary(cfa_results2, fit = T, std = T)\n\nlavaan 0.6-18 ended normally after 35 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        23\n\n                                                  Used       Total\n  Number of observations                           770         791\n\nModel Test User Model:\n                                                      \n  Test statistic                               243.463\n  Degrees of freedom                                32\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              4082.531\n  Degrees of freedom                                45\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.948\n  Tucker-Lewis Index (TLI)                       0.926\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -10174.154\n  Loglikelihood unrestricted model (H1)     -10052.422\n                                                      \n  Akaike (AIC)                               20394.308\n  Bayesian (BIC)                             20501.174\n  Sample-size adjusted Bayesian (SABIC)      20428.139\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.093\n  90 Percent confidence interval - lower         0.082\n  90 Percent confidence interval - upper         0.104\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.974\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.071\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  repetition =~                                                         \n    c_srhi_r1         1.000                               0.624    0.731\n    c_srhi_r2         1.425    0.070   20.300    0.000    0.889    0.855\n    c_srhi_r3         1.106    0.058   18.935    0.000    0.690    0.750\n  automatism =~                                                         \n    c_srhi_a1         1.000                               1.037    0.791\n    c_srhi_a2         0.869    0.046   18.809    0.000    0.902    0.655\n    c_srhi_a3         1.004    0.038   26.699    0.000    1.041    0.873\n    c_srhi_a5         0.943    0.047   20.165    0.000    0.978    0.694\n    c_srhi_a6         1.008    0.038   26.849    0.000    1.045    0.878\n  control =~                                                            \n    c_srhi_c1         1.000                               1.091    0.885\n    c_srhi_c2         0.942    0.046   20.361    0.000    1.027    0.820\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  repetition ~~                                                         \n    automatism        0.018    0.027    0.688    0.491    0.028    0.028\n    control           0.440    0.037   11.780    0.000    0.647    0.647\n  automatism ~~                                                         \n    control           0.310    0.049    6.355    0.000    0.274    0.274\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .c_srhi_r1         0.339    0.022   15.293    0.000    0.339    0.465\n   .c_srhi_r2         0.290    0.030    9.676    0.000    0.290    0.268\n   .c_srhi_r3         0.371    0.025   14.717    0.000    0.371    0.438\n   .c_srhi_a1         0.642    0.040   16.206    0.000    0.642    0.374\n   .c_srhi_a2         1.084    0.060   18.127    0.000    1.084    0.571\n   .c_srhi_a3         0.338    0.026   12.899    0.000    0.338    0.238\n   .c_srhi_a5         1.029    0.058   17.760    0.000    1.029    0.518\n   .c_srhi_a6         0.326    0.026   12.612    0.000    0.326    0.230\n   .c_srhi_c1         0.329    0.050    6.523    0.000    0.329    0.216\n   .c_srhi_c2         0.515    0.050   10.365    0.000    0.515    0.328\n    repetition        0.389    0.036   10.916    0.000    1.000    1.000\n    automatism        1.075    0.084   12.773    0.000    1.000    1.000\n    control           1.191    0.089   13.330    0.000    1.000    1.000\n\n\nDer Chi-Quadrat-Test ist zwar immer noch signifikant, CFI und TLI haben sich verbessert, RMSEA liegt unter 0.05 und SRMR liegt unter 0.08, passt also. Wir könnten also noch weiter versuchen, unser Modell zu verbessern.\n\n\n8.4.2 Modification Indices\nHierfür könnten wir uns die sog. Modification Indices (MI) des Modells ansehen, die wir mit der entsprechenden Funktion modificationindices() erhalten. Jeder MI gibt die Verbesserung des Modells (=Reduktion des Chi-Quadrat-Werts) wieder, wenn wir den vorgeschlagenen Parameter (Ladung, Korrelation, etc.) zum Modell hinzufügen würden. Die Spalte mi im Output-Tibble enthält den eigentlichen Modification Index, d.h. wir können absteigend danach sortieren und uns nur die 5 größten MI ausgeben lassen, die also das Modell am meisten verbessern würden.\n\nlavaan::modificationindices(cfa_results2) |&gt;\n  arrange(desc(mi)) |&gt;\n  head(5)\n\n         lhs op       rhs     mi   epc sepc.lv sepc.all sepc.nox\n1 repetition =~ c_srhi_a5 68.817 0.554   0.345    0.245    0.245\n2  c_srhi_a2 ~~ c_srhi_a5 63.061 0.336   0.336    0.318    0.318\n3  c_srhi_a3 ~~ c_srhi_a6 52.869 0.209   0.209    0.631    0.631\n4    control =~ c_srhi_a5 50.159 0.282   0.307    0.218    0.218\n5 repetition =~ c_srhi_a2 24.293 0.334   0.209    0.151    0.151\n\n\nWir sehen in den ersten beiden Zeilen das Item c_srhi_a5: In Zeile 1 wird eine Doppelladung repetition =~ c_srhi_a5 vorgeschlagen, d.h. das Item spiegelt nicht nur den Automatismus-, sondern z.T. auch den Wiederholungsaspekt wider. In Zeile 2 wird vorgeschlagen, doch die Items a2 und a5 korrelieren zu lassen ~~, was ein Indikator dafür ist, dass beide Items außer dem Automatisierungsaspekt noch eine Gemeinsamkeit haben. Beide MI-Vorschläge würden die gewünschte Einfachstruktur (jedes Item gehört zu genau einem Faktor) der Skala verändern, weshalb wir vielleicht c_srhi_a5 auch entfernen sollten, zumal das Item auch noch auf die Kontrolldimension laden würde, siehe Zeile 4.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#reliablität",
    "href": "konfirmatorische-faktorenanalyse.html#reliablität",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.5 Reliablität",
    "text": "8.5 Reliablität\nZum Schluss können wir uns noch die Realiabilität der fertigen Skala ansehen. Neben Cronbachs Alpha werden noch weitere Reliabilitätskoeffizienten ausgegeben (Bollen’s ω (omega), Bentler’s ω (omega2) und McDonald’s ω (omega3)), die auf dem geschätzten CFA-Modell basieren und weniger (falsche) Annahmen über die Faktorstruktur haben als Alpha. Bei einem guten Modell unterscheiden sich die Werte nicht sehr stark, enthält das Modell Items mit niedrigen Faktorladungen, die aber trotzdem klar zu einem Faktor gehörten, weichen die Omega-Werte erheblich von Alpha ab. Alle Werte liegen zwischen 0 und 1, wobei Werte, die näher bei 1 liegen, für eine gute Reliabilität stehen (vgl. das dazugehörige Kapitel in der BA-Statistik). Die letzte Zeile avevar bezeichnet die Average Variance Extracted, also die durchschnittlichen quadrierten Faktorladungen, die äquivalent zum o.g. \\(R^2\\) sind, d.h. wieviel Varianz in den Items durch die latente Variable erklärt werden kann. Auch hier sind höhere Werte besser, was bei allen drei Subskalen der Fall ist.\n\nsemTools::reliability(cfa_results2)\n\n       repetition automatism   control\nalpha   0.8208750  0.8831898 0.8410305\nomega   0.8291862  0.8798391 0.8417930\nomega2  0.8291862  0.8798391 0.8417930\nomega3  0.8273931  0.8702994 0.8417930\navevar  0.6235352  0.5949607 0.7269868\n\n\n\n\n\n\n\n\nWeiterführende Materialien\n\n\n\nDas Codebuch für den Datensatz gewohnheiten.xlsx finden Sie hier: Bachelor Kursmaterialien",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#glossar",
    "href": "konfirmatorische-faktorenanalyse.html#glossar",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.6 Glossar",
    "text": "8.6 Glossar\n\n\n\n\n\nFunktion\nDefinition\n\n\n\n\nlavaan::cfa\nKonfirmatorische Faktorenanalyse\n\n\nlavaan::modificationindices\nVerbesserungsfähigkeit des Modells berechnen\n\n\nsemTools::reliability\nReliabilitätskennwerte berechnen",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "konfirmatorische-faktorenanalyse.html#hausaufgabe",
    "href": "konfirmatorische-faktorenanalyse.html#hausaufgabe",
    "title": "8  Konfirmatorische Faktorenanalyse",
    "section": "8.7 Hausaufgabe",
    "text": "8.7 Hausaufgabe\nSie möchten prüfen, ob die Items zur Gewohnheitsstärke auch bei der Smartphonenutzung die drei Dimensionen abbilden. Die Items sind in den elf Variablen s_srhi_X enthalten. Definieren und schätzen Sie das Modell. Passt das Modell zu den Daten? Wie kann man ggf. das Modell verbessern?",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Konfirmatorische Faktorenanalyse</span>"
    ]
  },
  {
    "objectID": "messinvarianz.html",
    "href": "messinvarianz.html",
    "title": "9  Messinvarianz",
    "section": "",
    "text": "9.1 Pakete und Daten\nWir laden zunächst die notwendigen R-Pakete. Für die konfirmatorische Faktorenanalyse benötigen wir das lavaan-Paket. Wie immer laden wir außerdem tidyverse und report.\nlibrary(lavaan)\nlibrary(tidyverse)\nlibrary(report)\nFür die konfirmatorische Faktorenanalyse nutzen wir wieder den Excel-Datensatz gewohnheiten.xlsx. Wir wählen diesmal nur die Unterdimension Wiederholung bei der TV-Gewohnheitsvariable.\nd_habit &lt;- readxl::read_excel(\"data/gewohnheiten.xlsx\")\nd_habit |&gt;\n  select(starts_with(\"f_srhi_r\"))\n\n# A tibble: 791 × 3\n  f_srhi_r1 f_srhi_r2 f_srhi_r3\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1         5         4         4\n2         3         3         3\n3         5         5         4\n4         3         1         3\n5         5         4         5\n# ℹ 786 more rows\nZunächst schätzen wir eine konfirmatorische Faktorenanalyse für den SRHI-R, wobei wir nur auf die Ladungsstruktur achten. Das Modell ist mit 3 Indikatoren gerade identifiziert, d.h. es gibt keine Freiheitsgrade und daher auch keinen Modellfit.\nsrhi_model &lt;- \"\n   f_srhi =~ f_srhi_r1 + f_srhi_r2 + f_srhi_r3\n\"\ncfa_basic &lt;- cfa(srhi_model, data = d_habit)\nsummary(cfa_basic, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 14 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n                                                  Used       Total\n  Number of observations                           740         791\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srhi_r1         1.000                               0.936    0.862\n    f_srhi_r2         1.130    0.043   26.034    0.000    1.058    0.839\n    f_srhi_r3         1.073    0.041   25.977    0.000    1.004    0.837\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.302    0.027   11.130    0.000    0.302    0.256\n   .f_srhi_r2         0.470    0.037   12.586    0.000    0.470    0.296\n   .f_srhi_r3         0.431    0.034   12.709    0.000    0.431    0.299\n    f_srhi            0.877    0.063   13.864    0.000    1.000    1.000",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Messinvarianz</span>"
    ]
  },
  {
    "objectID": "messinvarianz.html#parameter-gleichsetzung",
    "href": "messinvarianz.html#parameter-gleichsetzung",
    "title": "9  Messinvarianz",
    "section": "9.2 Parameter-Gleichsetzung",
    "text": "9.2 Parameter-Gleichsetzung\n\n9.2.1 Kongenerisches Modell\nWir beginnen mit dem kongerischen Modell, in dem alle Ladungen frei geschätzt werden. Normalerweise wird immer die Ladung des ersten Indikators nicht geschätzt, sondern auf 1 fixiert, um das Modell zu identifizieren. Die Modellidentifikation erreichen wir jetzt, indem stattdessen die Varianz der latenten Variable auf 1 gesetzt wird (mit std.lv = TRUE). Dies ermöglicht uns, alle Faktorladungen im kongenerischen Modell frei zu schätzen und anschließend im tau-äquivalenten Modell alle 3 Ladungen gleichzusetzen.\n\nsrhi_model_con &lt;- \"\n   f_srhi =~ f_srhi_r1 + f_srhi_r2 + f_srhi_r3\n\"\ncfa_con &lt;- cfa(srhi_model_con, data = d_habit, std.lv = TRUE)\nsummary(cfa_con, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 13 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n\n                                                  Used       Total\n  Number of observations                           740         791\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srhi_r1         0.936    0.034   27.727    0.000    0.936    0.862\n    f_srhi_r2         1.058    0.040   26.697    0.000    1.058    0.839\n    f_srhi_r3         1.004    0.038   26.605    0.000    1.004    0.837\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.302    0.027   11.130    0.000    0.302    0.256\n   .f_srhi_r2         0.470    0.037   12.586    0.000    0.470    0.296\n   .f_srhi_r3         0.431    0.034   12.709    0.000    0.431    0.299\n    f_srhi            1.000                               1.000    1.000\n\n\nDie standardisierten Ladungen sehen schon einmal gut aus, mit Werten &gt; .80. Wir sehen auch, dass die unstandardisierten Ladungen fast gleich groß sind.\n\n\n9.2.2 Tau-äquivalentes Modell\nAngesichts der gleich großen Ladungen können wir ein sog. tau-äquivalentes Modell schätzen. Dies impliziert, dass alle (unstandardisierten) Faktorladungen gleich sind - alle Indikatoren sind also gleich valide. Ein tau-äquivalentes Modell hat den Vorteil, dass es viel sparsamer ist, da statt 3 nur eine einzige Faktorladung geschätzt werden muss. Wir sparen 2 Freiheitsgrade und erhalten daher dann selbst für einen Faktor mit 3 Items Modellgütemaße. Die Gleichsetzung der Ladungen lässt sich in lavaan leicht realisieren, in dem dasselbe Koeffizientenlabel für die Pfade verwendet wird. Die Art, Labels zu vergeben, hatten wir bereits bei der Mediationsanalyse kennengelernt (a und b-Pfade). Konventionell werden Ladungen mit dem griechischen Lambda bezeichnet, so dass wir hier jede Ladung entsprechend labeln.\n\nsrhi_model_tau &lt;- \"\n   f_srhi =~ lambda*f_srhi_r1 + lambda*f_srhi_r2 + lambda*f_srhi_r3\n\"\ncfa_tau &lt;- cfa(srhi_model_tau, data = d_habit, std.lv = TRUE)\nsummary(cfa_tau, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 10 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                         6\n  Number of equality constraints                     2\n\n                                                  Used       Total\n  Number of observations                           740         791\n\nModel Test User Model:\n                                                      \n  Test statistic                                10.090\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.006\n\nModel Test Baseline Model:\n\n  Test statistic                              1206.749\n  Degrees of freedom                                 3\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.993\n  Tucker-Lewis Index (TLI)                       0.990\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2918.743\n  Loglikelihood unrestricted model (H1)      -2913.699\n                                                      \n  Akaike (AIC)                                5845.487\n  Bayesian (BIC)                              5863.913\n  Sample-size adjusted Bayesian (SABIC)       5851.212\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.074\n  90 Percent confidence interval - lower         0.033\n  90 Percent confidence interval - upper         0.122\n  P-value H_0: RMSEA &lt;= 0.050                    0.148\n  P-value H_0: RMSEA &gt;= 0.080                    0.474\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.043\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srh_1 (lmbd)    0.987    0.029   33.902    0.000    0.987    0.886\n    f_srh_2 (lmbd)    0.987    0.029   33.902    0.000    0.987    0.809\n    f_srh_3 (lmbd)    0.987    0.029   33.902    0.000    0.987    0.828\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.267    0.025   10.655    0.000    0.267    0.215\n   .f_srhi_r2         0.514    0.035   14.734    0.000    0.514    0.345\n   .f_srhi_r3         0.446    0.032   13.983    0.000    0.446    0.314\n    f_srhi            1.000                               1.000    1.000\n\n\nWir erkennen zunächst an den Faktorladungen unter Latent Variables, dass die Gleichsetzung funktioniert hat. Zudem können wir am niedrigen (fast nicht-signfikanten) Chi-Quadrat-Wert und an den anderen Modellgütemaßen erkennen, dass das tau-äquivalente Modell gut zu den empirischen Daten passt.\n\n\n9.2.3 Modellvergleich\nDie Frage ist nun, ob die Gleichsetzung der Ladungen die Modellgüte signifikant verschlechtert hat - der absolute Chi-Quadrat-Wert kann mit zunehmenden Freiheitsgraden nur steigen. Dies können wir mit einem Chi-Quadrat-Differenztest prüfen, bei dem das kongenerische (Ladungen frei geschätzt) mit dem tau-äquivalenten Modell (alle Ladungen gleich) verglichen wird.\nFür den Modellvergleich verwenden wir wie immer die anova()-Funktion, die wir bereits vielfach gesehen haben.\n\nanova(cfa_con, cfa_tau)\n\n\nChi-Squared Difference Test\n\n        Df    AIC    BIC Chisq Chisq diff    RMSEA Df diff Pr(&gt;Chisq)   \ncfa_con  0 5839.4 5867.0  0.00                                          \ncfa_tau  2 5845.5 5863.9 10.09      10.09 0.073933       2   0.006442 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWir sehen, dass das tau-äquivalente Modell signifikant schlechteren Fit hat als das kongenerische, auch wenn die Modellgüte bei beiden Modellen noch sehr gut ist. Es bleibt unsere Entscheidung, mit welchem Modell wir weiterarbeiten. Wir bleiben vorerst beim kongenerischen Modell.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Messinvarianz</span>"
    ]
  },
  {
    "objectID": "messinvarianz.html#invarianztests-über-gruppen",
    "href": "messinvarianz.html#invarianztests-über-gruppen",
    "title": "9  Messinvarianz",
    "section": "9.3 Invarianztests über Gruppen",
    "text": "9.3 Invarianztests über Gruppen\nBei der Prüfung von Messinvarianz über Gruppen (oder über Messzeitpunkte) geht es um die Frage, ob die Messung in den Gruppen bzw. über die Zeit so weit konsistent ist, dass Unterschiede auf tatsächliche Differenzen in der latenten Variable zurückzuführen sind und nicht auf unterschiedliche Messung. Technisch wird das erreicht, indem wir immer stärkere Gleichsetzungs-Constraints spezifizieren und schauen, ob die Modelle dadurch signifikant schlechter werden. Wir schätzen also schrittweise immer strengere Modelle und prüfen mit Differenztests, ob die Gleichsetzungen das Modell verschlechtern. Wenn sie das tun, wissen wir, dass es Unterschiede in der Messung zwischen den Gruppen gibt und wir daher diese nur schwer bzw. gar nicht vergleichen dürfen.\n\n9.3.1 Konfigurale Invarianz\nWir vergleichen die Messinvarianz der Einfachheit halber zwischen Männern und Frauen, also mit der Gruppenvariable group = \"p_2\" im CFA-Aufruf. Zunächst schätzen wir das Grundmodell ohne Constraints. Wenn schon dieses nicht passt, heißt das, die faktorielle Struktur ist in den Gruppen schon fundamental unterschiedlich (etwa zweifaktoriell bei Männern, einfaktoriell bei Frauen o.ä.). Da unser Modell mit 3 Indikatoren allerdings, wie oben beschrieben, nur gerade identifiziert ist, passt es automatisch, d.h. wir erhalten gar keinen Modellfit, sondern nur Schätzungen für die Ladungen der Items.\n\ncfa_config &lt;- cfa(srhi_model, data = d_habit, group = \"p_2\")\nsummary(cfa_config, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 25 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n\n  Number of observations per group:               Used       Total\n    Weiblich                                       367         390\n    Männlich                                       373         401\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n  Test statistic for each group:\n    Weiblich                                     0.000\n    Männlich                                     0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1211.589\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2910.504\n  Loglikelihood unrestricted model (H1)      -2910.504\n                                                      \n  Akaike (AIC)                                5857.008\n  Bayesian (BIC)                              5939.928\n  Sample-size adjusted Bayesian (SABIC)       5882.772\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Weiblich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srhi_r1         1.000                               0.941    0.849\n    f_srhi_r2         1.152    0.062   18.719    0.000    1.084    0.861\n    f_srhi_r3         1.083    0.059   18.294    0.000    1.019    0.837\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         4.226    0.058   73.096    0.000    4.226    3.816\n   .f_srhi_r2         3.817    0.066   58.135    0.000    3.817    3.035\n   .f_srhi_r3         3.943    0.064   62.051    0.000    3.943    3.239\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.342    0.040    8.563    0.000    0.342    0.279\n   .f_srhi_r2         0.408    0.051    8.019    0.000    0.408    0.258\n   .f_srhi_r3         0.444    0.049    9.082    0.000    0.444    0.300\n    f_srhi            0.885    0.092    9.588    0.000    1.000    1.000\n\n\nGroup 2 [Männlich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srhi_r1         1.000                               0.931    0.876\n    f_srhi_r2         1.109    0.061   18.100    0.000    1.033    0.818\n    f_srhi_r3         1.062    0.057   18.487    0.000    0.989    0.837\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         4.249    0.055   77.174    0.000    4.249    3.996\n   .f_srhi_r2         3.775    0.065   57.718    0.000    3.775    2.989\n   .f_srhi_r3         3.992    0.061   65.236    0.000    3.992    3.378\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.263    0.037    7.137    0.000    0.263    0.233\n   .f_srhi_r2         0.528    0.055    9.649    0.000    0.528    0.331\n   .f_srhi_r3         0.418    0.047    8.913    0.000    0.418    0.299\n    f_srhi            0.867    0.086   10.034    0.000    1.000    1.000\n\n\nDer Output für die Parameterschätzer ist getrennt für Männer und Frauen, und wir erkennen, dass in diesem Modell Ladungen, Intercepts und Varianzen pro Geschlecht frei geschätzt werden.\n\n\n9.3.2 Metrische Invarianz\nAls metrische Invarianz (weak invariance) bezeichnet man das Modell, in dem alle Ladungen gleichgesetzt werden. Will man (z.B. im Rahmen einer Moderationshypothese) vergleichen, ob der Zusammenhang zwischen TV-Nutzung und Gewohnheitsstärke bei Männern und Frauen gleich ist, muss zumindest diese metrische Invarianz gewährleistet sein. Wir könnten die Gleichsetzung einzeln im Modell spezifizieren (s.o.), allerdings gibt es in Lavaan eine fertige Lösung über das group.equal Funktionsargument. Hier können wir pauschal festlegen, das alle Ladungen gleichgesetzt werden sollen. Das funktioniert, solange wir keine partiellen Gleichsetzungen wollen (also einzelne Ladungen frei schätzen).\n\ncfa_metric &lt;- cfa(srhi_model,\n  data = d_habit, group = \"p_2\",\n  group.equal = c(\"loadings\")\n)\nsummary(cfa_metric, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 23 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        18\n  Number of equality constraints                     2\n\n  Number of observations per group:               Used       Total\n    Weiblich                                       367         390\n    Männlich                                       373         401\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.241\n  Degrees of freedom                                 2\n  P-value (Chi-square)                           0.887\n  Test statistic for each group:\n    Weiblich                                     0.117\n    Männlich                                     0.124\n\nModel Test Baseline Model:\n\n  Test statistic                              1211.589\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.004\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2910.625\n  Loglikelihood unrestricted model (H1)      -2910.504\n                                                      \n  Akaike (AIC)                                5853.249\n  Bayesian (BIC)                              5926.955\n  Sample-size adjusted Bayesian (SABIC)       5876.150\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.048\n  P-value H_0: RMSEA &lt;= 0.050                    0.953\n  P-value H_0: RMSEA &gt;= 0.080                    0.012\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.006\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Weiblich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srh_1           1.000                               0.950    0.853\n    f_srh_2 (.p2.)    1.131    0.043   26.103    0.000    1.074    0.858\n    f_srh_3 (.p3.)    1.072    0.041   26.044    0.000    1.018    0.837\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         4.226    0.058   72.743    0.000    4.226    3.797\n   .f_srhi_r2         3.817    0.065   58.397    0.000    3.817    3.048\n   .f_srhi_r3         3.943    0.064   62.063    0.000    3.943    3.240\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.337    0.039    8.742    0.000    0.337    0.272\n   .f_srhi_r2         0.415    0.049    8.537    0.000    0.415    0.264\n   .f_srhi_r3         0.444    0.047    9.383    0.000    0.444    0.300\n    f_srhi            0.902    0.085   10.619    0.000    1.000    1.000\n\n\nGroup 2 [Männlich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srh_1           1.000                               0.924    0.872\n    f_srh_2 (.p2.)    1.131    0.043   26.103    0.000    1.045    0.822\n    f_srh_3 (.p3.)    1.072    0.041   26.044    0.000    0.990    0.838\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         4.249    0.055   77.496    0.000    4.249    4.013\n   .f_srhi_r2         3.775    0.066   57.403    0.000    3.775    2.972\n   .f_srhi_r3         3.992    0.061   65.224    0.000    3.992    3.377\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.269    0.035    7.773    0.000    0.269    0.239\n   .f_srhi_r2         0.522    0.053    9.814    0.000    0.522    0.324\n   .f_srhi_r3         0.416    0.045    9.252    0.000    0.416    0.298\n    f_srhi            0.853    0.079   10.861    0.000    1.000    1.000\n\n\nWir können bei den Parameterschätzern erkennen, dass die (unstandardisierten) Ladungen bei Item 2 und 3 gleichgesetzt sind, die Ladung 1 war ohnehin wie immer auf 1 fixiert. Durch die Gleichsetzung haben wir Freiheitsgrade gewonnen und erhalten daher nun auch einen (sehr guten) Modellfit mit einem nicht-signifikanten Chi-Quadrat-Wert. Dies spricht schon dafür, dass metrische Invarianz vorliegt. Wir prüfen dies noch einmal formal:\nModellvergleich konfigurale vs. metrische Invarianz\n\nanova(cfa_config, cfa_metric)\n\n\nChi-Squared Difference Test\n\n           Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\ncfa_config  0 5857.0 5939.9 0.0000                                    \ncfa_metric  2 5853.2 5927.0 0.2407    0.24066     0       2     0.8866\n\n\nIn der Tat hat sich trotz der Gleichsetzung der SRHI-R-Faktorladungen bei Männern und Frauen die Modellgüte nicht signifikant verschlechtert, so dass wir davon ausgehen können, alle Items sind gleich valide Indikatoren der Wiederholungsdimension von TV-Gewohnheitsstärke bei Frauen und Männern.\n\n\n9.3.3 Skalare Invarianz\nWollen wir die Mittelwerte der Gewohnheitsstärke zwischen Männern und Frauen vergleichen (etwa per t-Test der Mittelwert- oder Factorscores), muss die sog. skalare Invarianz (strong invariance) gewährleistet sein, bei der Ladungen und Intercepts gleichgesetzt werden. Die Intercepts beschreiben das Verhältnis von latentem Wert und den eigentlichen Scores der einzelnen Items. Wenn z.B. weibliche Teilnehmerinnen mit derselben wahren Gewohnheitsstärke tendenziell immer etwas niedrigere Item-Wert haben als männliche Teilnehmer, etwa weil sie regelmäßig oder Routine anders verstehen, würden wir beim Vergleich der Mittelwert zu falschen Schlüssen kommen. Wir setzen also im nächsten Schritt Ladungen und Intercepts über die Gruppen gleich und vergleichen direkt die Modelle.\n\ncfa_scalar &lt;- cfa(srhi_model,\n  data = d_habit, group = \"p_2\",\n  group.equal = c(\"loadings\", \"intercepts\")\n)\nsummary(cfa_scalar, fit.measures = TRUE, standardized = TRUE)\n\nlavaan 0.6-18 ended normally after 43 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        19\n  Number of equality constraints                     5\n\n  Number of observations per group:               Used       Total\n    Weiblich                                       367         390\n    Männlich                                       373         401\n\nModel Test User Model:\n                                                      \n  Test statistic                                 2.129\n  Degrees of freedom                                 4\n  P-value (Chi-square)                           0.712\n  Test statistic for each group:\n    Weiblich                                     1.026\n    Männlich                                     1.104\n\nModel Test Baseline Model:\n\n  Test statistic                              1211.589\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.002\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2911.569\n  Loglikelihood unrestricted model (H1)      -2910.504\n                                                      \n  Akaike (AIC)                                5851.138\n  Bayesian (BIC)                              5915.631\n  Sample-size adjusted Bayesian (SABIC)       5871.176\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.058\n  P-value H_0: RMSEA &lt;= 0.050                    0.921\n  P-value H_0: RMSEA &gt;= 0.080                    0.010\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.011\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\n\nGroup 1 [Weiblich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srh_1           1.000                               0.950    0.853\n    f_srh_2 (.p2.)    1.130    0.043   26.075    0.000    1.073    0.857\n    f_srh_3 (.p3.)    1.072    0.041   26.029    0.000    1.019    0.837\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srh_1 (.p8.)    4.233    0.055   76.557    0.000    4.233    3.803\n   .f_srh_2 (.p9.)    3.793    0.063   60.533    0.000    3.793    3.028\n   .f_srh_3 (.10.)    3.962    0.060   66.025    0.000    3.962    3.255\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.336    0.039    8.728    0.000    0.336    0.272\n   .f_srhi_r2         0.416    0.049    8.556    0.000    0.416    0.265\n   .f_srhi_r3         0.444    0.047    9.381    0.000    0.444    0.300\n    f_srhi            0.902    0.085   10.619    0.000    1.000    1.000\n\n\nGroup 2 [Männlich]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_srhi =~                                                             \n    f_srh_1           1.000                               0.924    0.872\n    f_srh_2 (.p2.)    1.130    0.043   26.075    0.000    1.044    0.822\n    f_srh_3 (.p3.)    1.072    0.041   26.029    0.000    0.991    0.838\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srh_1 (.p8.)    4.233    0.055   76.557    0.000    4.233    3.997\n   .f_srh_2 (.p9.)    3.793    0.063   60.533    0.000    3.793    2.986\n   .f_srh_3 (.10.)    3.962    0.060   66.025    0.000    3.962    3.351\n    f_srhi            0.011    0.073    0.151    0.880    0.012    0.012\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .f_srhi_r1         0.268    0.035    7.756    0.000    0.268    0.239\n   .f_srhi_r2         0.524    0.053    9.829    0.000    0.524    0.325\n   .f_srhi_r3         0.417    0.045    9.251    0.000    0.417    0.298\n    f_srhi            0.853    0.079   10.862    0.000    1.000    1.000\n\n\n\nanova(cfa_metric, cfa_scalar)\n\n\nChi-Squared Difference Test\n\n           Df    AIC    BIC  Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq)\ncfa_metric  2 5853.2 5927.0 0.2407                                    \ncfa_scalar  4 5851.1 5915.6 2.1291     1.8885     0       2      0.389\n\n\nIm Vergleich zum Modell mit metrischer Invarianz hat die Gleichsetzung der Intercepts nicht zu einem signfikant schlechterem Modellfit geführt. Wir dürfen also die Mittelwerte im SRHI-R zwischen Männern und Frauen vergleichen. Das können wir entweder über den t-Test der Mittelwertscores, die wir erst berechnen müssten, tun oder direkt im Modelloutput. Etwas versteckt unter Intercepts bei den Männern finden wir eine zusätzliche Zeile f_srhi, die es bei den Frauen nicht gibt. Dies ist direkt der Unterschied zwischen den Frauen als Referenzgruppe und den Männern. Der Wert von 0.011 (SE = .073) und einem p-Wert von .88 zeigt, dass es keinen signifikanten Unterschied zwischen Frauen und Männern im F-SRHI-R gibt.",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Messinvarianz</span>"
    ]
  },
  {
    "objectID": "messinvarianz.html#hausaufgabe",
    "href": "messinvarianz.html#hausaufgabe",
    "title": "9  Messinvarianz",
    "section": "9.4 Hausaufgabe",
    "text": "9.4 Hausaufgabe\nPrüfen Sie die Messinvarianz nach Geschlecht für den SRHI-A bei der TV-Nutzung. Dürfen wir Männer und Frauen in ihrem F-SRHI-A vergleichen, und wenn ja, wie fällt der Vergleich aus?",
    "crumbs": [
      "Faktorenanalyse",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Messinvarianz</span>"
    ]
  },
  {
    "objectID": "uebungen.html",
    "href": "uebungen.html",
    "title": "Übungen",
    "section": "",
    "text": "Übung 1\nFür diese Übungssitzung analysieren wir den Datensatz Faehnrich_2020.sav, in dem Posts von verschiedenen Universitäts-Facebook-Seiten, einige Inhaltsvariablen und deren Resonanz-Metriken enthalten sind.",
    "crumbs": [
      "Übungen"
    ]
  },
  {
    "objectID": "uebungen.html#übung-1",
    "href": "uebungen.html#übung-1",
    "title": "Übungen",
    "section": "",
    "text": "Aufgabe 1\n\nAnalysieren Sie, welche Universität (uni) im Mittel die meisten Kommentare pro Post (comments_count) erhält (nur deskriptiv).\nBerichten Sie, wieviel Varianz in der Kommentarzahl auf Unterschiede zwischen den Uni-Facebook-Pages zurückzuführen sind.\n\n\n\nAufgabe 2\nDie Posts sind verschiedenen Inhalts-Typen (type) zugeordnet (Link, Video, Foto, Status, Event und Note).\n\nAnalysieren Sie deskriptiv, wie häufig die verschiedenen Typen von Posts in der Stichprobe sind.\nAnalysieren Sie, ob und wie die Anzahl der Likes (likes_count) durch den Typ des Posts beeinflusst wird. Welcher Post-Typ hat den stärksten Einfluss, welche Typen unterscheiden sich statistisch signifikant in den Likes?\nVisualisieren Sie das Ergebnis.\n\n\n\nAufgabe 3\n\nPrüfen Sie die Hypothese: “Immer wenn wir kürzere Posts als üblich schreiben, bekommen wir auch mehr Likes als sonst.” (word_count)\nPrüfen Sie die Vermutung, dass dieser Zusammenhang nur bzw. besonders für Posts mit dem Thema Forschung gilt. (topic_research)\nVisualisieren Sie das Ergebnis.\n\nFür alle Aufgaben gilt:\n\nGeben Sie als Kommentar (mit # beginnend) an, welche Frage Sie bearbeiten, darunter folgt der zugehörige Code.\nDie Antwortsätze folgen darunter, ebenfalls als Kommentar (mit # beginnend).\nDer R-Code muss (wenigstens) komplett durchlaufen im Projekt, d.h. nicht funktionierenden Code auskommentieren und Frage als Kommentar dazu.",
    "crumbs": [
      "Übungen"
    ]
  },
  {
    "objectID": "uebungen.html#übung-2",
    "href": "uebungen.html#übung-2",
    "title": "Übungen",
    "section": "Übung 2",
    "text": "Übung 2\nFür diese Übungssitzung analysieren wir den Datensatz gewohnheiten.xlsx, den wir schon aus verschiedenen Sitzungen kennen und der u.a. Skalen zur Messung der Gewohnheitsstärke bei der Nutzung von Fernsehen, Computer und Smartphone enthält.\n\n\n\n\n\n\nCodebuch\n\n\n\nDas Codebuch für den Datensatz gewohnheiten.xlsx finden Sie hier: Bachelor Kursmaterialien\n\n\n\nAufgabe 1\n\nTesten Sie die folgende Annahme mit dem geeigneten Verfahren: „Je stärker die empfundene Kompetenz bzgl. der Smartphonenutzung (s_komp) ist, desto höher ist die Nutzungsintensität (i1_smartphone). Dieser Zusammenhang wird von der Gewohnheitsstärke (s_srhi_ges) mediiert: Je höher die empfundene Kompetenz, desto höher die Gewohnheitsstärke, und je höher die Gewohnheitsstärke, desto höher die Nutzungsintensität.\nGibt es Aspekte, die gegen ihre gewählte Vorgehensweise sprechen?\n\n\n\nAufgabe 2\nSie möchten wissen, ob und welche latenten Faktoren hinter den Trait-Selbstkonrolle-Items stehen. Die Items sind in den 13 Variablen p_scx enthalten. Wählen Sie eine geeignete Vorgehensweise und prüfen Sie, ob sich die Items für die Analyse eignen und benennen Sie die latenten Faktoren.\n\n\nAufgabe 3\nTesten Sie, ob das Geschlecht (p_2) der Proband:innen einen Einfluss auf den Wiederholungscharakter bei der Smartphone-Nutzung hat. Modellieren Sie den Wiederholungscharakter als latenten Faktor basierend auf dem Items (s_srhi_r1:s_srhi_r3).\nFür alle Aufgaben gilt:\n\nGeben Sie als Kommentar (mit # beginnend) an, welche Frage Sie bearbeiten, darunter folgt der zugehörige Code.\nDie Antwortsätze folgen darunter, ebenfalls als Kommentar (mit # beginnend).\nDer R-Code muss (wenigstens) komplett durchlaufen im Projekt, d.h. nicht funktionierenden Code auskommentieren und Frage als Kommentar dazu.",
    "crumbs": [
      "Übungen"
    ]
  },
  {
    "objectID": "glossar.html",
    "href": "glossar.html",
    "title": "Glossar",
    "section": "",
    "text": "Funktion\nDefinition\n\n\n\n\nanova\nModellvergleich und partieller F-Test\n\n\ncor.test\nKorrelation und Signifikanz schätzen\n\n\nlavaan::cfa\nKonfirmatorische Faktorenanalyse\n\n\nlavaan::modificationindices\nVerbesserungsfähigkeit des Modells berechnen\n\n\nlavaan::sem\nPfadmodelle schätzen\n\n\nlm\nLineares Regressionsmodell schätzen\n\n\nlme4::lmer\nMultilevel-Modelle schätzen\n\n\nmarginaleffects::avg_comparisons\nModellkontraste und Posthoc-Tests berechnen\n\n\nmarginaleffects::avg_predictions\nModellvorhersagen berechnen\n\n\nmarginaleffects::avg_slopes\nAME berechnen\n\n\nmediation::mediate\nMediationseffekte analysieren\n\n\nperformance::check_model\nModellannahmen prüfen\n\n\nperformance::check_performance\nModellannahmen prüfen\n\n\nperformance::icc\nIntraklassenkorrelationskoeffizient berechnen\n\n\nplm::plm\nFixed-Effects-Modell schätzen\n\n\nprincipal\nHauptkomponentenanalyse durchführen\n\n\npsych::cortest.bartlett\nBarlett-Test durchführen\n\n\npsych::fa.diagram\nVisualisierung der Beziehungen/ Ladungen zwischen den Items und den Faktoren\n\n\npsych::fa.parallel\nParallel-Analyse durchführen\n\n\npsych::KMO\nKMO-Wert berechnen\n\n\npsych::scree\nVisualisierung der Eigenwerte zur Bestimmung der Faktorenanzahl\n\n\nsemTools::reliability\nReliabilitätskennwerte berechnen",
    "crumbs": [
      "Glossar"
    ]
  }
]